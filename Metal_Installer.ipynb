{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "b0YnbjBDl3zq"
      },
      "outputs": [],
      "source": [
        "# @markdown # Step 1: Install all neccessary packages\n",
        "# Install all necessary packages\n",
        "!pip install biopython\n",
        "!pip install --upgrade tqdm\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "# Install PyMOL using Conda\n",
        "!mamba install -c conda-forge pymol-open-source -y\n",
        "\n",
        "# Import necessary modules\n",
        "from Bio.PDB import PDBParser, Selection, NeighborSearch\n",
        "from Bio.PDB.Polypeptide import is_aa\n",
        "from tqdm import tqdm\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6Q3_F6_hbkUp"
      },
      "outputs": [],
      "source": [
        "#@markdown # Step 2: Mutate the glycine to alanine\n",
        "#@markdown # **Please remove all water molecules and ligands before running.**\n",
        "\n",
        "# Import the necessary modules\n",
        "import pymol2\n",
        "\n",
        "#@markdown **Note:** Specify the paths to the input and output PDB files below.\n",
        "\n",
        "#@markdown ### Enter the path to your input PDB file:\n",
        "pdb_file_path = \"/content/3tis_run.pdb\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Enter the path to your output PDB file:\n",
        "output_file_path = \"/content/3tis_run_alanine.pdb\"  #@param {type:\"string\"}\n",
        "\n",
        "# Create an instance of the PyMOL session\n",
        "with pymol2.PyMOL() as pymol:\n",
        "    # Initialize PyMOL\n",
        "    pymol.cmd.reinitialize()\n",
        "\n",
        "    # Load the structure file\n",
        "    pymol.cmd.load(pdb_file_path)\n",
        "\n",
        "    # Identify glycine residues\n",
        "    glycine_residues = pymol.cmd.get_model(\"resn GLY\").atom\n",
        "\n",
        "    # Loop through glycine residues\n",
        "    for atom in glycine_residues:\n",
        "        residue_num = atom.resi\n",
        "        chain = atom.chain\n",
        "        # Construct the selection string in the format \"resi X and chain Y\"\n",
        "        selection_str = f\"resi {residue_num} and chain {chain}\"\n",
        "        # Apply the mutation using the mutagenesis command\n",
        "        pymol.cmd.wizard(\"mutagenesis\")\n",
        "        pymol.cmd.refresh_wizard()\n",
        "        pymol.cmd.get_wizard().do_select(selection_str)\n",
        "        pymol.cmd.get_wizard().set_mode(\"ALA\")\n",
        "        pymol.cmd.get_wizard().apply()\n",
        "        pymol.cmd.delete(selection_str)  # Delete the original residue to avoid clashes\n",
        "\n",
        "    # Save the mutated structure\n",
        "    pymol.cmd.save(output_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sr9mhfr9R5zm"
      },
      "outputs": [],
      "source": [
        "# Existing imports and setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from Bio.PDB import PDBParser\n",
        "import itertools\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 3A: Run the Metal-Installer\n",
        "\n",
        "# Import the necessary modules\n",
        "import pymol2\n",
        "from IPython.display import display, Markdown\n",
        "import requests  # Required for downloading files from GitHub\n",
        "\n",
        "# @markdown **Note:** Specify the paths to the input and output files below.\n",
        "\n",
        "# @markdown ### Enter the path to your input PDB file:\n",
        "pdb_file = \"/content/3tis_run_alanine.pdb\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Enter the path to your output Excel file:\n",
        "output_excel_file = \"/content/3tis_run_alanine_Cu_3His.xlsx\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "# @markdown ### Enter the path to your PyMOL script file:\n",
        "pymol_script_file = \"/content/3tis_run_alanine_Cu_3His.pml\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Set the metal type to use:\n",
        "Metal = 'Cu'  # @param [\"Zn\", \"Mn\", \"Cu\", \"Fe\"]\n",
        "\n",
        "# @markdown ### Select the combination type:\n",
        "# @markdown **Note:** 2His/1Cys is only available to Cu\n",
        "Combinations = '3His'  # @param [\"3His\", \"2His_1Asp\", \"2His_1Glu\", \"2His_1Cys\"]\n",
        "\n",
        "# @markdown ### Choose a threshold for analysis:\n",
        "Range = '4'  # @param [\"1\", \"2\", \"3\", \"4\",\"5\"]\n",
        "\n",
        "# @markdown ### Specify the specific residue number (use 0 for no specific residue):\n",
        "specific_residue_number = 24  # @param {type:\"integer\"}\n",
        "\n",
        "# Additional code to construct the URL for thresholds based on user input and download the file\n",
        "\n",
        "# Base URL for the thresholds files on GitHub\n",
        "base_url = \"https://raw.githubusercontent.com/SNU-Songlab/Metal-Installer-code/main/Threshold\"\n",
        "\n",
        "# Construct the full URL based on user input\n",
        "thresholds_url = f\"{base_url}/{Metal}/{Combinations}/{Range}.xlsx\"\n",
        "\n",
        "# Define the local path to save the downloaded file\n",
        "thresholds_file = \"/content/thresholds.xlsx\"  # This path will be used throughout the script\n",
        "\n",
        "# Download the file from GitHub\n",
        "response = requests.get(thresholds_url)\n",
        "\n",
        "# Check if the request was successful and save the file\n",
        "if response.status_code == 200:\n",
        "    with open(thresholds_file, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f\"File downloaded successfully from {thresholds_url} and saved as {thresholds_file}\")\n",
        "else:\n",
        "    raise ValueError(f\"Failed to download file from {thresholds_url}. Status code: {response.status_code}\")\n",
        "\n",
        "# Load thresholds from the downloaded Excel file\n",
        "thresholds_df = pd.read_excel(thresholds_file, sheet_name='Sheet1')\n",
        "\n",
        "# Extract threshold values\n",
        "thresholds = {}\n",
        "for _, row in thresholds_df.iterrows():\n",
        "    parameter = row['Parameter']\n",
        "    min_value = row['Min']\n",
        "    max_value = row['Max']\n",
        "\n",
        "    if pd.notna(min_value) and pd.notna(max_value):\n",
        "        thresholds[parameter] = (min_value, max_value)\n",
        "\n",
        "# Assign threshold values\n",
        "alpha_distance_range = thresholds['alpha_distance_range']\n",
        "beta_distance_range = thresholds['beta_distance_range']\n",
        "ratio_threshold_range = thresholds['ratio_threshold_range']\n",
        "pie_threshold_range = thresholds['pie_threshold_range']\n",
        "\n",
        "# PDB Parser setup\n",
        "parser = PDBParser(QUIET=True)\n",
        "structure = parser.get_structure('protein', pdb_file)\n",
        "model = structure[0]\n",
        "residues = [residue for residue in model.get_residues() if residue.get_id()[0] == ' ']\n",
        "\n",
        "# Step 1: Filter combinations to include specific residue number if specified\n",
        "if specific_residue_number != 0:\n",
        "    combinations = [\n",
        "        comb for comb in itertools.combinations(residues, 3)\n",
        "        if any(res.get_id()[1] == specific_residue_number for res in comb)\n",
        "    ]\n",
        "else:\n",
        "    combinations = list(itertools.combinations(residues, 3))\n",
        "\n",
        "# Distance filter\n",
        "filtered_data_distances = []\n",
        "\n",
        "for idx, combination in enumerate(combinations):\n",
        "    alpha_distances, beta_distances = [], []\n",
        "\n",
        "    try:\n",
        "        for res1, res2 in itertools.combinations(combination, 2):\n",
        "            if res1.has_id('CA') and res2.has_id('CA'):\n",
        "                ca1, ca2 = res1['CA'].coord, res2['CA'].coord\n",
        "                alpha_distance = np.linalg.norm(ca1 - ca2)\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            if res1.has_id('CB') and res2.has_id('CB'):\n",
        "                cb1, cb2 = res1['CB'].coord, res2['CB'].coord\n",
        "                beta_distance = np.linalg.norm(cb1 - cb2)\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            if (alpha_distance_range[0] <= alpha_distance <= alpha_distance_range[1] and\n",
        "                    beta_distance_range[0] <= beta_distance <= beta_distance_range[1]):\n",
        "                alpha_distances.append(alpha_distance)\n",
        "                beta_distances.append(beta_distance)\n",
        "\n",
        "        if len(alpha_distances) >= 3 and len(beta_distances) >= 3:\n",
        "            filtered_data_distances.append({\n",
        "                'PDB_ID': pdb_file,\n",
        "                'Combination': combination,\n",
        "                'Coord_chain_id_number1': combination[0].get_full_id()[2],\n",
        "                'Coord_residue_number1': combination[0].get_full_id()[3][1],\n",
        "                'Coord_residue_name1': combination[0].get_resname(),\n",
        "                'Coord_atom_name1': 'CA',\n",
        "                'Coord_chain_id_number2': combination[1].get_full_id()[2],\n",
        "                'Coord_residue_number2': combination[1].get_full_id()[3][1],\n",
        "                'Coord_residue_name2': combination[1].get_resname(),\n",
        "                'Coord_atom_name2': 'CA',\n",
        "                'Coord_chain_id_number3': combination[2].get_full_id()[2],\n",
        "                'Coord_residue_number3': combination[2].get_full_id()[3][1],\n",
        "                'Coord_residue_name3': combination[2].get_resname(),\n",
        "                'Coord_atom_name3': 'CA',\n",
        "                'Alpha Distance 1': alpha_distances[0],\n",
        "                'Alpha Distance 2': alpha_distances[1],\n",
        "                'Alpha Distance 3': alpha_distances[2],\n",
        "                'Beta Distance 1': beta_distances[0],\n",
        "                'Beta Distance 2': beta_distances[1],\n",
        "                'Beta Distance 3': beta_distances[2]\n",
        "            })\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error processing combination {combination}: {e}\")\n",
        "\n",
        "# Create DataFrame for distances\n",
        "column_order = [\n",
        "    'PDB_ID',\n",
        "    'Combination',\n",
        "    'Coord_chain_id_number1', 'Coord_residue_number1', 'Coord_residue_name1', 'Coord_atom_name1',\n",
        "    'Coord_chain_id_number2', 'Coord_residue_number2', 'Coord_residue_name2', 'Coord_atom_name2',\n",
        "    'Coord_chain_id_number3', 'Coord_residue_number3', 'Coord_residue_name3', 'Coord_atom_name3',\n",
        "    'Alpha Distance 1', 'Alpha Distance 2', 'Alpha Distance 3',\n",
        "    'Beta Distance 1', 'Beta Distance 2', 'Beta Distance 3'\n",
        "]\n",
        "\n",
        "df_distances = pd.DataFrame(filtered_data_distances)\n",
        "df_distances = df_distances[column_order]\n",
        "\n",
        "# Ratio filter\n",
        "filtered_data_ratio = []\n",
        "\n",
        "for idx, row in df_distances.iterrows():\n",
        "    alpha_distances = [row['Alpha Distance 1'], row['Alpha Distance 2'], row['Alpha Distance 3']]\n",
        "    beta_distances = [row['Beta Distance 1'], row['Beta Distance 2'], row['Beta Distance 3']]\n",
        "\n",
        "    for i in range(3):\n",
        "        alpha_distance_i = alpha_distances[i]\n",
        "        beta_distance_i = beta_distances[i]\n",
        "        ratio = alpha_distance_i / beta_distance_i\n",
        "\n",
        "        if not (ratio_threshold_range[0] <= ratio <= ratio_threshold_range[1]):\n",
        "            break\n",
        "    else:\n",
        "        filtered_data_ratio.append(row)\n",
        "\n",
        "df_ratio = pd.DataFrame(filtered_data_ratio)\n",
        "df_ratio = df_ratio[column_order]\n",
        "\n",
        "\n",
        "# Pie filter\n",
        "def calculate_pie(vector1, vector2):\n",
        "    dot_product = np.dot(vector1, vector2)\n",
        "    magnitude_product = np.linalg.norm(vector1) * np.linalg.norm(vector2)\n",
        "    if magnitude_product == 0:\n",
        "        return np.nan\n",
        "    cosine_angle = dot_product / magnitude_product\n",
        "    cosine_angle = np.clip(cosine_angle, -1.0, 1.0)\n",
        "    return np.degrees(np.arccos(cosine_angle))\n",
        "\n",
        "def process_row(row):\n",
        "    pdb_file_path = pdb_file\n",
        "    if not os.path.isfile(pdb_file_path):\n",
        "        print(f\"PDB file not found: {pdb_file_path}\")\n",
        "        return [None, None, None]\n",
        "\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure('protein', pdb_file_path)\n",
        "    model = structure[0]\n",
        "\n",
        "    try:\n",
        "        residues = row['Combination']\n",
        "        print(f\"Residues loaded: {residues}\")\n",
        "\n",
        "        pies = []\n",
        "        pairs = [(0, 1), (0, 2), (1, 2)]\n",
        "\n",
        "        for i, j in pairs:\n",
        "            try:\n",
        "                CA1 = residues[i]['CA']\n",
        "                CA2 = residues[j]['CA']\n",
        "                CB1 = residues[i]['CB'] if 'CB' in residues[i] else CA1\n",
        "                CB2 = residues[j]['CB'] if 'CB' in residues[j] else CA2\n",
        "\n",
        "                vector_CA = CA2.coord - CA1.coord\n",
        "                vector_CB = CB2.coord - CB1.coord\n",
        "\n",
        "                angle = calculate_pie(vector_CA, vector_CB)\n",
        "                pies.append(angle)\n",
        "            except KeyError as e:\n",
        "                print(f\"KeyError for residues {residues[i]} and {residues[j]}: {e}\")\n",
        "                pies.append(None)\n",
        "\n",
        "        return pies\n",
        "    except KeyError as e:\n",
        "        print(f\"KeyError: {e}\")\n",
        "        return [None, None, None]\n",
        "\n",
        "pie_results = df_ratio.apply(process_row, axis=1, result_type='expand')\n",
        "df_ratio[['Pie_1_2', 'Pie_1_3', 'Pie_2_3']] = pie_results\n",
        "\n",
        "# Create filter columns based on pie thresholds\n",
        "for col in ['Pie_1_2', 'Pie_1_3', 'Pie_2_3']:\n",
        "    df_ratio[f'{col}_Filter'] = df_ratio.apply(lambda row: pie_threshold_range[0] < row[col] < pie_threshold_range[1] if pd.notnull(row[col]) else False, axis=1)\n",
        "\n",
        "df_ratio['Pie_Filter'] = df_ratio[[f'{col}_Filter' for col in ['Pie_1_2', 'Pie_1_3', 'Pie_2_3']]].all(axis=1)\n",
        "\n",
        "df_final_filter = df_ratio[df_ratio['Pie_Filter']]\n",
        "\n",
        "# Save all DataFrames into a single Excel file with different tabs\n",
        "with pd.ExcelWriter(output_excel_file) as writer:\n",
        "    df_distances.to_excel(writer, sheet_name='Distances', index=False)\n",
        "    df_ratio.to_excel(writer, sheet_name='Ratio', index=False)\n",
        "    df_final_filter.to_excel(writer, sheet_name='Pie', index=False)\n",
        "\n",
        "# Generate PyMOL script file\n",
        "pymol_script_commands = []\n",
        "df_final_filter['Combination_Number'] = range(1, len(df_final_filter) + 1)\n",
        "\n",
        "for index, row in df_final_filter.iterrows():\n",
        "    combination = row['Combination']\n",
        "    chain1, res1 = combination[0].get_full_id()[2], combination[0].get_full_id()[3][1]\n",
        "    chain2, res2 = combination[1].get_full_id()[2], combination[1].get_full_id()[3][1]\n",
        "    chain3, res3 = combination[2].get_full_id()[2], combination[2].get_full_id()[3][1]\n",
        "\n",
        "    selection_name = f\"obj{row['Combination_Number']:02d}\"\n",
        "    pymol_script_commands.append(f\"select {selection_name}, (chain {chain1} and resi {res1}) or (chain {chain2} and resi {res2}) or (chain {chain3} and resi {res3})\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue1, /{pdb_file}//{chain1}/{res1}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue2, /{pdb_file}//{chain2}/{res2}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue3, /{pdb_file}//{chain3}/{res3}\")\n",
        "\n",
        "with open(pymol_script_file, 'w') as f:\n",
        "    f.write(\"# PyMOL script for visualizing filtered residue combinations\\n\\n\")\n",
        "    for command in pymol_script_commands:\n",
        "        f.write(command + '\\n')\n",
        "\n",
        "print(f\"\\nResults saved to {output_excel_file}\")\n",
        "print(f\"PyMOL script saved to {pymol_script_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "i9GaAf8WM8ke"
      },
      "outputs": [],
      "source": [
        "# Existing imports and setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from Bio.PDB import PDBParser\n",
        "import itertools\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 3B: Run the Metal-Installer\n",
        "\n",
        "# Import the necessary modules\n",
        "import pymol2\n",
        "from IPython.display import display, Markdown\n",
        "import requests  # Required for downloading files from GitHub\n",
        "\n",
        "# @markdown **Note:** Specify the paths to the input and output files below.\n",
        "\n",
        "# @markdown ### Enter the path to your input PDB file:\n",
        "pdb_file = \"/content/1EP0_alanine_dimer.pdb\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Enter the path to your output Excel file:\n",
        "output_excel_file = \"/content/1EP0_alanine_dimer_FE_2His_1asp_130.xlsx\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Enter the path to your PyMOL script file:\n",
        "pymol_script_file = \"/content/OmpF_dimer_alanine_3His_Full.pml\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Specify the specific residue number (use 0 for no specific residue):\n",
        "specific_residue_number = 0  # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ### Set the thresholds for analysis\n",
        "# @markdown **Alpha Distance**: Enter the minimum and maximum values.\n",
        "alpha_distance_min = 5.5  # @param {type:\"number\"}\n",
        "alpha_distance_max = 10  # @param {type:\"number\"}\n",
        "\n",
        "# @markdown **Beta Distance**: Enter the minimum and maximum values.\n",
        "beta_distance_min = 6.0  # @param {type:\"number\"}\n",
        "beta_distance_max = 9  # @param {type:\"number\"}\n",
        "\n",
        "# @markdown **Ratio Threshold**: Enter the minimum and maximum values.\n",
        "ratio_threshold_min = 0.7  # @param {type:\"number\"}\n",
        "ratio_threshold_max = 1.4  # @param {type:\"number\"}\n",
        "\n",
        "# @markdown **Pie Threshold**: Enter the minimum and maximum values.\n",
        "pie_threshold_min = 0  # @param {type:\"number\"}\n",
        "pie_threshold_max = 15  # @param {type:\"number\"}\n",
        "\n",
        "# Set thresholds based on user inputs\n",
        "alpha_distance_range = (alpha_distance_min, alpha_distance_max)\n",
        "beta_distance_range = (beta_distance_min, beta_distance_max)\n",
        "ratio_threshold_range = (ratio_threshold_min, ratio_threshold_max)\n",
        "pie_threshold_range = (pie_threshold_min, pie_threshold_max)\n",
        "\n",
        "# Output the ranges to confirm\n",
        "print(f\"Alpha Distance Range: {alpha_distance_range}\")\n",
        "print(f\"Beta Distance Range: {beta_distance_range}\")\n",
        "print(f\"Ratio Threshold Range: {ratio_threshold_range}\")\n",
        "print(f\"Pie Threshold Range: {pie_threshold_range}\")\n",
        "\n",
        "# Capture the inputs into variables\n",
        "alpha_distance_range = (alpha_distance_min, alpha_distance_max)\n",
        "beta_distance_range = (beta_distance_min, beta_distance_max)\n",
        "ratio_threshold_range = (ratio_threshold_min, ratio_threshold_max)\n",
        "pie_threshold_range = (pie_threshold_min, pie_threshold_max)\n",
        "\n",
        "# Continue with the script using these threshold values\n",
        "print(f\"Alpha Distance Range: {alpha_distance_range}\")\n",
        "print(f\"Beta Distance Range: {beta_distance_range}\")\n",
        "print(f\"Ratio Threshold Range: {ratio_threshold_range}\")\n",
        "print(f\"Pie Threshold Range: {pie_threshold_range}\")\n",
        "\n",
        "# PDB Parser setup\n",
        "parser = PDBParser(QUIET=True)\n",
        "structure = parser.get_structure('protein', pdb_file)\n",
        "model = structure[0]\n",
        "residues = [residue for residue in model.get_residues() if residue.get_id()[0] == ' ']\n",
        "\n",
        "# Step 1: Filter combinations to include specific residue number if specified\n",
        "if specific_residue_number != 0:\n",
        "    combinations = [\n",
        "        comb for comb in itertools.combinations(residues, 3)\n",
        "        if any(res.get_id()[1] == specific_residue_number for res in comb)\n",
        "    ]\n",
        "else:\n",
        "    combinations = list(itertools.combinations(residues, 3))\n",
        "\n",
        "\n",
        "# Distance filter\n",
        "filtered_data_distances = []\n",
        "\n",
        "for idx, combination in enumerate(combinations):\n",
        "    alpha_distances, beta_distances = [], []\n",
        "\n",
        "    try:\n",
        "        for res1, res2 in itertools.combinations(combination, 2):\n",
        "            if res1.has_id('CA') and res2.has_id('CA'):\n",
        "                ca1, ca2 = res1['CA'].coord, res2['CA'].coord\n",
        "                alpha_distance = np.linalg.norm(ca1 - ca2)\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            if res1.has_id('CB') and res2.has_id('CB'):\n",
        "                cb1, cb2 = res1['CB'].coord, res2['CB'].coord\n",
        "                beta_distance = np.linalg.norm(cb1 - cb2)\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            if (alpha_distance_range[0] <= alpha_distance <= alpha_distance_range[1] and\n",
        "                    beta_distance_range[0] <= beta_distance <= beta_distance_range[1]):\n",
        "                alpha_distances.append(alpha_distance)\n",
        "                beta_distances.append(beta_distance)\n",
        "\n",
        "        if len(alpha_distances) >= 3 and len(beta_distances) >= 3:\n",
        "            filtered_data_distances.append({\n",
        "                'PDB_ID': pdb_file,\n",
        "                'Combination': combination,\n",
        "                'Coord_chain_id_number1': combination[0].get_full_id()[2],\n",
        "                'Coord_residue_number1': combination[0].get_full_id()[3][1],\n",
        "                'Coord_residue_name1': combination[0].get_resname(),\n",
        "                'Coord_atom_name1': 'CA',\n",
        "                'Coord_chain_id_number2': combination[1].get_full_id()[2],\n",
        "                'Coord_residue_number2': combination[1].get_full_id()[3][1],\n",
        "                'Coord_residue_name2': combination[1].get_resname(),\n",
        "                'Coord_atom_name2': 'CA',\n",
        "                'Coord_chain_id_number3': combination[2].get_full_id()[2],\n",
        "                'Coord_residue_number3': combination[2].get_full_id()[3][1],\n",
        "                'Coord_residue_name3': combination[2].get_resname(),\n",
        "                'Coord_atom_name3': 'CA',\n",
        "                'Alpha Distance 1': alpha_distances[0],\n",
        "                'Alpha Distance 2': alpha_distances[1],\n",
        "                'Alpha Distance 3': alpha_distances[2],\n",
        "                'Beta Distance 1': beta_distances[0],\n",
        "                'Beta Distance 2': beta_distances[1],\n",
        "                'Beta Distance 3': beta_distances[2]\n",
        "            })\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error processing combination {combination}: {e}\")\n",
        "\n",
        "# Create DataFrame for distances\n",
        "column_order = [\n",
        "    'PDB_ID',\n",
        "    'Combination',\n",
        "    'Coord_chain_id_number1', 'Coord_residue_number1', 'Coord_residue_name1', 'Coord_atom_name1',\n",
        "    'Coord_chain_id_number2', 'Coord_residue_number2', 'Coord_residue_name2', 'Coord_atom_name2',\n",
        "    'Coord_chain_id_number3', 'Coord_residue_number3', 'Coord_residue_name3', 'Coord_atom_name3',\n",
        "    'Alpha Distance 1', 'Alpha Distance 2', 'Alpha Distance 3',\n",
        "    'Beta Distance 1', 'Beta Distance 2', 'Beta Distance 3'\n",
        "]\n",
        "\n",
        "df_distances = pd.DataFrame(filtered_data_distances)\n",
        "df_distances = df_distances[column_order]\n",
        "\n",
        "# Ratio filter\n",
        "filtered_data_ratio = []\n",
        "\n",
        "for idx, row in df_distances.iterrows():\n",
        "    alpha_distances = [row['Alpha Distance 1'], row['Alpha Distance 2'], row['Alpha Distance 3']]\n",
        "    beta_distances = [row['Beta Distance 1'], row['Beta Distance 2'], row['Beta Distance 3']]\n",
        "\n",
        "    for i in range(3):\n",
        "        alpha_distance_i = alpha_distances[i]\n",
        "        beta_distance_i = beta_distances[i]\n",
        "        ratio = alpha_distance_i / beta_distance_i\n",
        "\n",
        "        if not (ratio_threshold_range[0] <= ratio <= ratio_threshold_range[1]):\n",
        "            break\n",
        "    else:\n",
        "        filtered_data_ratio.append(row)\n",
        "\n",
        "df_ratio = pd.DataFrame(filtered_data_ratio)\n",
        "df_ratio = df_ratio[column_order]\n",
        "\n",
        "# Pie filter\n",
        "def calculate_pie(vector1, vector2):\n",
        "    dot_product = np.dot(vector1, vector2)\n",
        "    magnitude_product = np.linalg.norm(vector1) * np.linalg.norm(vector2)\n",
        "    if magnitude_product == 0:\n",
        "        return np.nan\n",
        "    cosine_angle = dot_product / magnitude_product\n",
        "    cosine_angle = np.clip(cosine_angle, -1.0, 1.0)\n",
        "    return np.degrees(np.arccos(cosine_angle))\n",
        "\n",
        "def process_row(row):\n",
        "    pdb_file_path = pdb_file\n",
        "    if not os.path.isfile(pdb_file_path):\n",
        "        print(f\"PDB file not found: {pdb_file_path}\")\n",
        "        return [None, None, None]\n",
        "\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure('protein', pdb_file_path)\n",
        "    model = structure[0]\n",
        "\n",
        "    try:\n",
        "        residues = row['Combination']\n",
        "        print(f\"Residues loaded: {residues}\")\n",
        "\n",
        "        pies = []\n",
        "        pairs = [(0, 1), (0, 2), (1, 2)]\n",
        "\n",
        "        for i, j in pairs:\n",
        "            try:\n",
        "                CA1 = residues[i]['CA']\n",
        "                CA2 = residues[j]['CA']\n",
        "                CB1 = residues[i]['CB'] if 'CB' in residues[i] else CA1\n",
        "                CB2 = residues[j]['CB'] if 'CB' in residues[j] else CA2\n",
        "\n",
        "                vector_CA = CA2.coord - CA1.coord\n",
        "                vector_CB = CB2.coord - CB1.coord\n",
        "\n",
        "                angle = calculate_pie(vector_CA, vector_CB)\n",
        "                pies.append(angle)\n",
        "            except KeyError as e:\n",
        "                print(f\"KeyError for residues {residues[i]} and {residues[j]}: {e}\")\n",
        "                pies.append(None)\n",
        "\n",
        "        return pies\n",
        "    except KeyError as e:\n",
        "        print(f\"KeyError: {e}\")\n",
        "        return [None, None, None]\n",
        "\n",
        "pie_results = df_ratio.apply(process_row, axis=1, result_type='expand')\n",
        "df_ratio[['Pie_1_2', 'Pie_1_3', 'Pie_2_3']] = pie_results\n",
        "\n",
        "# Create filter columns based on pie thresholds\n",
        "for col in ['Pie_1_2', 'Pie_1_3', 'Pie_2_3']:\n",
        "    df_ratio[f'{col}_Filter'] = df_ratio.apply(lambda row: pie_threshold_range[0] < row[col] < pie_threshold_range[1] if pd.notnull(row[col]) else False, axis=1)\n",
        "\n",
        "df_ratio['Pie_Filter'] = df_ratio[[f'{col}_Filter' for col in ['Pie_1_2', 'Pie_1_3', 'Pie_2_3']]].all(axis=1)\n",
        "\n",
        "df_final_filter = df_ratio[df_ratio['Pie_Filter']]\n",
        "# Remove '.pdb' from the PDB_ID in the final filtered DataFrame\n",
        "df_final_filter['PDB_ID'] = df_final_filter['PDB_ID'].str.replace('.pdb', '', regex=False)\n",
        "# Save all DataFrames into a single Excel file with different tabs\n",
        "with pd.ExcelWriter(output_excel_file) as writer:\n",
        "    df_distances.to_excel(writer, sheet_name='Distances', index=False)\n",
        "    df_ratio.to_excel(writer, sheet_name='Ratio', index=False)\n",
        "    df_final_filter.to_excel(writer, sheet_name='Pie', index=False)\n",
        "\n",
        "# Generate PyMOL script file\n",
        "pymol_script_commands = []\n",
        "df_final_filter['Combination_Number'] = range(1, len(df_final_filter) + 1)\n",
        "\n",
        "for index, row in df_final_filter.iterrows():\n",
        "    combination = row['Combination']\n",
        "    chain1, res1 = combination[0].get_full_id()[2], combination[0].get_full_id()[3][1]\n",
        "    chain2, res2 = combination[1].get_full_id()[2], combination[1].get_full_id()[3][1]\n",
        "    chain3, res3 = combination[2].get_full_id()[2], combination[2].get_full_id()[3][1]\n",
        "\n",
        "    selection_name = f\"obj{row['Combination_Number']:02d}\"\n",
        "    pymol_script_commands.append(f\"select {selection_name}, (chain {chain1} and resi {res1}) or (chain {chain2} and resi {res2}) or (chain {chain3} and resi {res3})\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue1, /{pdb_file}//{chain1}/{res1}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue2, /{pdb_file}//{chain2}/{res2}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue3, /{pdb_file}//{chain3}/{res3}\")\n",
        "\n",
        "with open(pymol_script_file, 'w') as f:\n",
        "    f.write(\"# PyMOL script for visualizing filtered residue combinations\\n\\n\")\n",
        "    for command in pymol_script_commands:\n",
        "        f.write(command + '\\n')\n",
        "\n",
        "print(f\"\\nResults saved to {output_excel_file}\")\n",
        "print(f\"PyMOL script saved to {pymol_script_file}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlddZ35YMLWD",
        "outputId": "85473933-07c3-489b-d38a-d2a3bbf7e1d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coordinates extracted and saved to /content/3ttis_coordinates.xlsx\n"
          ]
        }
      ],
      "source": [
        "from Bio.PDB import PDBParser\n",
        "import pandas as pd\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 4A: Preparation steps for metal-sites expectation (Coordinates extraction)\n",
        "\n",
        "# @markdown **Note:** Specify the paths to the input and output files below.\n",
        "# @markdown ### Enter the path to your input excel file (The result of the step 3)\n",
        "input_file = '/content/3tis_run_alanine_Cu_3His.xlsx' # @param {type:\"string\"}\n",
        "df_pie = pd.read_excel(input_file, sheet_name='Pie')\n",
        "\n",
        "# @markdown ### Enter the path to your input PDB file:\n",
        "pdb_file = \"/content/3tis_run_alanine.pdb\"  # @param {type:\"string\"}\n",
        "parser = PDBParser(QUIET=True)\n",
        "structure = parser.get_structure('protein', pdb_file)\n",
        "\n",
        "# Extract the PDB ID by removing the directory and `.pdb` extension\n",
        "pdb_id = os.path.basename(pdb_file).replace('.pdb', '')\n",
        "\n",
        "# Function to extract Cα and Cβ coordinates for a given residue\n",
        "def extract_coordinates(chain, res_id, atom_name):\n",
        "    try:\n",
        "        residue = chain[res_id]\n",
        "        atom_coord = residue[atom_name].coord\n",
        "        return atom_coord\n",
        "    except KeyError:\n",
        "        return [None, None, None]\n",
        "\n",
        "# Pre-fetch chains to avoid repetitive lookups\n",
        "chains = {chain.id: chain for chain in structure[0]}\n",
        "\n",
        "# Loop through each row in the Excel file and extract coordinates\n",
        "ca_coords = []\n",
        "cb_coords = []\n",
        "\n",
        "for idx, row in df_pie.iterrows():\n",
        "    chain1 = chains.get(row['Coord_chain_id_number1'])\n",
        "    chain2 = chains.get(row['Coord_chain_id_number2'])\n",
        "    chain3 = chains.get(row['Coord_chain_id_number3'])\n",
        "\n",
        "    # Extract chain, residue, and atom info for each of the three residues\n",
        "    res1_coord = extract_coordinates(chain1, row['Coord_residue_number1'], 'CA')\n",
        "    res2_coord = extract_coordinates(chain2, row['Coord_residue_number2'], 'CA')\n",
        "    res3_coord = extract_coordinates(chain3, row['Coord_residue_number3'], 'CA')\n",
        "\n",
        "    # Add coordinates for each residue\n",
        "    ca_coords.append([*res1_coord, *res2_coord, *res3_coord])\n",
        "\n",
        "    # If Cβ is also needed:\n",
        "    res1_cb = extract_coordinates(chain1, row['Coord_residue_number1'], 'CB')\n",
        "    res2_cb = extract_coordinates(chain2, row['Coord_residue_number2'], 'CB')\n",
        "    res3_cb = extract_coordinates(chain3, row['Coord_residue_number3'], 'CB')\n",
        "\n",
        "    cb_coords.append([*res1_cb, *res2_cb, *res3_cb])\n",
        "\n",
        "# Convert the extracted coordinates to DataFrames\n",
        "ca_columns = ['CA1_X', 'CA1_Y', 'CA1_Z', 'CA2_X', 'CA2_Y', 'CA2_Z', 'CA3_X', 'CA3_Y', 'CA3_Z']\n",
        "cb_columns = ['CB1_X', 'CB1_Y', 'CB1_Z', 'CB2_X', 'CB2_Y', 'CB2_Z', 'CB3_X', 'CB3_Y', 'CB3_Z']\n",
        "\n",
        "df_ca = pd.DataFrame(ca_coords, columns=ca_columns)\n",
        "df_cb = pd.DataFrame(cb_coords, columns=cb_columns)\n",
        "\n",
        "# Merge the coordinates with the original DataFrame\n",
        "df_pie = pd.concat([df_pie.reset_index(drop=True), df_ca, df_cb], axis=1)\n",
        "\n",
        "# Remove `.pdb` from the `PDB_ID` column if it exists\n",
        "if 'PDB_ID' in df_pie.columns:\n",
        "    df_pie['PDB_ID'] = df_pie['PDB_ID'].str.replace('.pdb', '', regex=False)\n",
        "# @markdown ### Enter the path to your output Excel file:\n",
        "output_file = '/content/3ttis_coordinates.xlsx'   # @param {type:\"string\"}\n",
        "df_pie.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Coordinates extracted and saved to {output_file}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2yb2fkkN2IKl"
      },
      "outputs": [],
      "source": [
        "#Final (Dynamically:Last_One+edge): 진짜 이거 ratio 까지 되는거 (마지막):찐찐찐\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from Bio.PDB import PDBParser\n",
        "import requests\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 4B: Run the metal-sites expectation\n",
        "\n",
        "# Define input and output file paths\n",
        "# @markdown ### Enter the path to your input excel file (The result of the step 4A)\n",
        "input_coords_file = '/content/3ttis_coordinates_1.xlsx' # @param {type:\"string\"}\n",
        "\n",
        "# Load input file\n",
        "df_alanine = pd.read_excel(input_coords_file)\n",
        "\n",
        "# Define file download paths\n",
        "prob_map_file = '/content/map.xlsx'\n",
        "thresholds_file = '/content/threshold.xlsx'\n",
        "\n",
        "# Download files from GitHub\n",
        "base_url = \"https://raw.githubusercontent.com/SNU-Songlab/Metal-Installer-code/main/probability/\"\n",
        "# @markdown ### Set the metal type to use:\n",
        "Metal = 'Cu'  # @param [\"Zn\", \"Mn\", \"Cu\", \"Fe\"]\n",
        "# @markdown ### Select the combination type:\n",
        "# @markdown **Note:** 3His:Zn/Cu/Fe & 2His/1Asp:Zn/Fe/Mn & 2His/1Glu: Zn/Fe/Mn & 2His/1Cys: Cu\n",
        "Combinations = '3His'  # @param [\"3His\", \"2His_1Asp\", \"2His_1Glu\", \"2His_1Cys\"]\n",
        "\n",
        "map_url = f\"{base_url}/{Metal}/{Combinations}/map.xlsx\"\n",
        "thresholds_url = f\"{base_url}/{Metal}/{Combinations}/threshold.xlsx\"\n",
        "\n",
        "# Download probability map\n",
        "response = requests.get(map_url)\n",
        "if response.status_code == 200:\n",
        "    with open(prob_map_file, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "else:\n",
        "    raise ValueError(f\"Failed to download file from {map_url}. Status code: {response.status_code}\")\n",
        "\n",
        "# Download thresholds file\n",
        "response = requests.get(thresholds_url)\n",
        "if response.status_code == 200:\n",
        "    with open(thresholds_file, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "else:\n",
        "    raise ValueError(f\"Failed to download file from {thresholds_url}. Status code: {response.status_code}\")\n",
        "\n",
        "# Load downloaded Excel files\n",
        "thresholds_df = pd.read_excel(thresholds_file, sheet_name='Sheet1')\n",
        "df_precomputed_prob_map = pd.read_excel(prob_map_file)\n",
        "\n",
        "def calculate_ratio(current_point, ca_xyz, cb_xyz):\n",
        "    # Calculate distances to Ca and Cb atoms\n",
        "    ca_distances = np.linalg.norm(ca_xyz - current_point, axis=1)\n",
        "    cb_distances = np.linalg.norm(cb_xyz - current_point, axis=1)\n",
        "    # Return ratios for each residue\n",
        "    return ca_distances / cb_distances\n",
        "\n",
        "# Extract thresholds into a dictionary\n",
        "thresholds = {}\n",
        "for _, row in thresholds_df.iterrows():\n",
        "    parameter = row['Parameter']\n",
        "    min_value = row['Min']\n",
        "    max_value = row['Max']\n",
        "    if pd.notna(min_value) and pd.notna(max_value):\n",
        "        thresholds[parameter] = (min_value, max_value)\n",
        "\n",
        "required_keys = ['ca_distances_calc', 'cb_distances_calc', 'ratio', 'angle']\n",
        "\n",
        "for key in required_keys:\n",
        "    if key not in thresholds:\n",
        "        raise KeyError(f\"Missing key '{key}' in thresholds file.\")\n",
        "\n",
        "\n",
        "# Define bin edges for CA-Zn distances, CB-Zn distances, and angles\n",
        "prob_map_file = '/content/map.xlsx'\n",
        "df_precomputed_prob_map = pd.read_excel(prob_map_file)\n",
        "\n",
        "ca_bins = np.sort(df_precomputed_prob_map['Calpha_Zn_Dist'].unique())\n",
        "cb_bins = np.sort(df_precomputed_prob_map['Cbeta_Zn_Dist'].unique())\n",
        "angle_bins = np.sort(df_precomputed_prob_map['CA-Zn-CB_Angle'].unique())\n",
        "\n",
        "# Pivot the probability map into a 3D array format\n",
        "pivoted_prob_map = df_precomputed_prob_map.pivot_table(\n",
        "    index='Calpha_Zn_Dist', columns=['Cbeta_Zn_Dist', 'CA-Zn-CB_Angle'], values='Probability', fill_value=0\n",
        ")\n",
        "prob_map_3d = pivoted_prob_map.values.reshape((len(ca_bins), len(cb_bins), len(angle_bins)))\n",
        "\n",
        "# Function to load a PDB file based on entry ID\n",
        "def load_pdb_structure(entry_id, pdb_directory):\n",
        "    pdb_parser = PDBParser()\n",
        "    pdb_file_path = os.path.join(pdb_directory, f\"{entry_id}.pdb\")\n",
        "    structure = pdb_parser.get_structure(entry_id, pdb_file_path)\n",
        "    return structure\n",
        "\n",
        "# Function to score Zn positions\n",
        "def score_zn_predictions(ca_distances, cb_distances, angles, prob_map_3d, ca_bins, cb_bins, angle_bins):\n",
        "    ca_bin_indices = np.digitize(ca_distances, ca_bins) - 1\n",
        "    cb_bin_indices = np.digitize(cb_distances, cb_bins) - 1\n",
        "    angle_bin_indices = np.digitize(angles, angle_bins) - 1\n",
        "    probabilities = []\n",
        "    valid = True\n",
        "    for cbin, bbin, abin in zip(ca_bin_indices, cb_bin_indices, angle_bin_indices):\n",
        "        if 0 <= cbin < prob_map_3d.shape[0] and 0 <= bbin < prob_map_3d.shape[1] and 0 <= abin < prob_map_3d.shape[2]:\n",
        "            prob_value = prob_map_3d[cbin, bbin, abin]\n",
        "            if prob_value == 0:\n",
        "                valid = False\n",
        "                break\n",
        "            probabilities.append(prob_value)\n",
        "        else:\n",
        "            valid = False\n",
        "            break\n",
        "    final_score = np.prod(probabilities) if valid else None\n",
        "    return final_score\n",
        "\n",
        "# Function to calculate angles between Zn-Cα and Zn-Cβ vectors for each triplet\n",
        "def calculate_angles(zn_coords, ca_coords_triplet, cb_coords_triplet):\n",
        "    angles = []\n",
        "    for i in range(3):\n",
        "        v1 = ca_coords_triplet[i] - zn_coords\n",
        "        v2 = cb_coords_triplet[i] - zn_coords\n",
        "        cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
        "        angle = np.arccos(np.clip(cos_theta, -1.0, 1.0))\n",
        "        angles.append(np.degrees(angle))\n",
        "    return angles\n",
        "\n",
        "# Function to filter Zn candidates by distance thresholds\n",
        "def filter_by_distance_threshold(ca_coords, cb_coords, zn_candidates, ca_xyz, cb_xyz):\n",
        "    filtered_candidates = []\n",
        "    for zn_candidate in zn_candidates:\n",
        "        # Calculate distances to Cα and Cβ\n",
        "        ca_distances_calc = np.linalg.norm(zn_candidate - ca_coords, axis=1)\n",
        "        cb_distances_calc = np.linalg.norm(zn_candidate - cb_coords, axis=1)\n",
        "\n",
        "        # Calculate Zn-Cα/Zn-Cβ ratios\n",
        "        ratio = ca_distances_calc / cb_distances_calc\n",
        "\n",
        "        # Calculate angles\n",
        "        angles = np.array(calculate_angles(zn_candidate, ca_xyz, cb_xyz))\n",
        "\n",
        "        # Apply thresholds\n",
        "        if (np.all((thresholds['ca_distances_calc'][0] <= ca_distances_calc) & (ca_distances_calc <= thresholds['ca_distances_calc'][1])) and\n",
        "            np.all((thresholds['cb_distances_calc'][0] <= cb_distances_calc) & (cb_distances_calc <= thresholds['cb_distances_calc'][1])) and\n",
        "            np.all((thresholds['ratio'][0] <= ratio) & (ratio <= thresholds['ratio'][1]))):\n",
        "            filtered_candidates.append(zn_candidate)\n",
        "\n",
        "    return np.array(filtered_candidates)\n",
        "\n",
        "\n",
        "\n",
        "def define_excluded_triads(triad_residues, structure):\n",
        "    excluded_residues = set()\n",
        "    for _, residue_number in triad_residues:\n",
        "        for model in structure:\n",
        "            for chain in model:\n",
        "                for residue in chain:\n",
        "                    if residue.get_id()[1] == residue_number:\n",
        "                        excluded_residues.add((chain.id, residue.get_id()[1]))\n",
        "    return excluded_residues\n",
        "\n",
        "# Function to perform proximity filtering and record nearby amino acids\n",
        "def find_proximity_amino_acids(structure, zn_candidate, excluded_residues, exclusion_radius=2.5):\n",
        "    nearby_amino_acids = []\n",
        "\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            for residue in chain:\n",
        "                # Skip if the residue is in the excluded set\n",
        "                if (chain.id, residue.get_id()[1]) in excluded_residues:\n",
        "                    continue\n",
        "\n",
        "                for atom in residue:\n",
        "                    atom_coords = atom.coord\n",
        "                    distance_to_atom = np.linalg.norm(zn_candidate - atom_coords)\n",
        "                    if distance_to_atom < exclusion_radius:\n",
        "                        nearby_amino_acids.append({\n",
        "                            'Chain_ID': chain.id,\n",
        "                            'Residue_Number': residue.get_id()[1],\n",
        "                            'Residue_Name': residue.get_resname(),\n",
        "                            'Atom_Name': atom.get_name(),\n",
        "                            'Distance_to_Zn': distance_to_atom\n",
        "                        })\n",
        "                        break  # Log only once per residue within radius\n",
        "    return nearby_amino_acids\n",
        "def define_excluded_triads(triad_residues, structure):\n",
        "    excluded_residues = set()\n",
        "    for _, residue_number in triad_residues:\n",
        "        for model in structure:\n",
        "            for chain in model:\n",
        "                for residue in chain:\n",
        "                    if residue.get_id()[1] == residue_number:\n",
        "                        excluded_residues.add((chain.id, residue.get_id()[1]))\n",
        "    return excluded_residues\n",
        "# Function for proximity filtering with explicit exclusion of defined triads\n",
        "def proximity_filter(structure, zn_candidate, excluded_residues, exclusion_radius=2.5):\n",
        "    \"\"\"\n",
        "    Perform proximity filtering, excluding residues with the same residue number across chains.\n",
        "    \"\"\"\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            for residue in chain:\n",
        "                chain_id = chain.id\n",
        "                residue_number = residue.get_id()[1]  # Residue sequence number\n",
        "\n",
        "                # Skip residues if they match any in the exclusion set\n",
        "                if (chain_id, residue_number) in excluded_residues:\n",
        "                    continue\n",
        "\n",
        "                for atom in residue:\n",
        "                    atom_coords = atom.coord\n",
        "                    distance_to_atom = np.linalg.norm(zn_candidate - atom_coords)\n",
        "                    if distance_to_atom < exclusion_radius:\n",
        "                        return False  # Invalid candidate due to proximity to excluded residue\n",
        "\n",
        "    return True\n",
        "\n",
        "# Main function to estimate Zn candidates with precise boundary handling from Excel\n",
        "def estimate_zn_iterative(ca_coords, cb_coords, prob_map_3d, ca_bins, cb_bins, angle_bins, pdb_directory, grid_resolution=0.2):\n",
        "    # Extract thresholds from the DataFrame\n",
        "    thresholds = {}\n",
        "    for _, row in thresholds_df.iterrows():\n",
        "        parameter = row['Parameter']\n",
        "        min_value = row['Min']\n",
        "        max_value = row['Max']\n",
        "        if pd.notna(min_value) and pd.notna(max_value):\n",
        "            thresholds[parameter] = (min_value, max_value)\n",
        "\n",
        "    required_keys = ['ca_distances_calc', 'cb_distances_calc', 'ratio', 'angle']\n",
        "\n",
        "    for key in required_keys:\n",
        "        if key not in thresholds:\n",
        "            raise KeyError(f\"Missing key '{key}' in thresholds file.\")\n",
        "\n",
        "    zn_coords_list = []\n",
        "    best_scores = []\n",
        "    angle_list = []\n",
        "    proximity_data = []  # Store proximity information for each valid Zn candidate\n",
        "\n",
        "    for i in range(len(ca_coords)):\n",
        "        entry_id = df_alanine['PDB_ID'][i]\n",
        "        structure = load_pdb_structure(entry_id, pdb_directory)\n",
        "\n",
        "        # Extract and reshape Cα and Cβ coordinates\n",
        "        ca_xyz = ca_coords.iloc[i].values.reshape(3, 3)\n",
        "        cb_xyz = cb_coords.iloc[i].values.reshape(3, 3)\n",
        "\n",
        "        # Define triad residues (ignoring chain IDs initially)\n",
        "        triad_residues = [\n",
        "            (None, df_alanine.at[i, 'Coord_residue_number1']),\n",
        "            (None, df_alanine.at[i, 'Coord_residue_number2']),\n",
        "            (None, df_alanine.at[i, 'Coord_residue_number3'])\n",
        "        ]\n",
        "\n",
        "        # Define excluded residues considering all chains with the same residue numbers\n",
        "        excluded_residues = define_excluded_triads(triad_residues, structure)\n",
        "\n",
        "        # Initialize shared region boundaries\n",
        "        shared_x_min = -np.inf\n",
        "        shared_x_max = np.inf\n",
        "        shared_y_min = -np.inf\n",
        "        shared_y_max = np.inf\n",
        "        shared_z_min = -np.inf\n",
        "        shared_z_max = np.inf\n",
        "\n",
        "        # Define inner and outer box boundaries from thresholds\n",
        "        inner_boxes = []\n",
        "        for j in range(3):\n",
        "            x_min_inner = min(ca_xyz[j, 0], cb_xyz[j, 0]) - thresholds['ca_distances_calc'][0]\n",
        "            x_max_inner = max(ca_xyz[j, 0], cb_xyz[j, 0]) + thresholds['ca_distances_calc'][0]\n",
        "\n",
        "            y_min_inner = min(ca_xyz[j, 1], cb_xyz[j, 1]) - thresholds['cb_distances_calc'][0]\n",
        "            y_max_inner = max(ca_xyz[j, 1], cb_xyz[j, 1]) + thresholds['cb_distances_calc'][0]\n",
        "\n",
        "            z_min_inner = min(ca_xyz[j, 2], cb_xyz[j, 2]) - thresholds['ca_distances_calc'][0]\n",
        "            z_max_inner = max(ca_xyz[j, 2], cb_xyz[j, 2]) + thresholds['ca_distances_calc'][0]\n",
        "\n",
        "            inner_boxes.append((x_min_inner, x_max_inner, y_min_inner, y_max_inner, z_min_inner, z_max_inner))\n",
        "\n",
        "            x_min_outer = min(ca_xyz[j, 0], cb_xyz[j, 0]) - thresholds['ca_distances_calc'][1]\n",
        "            x_max_outer = max(ca_xyz[j, 0], cb_xyz[j, 0]) + thresholds['ca_distances_calc'][1]\n",
        "\n",
        "            y_min_outer = min(ca_xyz[j, 1], cb_xyz[j, 1]) - thresholds['cb_distances_calc'][1]\n",
        "            y_max_outer = max(ca_xyz[j, 1], cb_xyz[j, 1]) + thresholds['cb_distances_calc'][1]\n",
        "\n",
        "            z_min_outer = min(ca_xyz[j, 2], cb_xyz[j, 2]) - thresholds['ca_distances_calc'][1]\n",
        "            z_max_outer = max(ca_xyz[j, 2], cb_xyz[j, 2]) + thresholds['ca_distances_calc'][1]\n",
        "\n",
        "            # Update shared region with intersection\n",
        "            shared_x_min = max(shared_x_min, x_min_outer - grid_resolution)\n",
        "            shared_x_max = min(shared_x_max, x_max_outer + grid_resolution)\n",
        "            shared_y_min = max(shared_y_min, y_min_outer - grid_resolution)\n",
        "            shared_y_max = min(shared_y_max, y_max_outer + grid_resolution)\n",
        "            shared_z_min = max(shared_z_min, z_min_outer - grid_resolution)\n",
        "            shared_z_max = min(shared_z_max, z_max_outer + grid_resolution)\n",
        "\n",
        "        # Ensure valid search space exists\n",
        "        if shared_x_min >= shared_x_max or shared_y_min >= shared_y_max or shared_z_min >= shared_z_max:\n",
        "            print(f\"No shared search space for Entry {i}: {entry_id}\")\n",
        "            zn_coords_list.append(\"no metal\")\n",
        "            best_scores.append(0)\n",
        "            angle_list.append([None, None, None])\n",
        "            continue\n",
        "\n",
        "        # Debug print for shared search region\n",
        "        print(f\"Shared Region for Entry {i}: {entry_id}\")\n",
        "        print(f\"x_min: {shared_x_min}, x_max: {shared_x_max}\")\n",
        "        print(f\"y_min: {shared_y_min}, y_max: {shared_y_max}\")\n",
        "        print(f\"z_min: {shared_z_min}, z_max: {shared_z_max}\")\n",
        "\n",
        "        # Generate Zn candidates grid within the shared region excluding inner boxes\n",
        "        zn_candidates = []\n",
        "        total_grid_points = 0\n",
        "        distance_valid_points = 0\n",
        "        angle_valid_points = 0\n",
        "        ratio_valid_points = 0\n",
        "        probability_valid_points = 0\n",
        "\n",
        "        # First find shared region with coarse grid\n",
        "        shared_region_found = False\n",
        "        if shared_x_min < shared_x_max and shared_y_min < shared_y_max and shared_z_min < shared_z_max:\n",
        "            shared_region_found = True\n",
        "\n",
        "                # If shared region exists, search with finer grid\n",
        "        if shared_region_found:\n",
        "            grid_resolution = 0.2  # Use the input parameter\n",
        "            total_grid_points = 0\n",
        "            distance_valid_points = 0\n",
        "            angle_valid_points = 0\n",
        "            ratio_valid_points = 0  # Renamed for clarity\n",
        "            probability_valid_points = 0\n",
        "            valid_points = []\n",
        "            all_scores = []\n",
        "\n",
        "            for x in np.arange(shared_x_min, shared_x_max + 1e-8, grid_resolution):\n",
        "                for y in np.arange(shared_y_min, shared_y_max + 1e-8, grid_resolution):\n",
        "                    for z in np.arange(shared_z_min, shared_z_max + 1e-8, grid_resolution):\n",
        "                        total_grid_points += 1\n",
        "\n",
        "                        # Check both corner and center points\n",
        "                        corner_point = np.array([x, y, z])\n",
        "                        center_point = np.array([\n",
        "                            x + grid_resolution/2,\n",
        "                            y + grid_resolution/2,\n",
        "                            z + grid_resolution/2\n",
        "                        ])\n",
        "\n",
        "                        for point in [corner_point, center_point]:\n",
        "                            # Distance check\n",
        "                            distances_ca = np.linalg.norm(ca_xyz - point, axis=1)\n",
        "                            distances_cb = np.linalg.norm(cb_xyz - point, axis=1)\n",
        "\n",
        "                            distance_condition = (np.all((thresholds['ca_distances_calc'][0] <= distances_ca) &\n",
        "                                                       (distances_ca <= thresholds['ca_distances_calc'][1])) and\n",
        "                                               np.all((thresholds['cb_distances_calc'][0] <= distances_cb) &\n",
        "                                                       (distances_cb <= thresholds['cb_distances_calc'][1])))\n",
        "\n",
        "                            if distance_condition:\n",
        "                                distance_valid_points += 1\n",
        "\n",
        "                                # Calculate angles\n",
        "                                angles = calculate_angles(point, ca_xyz, cb_xyz)\n",
        "                                angle_condition = all(thresholds['angle'][0] <= angle <= thresholds['angle'][1]\n",
        "                                                   for angle in angles)\n",
        "\n",
        "                                if angle_condition:\n",
        "                                    angle_valid_points += 1\n",
        "\n",
        "                                    # Calculate ratios\n",
        "                                    ratios = calculate_ratio(point, ca_xyz, cb_xyz)\n",
        "                                    ratio_condition = np.all((thresholds['ratio'][0] <= ratios) &\n",
        "                                                           (ratios <= thresholds['ratio'][1]))\n",
        "\n",
        "                                    if ratio_condition:\n",
        "                                        ratio_valid_points += 1  # Only increment if ratio check passes\n",
        "\n",
        "                                        # Calculate probability score\n",
        "                                        score = score_zn_predictions(\n",
        "                                            distances_ca,\n",
        "                                            distances_cb,\n",
        "                                            angles,\n",
        "                                            prob_map_3d, ca_bins, cb_bins, angle_bins)\n",
        "\n",
        "                                        if score is not None and score > 0:\n",
        "                                            probability_valid_points += 1  # Only increment if probability check passes\n",
        "                                            valid_points.append(point)\n",
        "                                            all_scores.append(score)\n",
        "                                            zn_candidates.append([x, y, z])\n",
        "\n",
        "            # Print filtering statistics\n",
        "            print(f\"Total grid points searched: {total_grid_points}\")\n",
        "            print(f\"Points passing distance criteria: {distance_valid_points}\")\n",
        "            print(f\"Points passing angle criteria: {angle_valid_points}\")\n",
        "            print(f\"Points passing ratio criteria: {ratio_valid_points}\")\n",
        "            print(f\"Points passing probability criteria: {probability_valid_points}\")\n",
        "\n",
        "        zn_candidates = np.array(zn_candidates)\n",
        "\n",
        "        # Filter Zn candidates by distance and proximity\n",
        "        distance_filtered_candidates = filter_by_distance_threshold(ca_xyz, cb_xyz, zn_candidates, ca_xyz, cb_xyz)\n",
        "\n",
        "        for zn_candidate in distance_filtered_candidates:\n",
        "            angles = calculate_angles(zn_candidate, ca_xyz, cb_xyz)\n",
        "            if any(angle > thresholds['angle'][1] or angle < thresholds['angle'][0] for angle in angles):\n",
        "                continue\n",
        "\n",
        "            score = score_zn_predictions(\n",
        "                np.linalg.norm(zn_candidate - ca_xyz, axis=1),\n",
        "                np.linalg.norm(zn_candidate - cb_xyz, axis=1),\n",
        "                angles,\n",
        "                prob_map_3d, ca_bins, cb_bins, angle_bins\n",
        "            )\n",
        "\n",
        "            if score is not None and score > 0:\n",
        "                valid = proximity_filter(structure, zn_candidate, excluded_residues)\n",
        "                if valid:\n",
        "                    zn_coords_list.append(zn_candidate)\n",
        "                    best_scores.append(score)\n",
        "                    angle_list.append(angles)\n",
        "                    break\n",
        "\n",
        "        if len(zn_coords_list) <= i:\n",
        "            zn_coords_list.append(\"no metal\")\n",
        "            best_scores.append(0)\n",
        "            angle_list.append([None, None, None])\n",
        "\n",
        "    return zn_coords_list, best_scores, angle_list, proximity_data\n",
        "\n",
        "\n",
        "# Define coordinates for Zn estimation and specify PDB directory\n",
        "ca_coords = df_alanine[['CA1_X', 'CA1_Y', 'CA1_Z', 'CA2_X', 'CA2_Y', 'CA2_Z', 'CA3_X', 'CA3_Y', 'CA3_Z']]\n",
        "cb_coords = df_alanine[['CB1_X', 'CB1_Y', 'CB1_Z', 'CB2_X', 'CB2_Y', 'CB2_Z', 'CB3_X', 'CB3_Y', 'CB3_Z']]\n",
        "pdb_directory = '/content/3p43_alanine.pdb'  # Replace with actual path to PDB files\n",
        "\n",
        "# Run Zn estimation with grid generation, scoring, and iterative proximity filtering\n",
        "estimated_zn_coords_grid, zn_scores, angles_list, proximity_data = estimate_zn_iterative(\n",
        "    ca_coords, cb_coords, prob_map_3d, ca_bins, cb_bins, angle_bins, pdb_directory, grid_resolution=0.2\n",
        ")\n",
        "\n",
        "# After calculating Zn coordinates, scores, and angles\n",
        "df_alanine['Zn_X_Grid'] = [coords[0] if not isinstance(coords, str) else None for coords in estimated_zn_coords_grid]\n",
        "df_alanine['Zn_Y_Grid'] = [coords[1] if not isinstance(coords, str) else None for coords in estimated_zn_coords_grid]\n",
        "df_alanine['Zn_Z_Grid'] = [coords[2] if not isinstance(coords, str) else None for coords in estimated_zn_coords_grid]\n",
        "df_alanine['Zn_Score'] = zn_scores\n",
        "df_alanine['Angle_1'], df_alanine['Angle_2'], df_alanine['Angle_3'] = zip(*angles_list)\n",
        "\n",
        "# Remove rows where Zn_Score is 0\n",
        "df_alanine = df_alanine[df_alanine['Zn_Score'] != 0]\n",
        "\n",
        "# @markdown ### Save the Filtered DataFrame to an Excel File\n",
        "output_file_path = '/content/3ttis_coordinates_1_result.xlsx'  # @param {type:\"string\"}\n",
        "df_alanine.to_excel(output_file_path, index=False)\n",
        "# @markdown **Filtered Zn coordinates, scores, and angles saved.**\n",
        "print(f\"Filtered Zn coordinates, scores, and angles saved to '{output_file_path}'\")\n",
        "\n",
        "# @markdown ### Save the Proximity Information to an Excel File\n",
        "df_proximity = pd.DataFrame(proximity_data)\n",
        "output_proximity_file = '/content/test_proximity3.xlsx' # @param {type:\"string\"}\n",
        "df_proximity.to_excel(output_proximity_file, index=False)\n",
        "# @markdown **Proximity amino acid details saved.**\n",
        "print(f\"Proximity amino acid details saved to '{output_proximity_file}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8VwAlZ7nSEw",
        "outputId": "a770bd89-9ee5-4261-b83b-c26661487459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyMOL script saved to /content/3tis_final.pml\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from Bio.PDB import PDBParser\n",
        "import requests\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 5: Analysis the result (Apply to the PDB file)\n",
        "\n",
        "# Load input file\n",
        "input_file_path = \"/content/3ttis_coordinates_1_result.xlsx\" # @param {type:\"string\"}\n",
        "df_new = pd.read_excel(input_file_path)\n",
        "\n",
        "# Generate PyMOL script file\n",
        "pymol_script_commands = []\n",
        "df_new['Combination_Number'] = range(1, len(df_new) + 1)\n",
        "\n",
        "# Generate the PyMOL script for both valid and invalid Zn binding forms\n",
        "for index, row in df_new.iterrows():\n",
        "    # Retrieve chain and residue information\n",
        "    chain1, res1 = row['Coord_chain_id_number1'], row['Coord_residue_number1']\n",
        "    chain2, res2 = row['Coord_chain_id_number2'], row['Coord_residue_number2']\n",
        "    chain3, res3 = row['Coord_chain_id_number3'], row['Coord_residue_number3']\n",
        "\n",
        "    # Retrieve Zn coordinates\n",
        "    zn_x, zn_y, zn_z = row['Zn_X_Grid'], row['Zn_Y_Grid'], row['Zn_Z_Grid']\n",
        "\n",
        "    selection_name = f\"obj{row['Combination_Number']:02d}\"\n",
        "\n",
        "    # Select the residues\n",
        "    pymol_script_commands.append(f\"select {selection_name}, (chain {chain1} and resi {res1}) or (chain {chain2} and resi {res2}) or (chain {chain3} and resi {res3})\")\n",
        "\n",
        "    # Create the objects for the residues\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue1, /{row['PDB_ID']}//{chain1}/{res1}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue2, /{row['PDB_ID']}//{chain2}/{res2}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue3, /{row['PDB_ID']}//{chain3}/{res3}\")\n",
        "\n",
        "    # Check if Zn coordinates are available\n",
        "    if not pd.isna(zn_x) and not pd.isna(zn_y) and not pd.isna(zn_z):\n",
        "        # Zn coordinates are present, add the Zn pseudoatom\n",
        "        zn_name = f\"{selection_name}_Metal\"\n",
        "        pymol_script_commands.append(f\"pseudoatom {zn_name}, pos=[{zn_x}, {zn_y}, {zn_z}], elem=Metal, name={zn_name}\")\n",
        "        pymol_script_commands.append(f\"show sphere, {zn_name}\")\n",
        "    else:\n",
        "        # Zn coordinates are missing, mark this combination as non-binding\n",
        "        pymol_script_commands.append(f\"# {selection_name} does not bind Zn\")\n",
        "\n",
        "# Save the commands into a PyMOL script\n",
        "pymol_script_file = \"/content/3tis_final.pml\" # @param {type:\"string\"}\n",
        "with open(pymol_script_file, 'w') as f:\n",
        "    f.write(\"# PyMOL script for visualizing both Zn-binding and non-binding residue combinations\\n\\n\")\n",
        "    for command in pymol_script_commands:\n",
        "        f.write(command + '\\n')\n",
        "\n",
        "print(f\"PyMOL script saved to {pymol_script_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kU_wIAFoS_Yk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e36139c4-9315-4f5c-dcf5-8afe332c330a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved at: /content/3ttis_coordinates_1_result_residue_count.xlsx\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 5: Analysis the result (Sort the result based on the metal-ligating ligands)\n",
        "\n",
        "\n",
        "# Load the provided Excel file\n",
        "file_path = '/content/3ttis_coordinates_1_result.xlsx' # @param {type:\"string\"}\n",
        "excel_data = pd.ExcelFile(file_path)\n",
        "\n",
        "# Load the data from the first sheet\n",
        "df = excel_data.parse('Sheet1')\n",
        "\n",
        "# Define function to count specific residues in the 'Combination' column\n",
        "def count_residues(row):\n",
        "    # Count occurrences of specific residue names in the 'Combination' column\n",
        "    residue_names = ['HIS', 'CYS', 'GLU', 'ASP']\n",
        "    count = sum(row['Combination'].count(residue) for residue in residue_names)\n",
        "    return count\n",
        "\n",
        "# Apply the function to each row and store the result in a new column 'Residue_Count'\n",
        "df['Residue_Count'] = df.apply(count_residues, axis=1)\n",
        "\n",
        "# Split the data based on the count of residues and save to separate sheets in a new Excel file\n",
        "output_file_path = '/content/3ttis_coordinates_1_result_residue_count.xlsx'  # @param {type:\"string\"}\n",
        "with pd.ExcelWriter(output_file_path) as writer:\n",
        "    for count in df['Residue_Count'].unique():\n",
        "        df_filtered = df[df['Residue_Count'] == count]\n",
        "        df_filtered.to_excel(writer, sheet_name=f'Residue_Count_{count}', index=False)\n",
        "\n",
        "print(\"File saved at:\", output_file_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}