{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "b0YnbjBDl3zq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08401c8c-5a48-42a1-aea7-b423c41dba3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.26.4)\n",
            "Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: biopython\n",
            "Successfully installed biopython-1.84\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.6\n",
            "    Uninstalling tqdm-4.66.6:\n",
            "      Successfully uninstalled tqdm-4.66.6\n",
            "Successfully installed tqdm-4.67.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apbs apbs-data freeglut3 libapbs3 libevdev2 libglu1-mesa libgudev-1.0-0 libinput-bin libinput10\n",
            "  libmaloc1 libmd4c0 libmtdev1 libqt5core5a libqt5dbus5 libqt5designer5 libqt5gui5 libqt5help5\n",
            "  libqt5network5 libqt5opengl5 libqt5printsupport5 libqt5sql5 libqt5sql5-sqlite libqt5svg5\n",
            "  libqt5test5 libqt5widgets5 libqt5xml5 libwacom-bin libwacom-common libwacom9 libxcb-icccm4\n",
            "  libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1 libxcb-xinerama0 libxcb-xinput0\n",
            "  libxcb-xkb1 libxkbcommon-x11-0 pymol-data python3-numpy python3-opengl python3-pymol\n",
            "  python3-pyqt5 python3-pyqt5.qtopengl python3-pyqt5.sip qt5-gtk-platformtheme qttranslations5-l10n\n",
            "Suggested packages:\n",
            "  qt5-image-formats-plugins qtwayland5 python-numpy-doc python3-pytest libgle3\n",
            "The following NEW packages will be installed:\n",
            "  apbs apbs-data freeglut3 libapbs3 libevdev2 libglu1-mesa libgudev-1.0-0 libinput-bin libinput10\n",
            "  libmaloc1 libmd4c0 libmtdev1 libqt5core5a libqt5dbus5 libqt5designer5 libqt5gui5 libqt5help5\n",
            "  libqt5network5 libqt5opengl5 libqt5printsupport5 libqt5sql5 libqt5sql5-sqlite libqt5svg5\n",
            "  libqt5test5 libqt5widgets5 libqt5xml5 libwacom-bin libwacom-common libwacom9 libxcb-icccm4\n",
            "  libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1 libxcb-xinerama0 libxcb-xinput0\n",
            "  libxcb-xkb1 libxkbcommon-x11-0 pymol pymol-data python3-numpy python3-opengl python3-pymol\n",
            "  python3-pyqt5 python3-pyqt5.qtopengl python3-pyqt5.sip qt5-gtk-platformtheme qttranslations5-l10n\n",
            "0 upgraded, 48 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 259 MB of archives.\n",
            "After this operation, 1,335 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5core5a amd64 5.15.3+dfsg-2ubuntu0.2 [2,006 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libevdev2 amd64 1.12.1+dfsg-1 [39.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmtdev1 amd64 1.1.6-1build4 [14.5 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgudev-1.0-0 amd64 1:237-2build1 [16.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-common all 2.2.0-1 [54.3 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom9 amd64 2.2.0-1 [22.0 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput-bin amd64 1.20.0-1ubuntu0.3 [19.9 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput10 amd64 1.20.0-1ubuntu0.3 [131 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmd4c0 amd64 0.4.8-1 [42.0 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5dbus5 amd64 5.15.3+dfsg-2ubuntu0.2 [222 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5network5 amd64 5.15.3+dfsg-2ubuntu0.2 [731 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5gui5 amd64 5.15.3+dfsg-2ubuntu0.2 [3,722 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5widgets5 amd64 5.15.3+dfsg-2ubuntu0.2 [2,561 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5svg5 amd64 5.15.3-1 [149 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/universe amd64 apbs-data all 3.0.0+dfsg1-3build2 [230 MB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmaloc1 amd64 1.5-1 [81.4 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libapbs3 amd64 3.0.0+dfsg1-3build2 [263 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/universe amd64 apbs amd64 3.0.0+dfsg1-3build2 [83.8 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5xml5 amd64 5.15.3+dfsg-2ubuntu0.2 [124 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5designer5 amd64 5.15.3-1 [2,832 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5sql5 amd64 5.15.3+dfsg-2ubuntu0.2 [123 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5help5 amd64 5.15.3-1 [162 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5opengl5 amd64 5.15.3+dfsg-2ubuntu0.2 [153 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5printsupport5 amd64 5.15.3+dfsg-2ubuntu0.2 [214 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5sql5-sqlite amd64 5.15.3+dfsg-2ubuntu0.2 [53.0 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5test5 amd64 5.15.3+dfsg-2ubuntu0.2 [152 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-bin amd64 2.2.0-1 [13.6 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-numpy amd64 1:1.21.5-1ubuntu22.04.1 [3,467 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-opengl all 3.1.5+dfsg-1 [605 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-pyqt5.sip amd64 12.9.1-1build1 [61.1 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-pyqt5 amd64 5.15.6+dfsg-1ubuntu3 [2,822 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-pyqt5.qtopengl amd64 5.15.6+dfsg-1ubuntu3 [134 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pymol-data all 2.5.0+dfsg-1build1 [1,376 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-pymol amd64 2.5.0+dfsg-1build1 [3,958 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pymol all 2.5.0+dfsg-1build1 [127 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 qt5-gtk-platformtheme amd64 5.15.3+dfsg-2ubuntu0.2 [130 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qttranslations5-l10n all 5.15.3-1 [1,983 kB]\n",
            "Fetched 259 MB in 19s (13.9 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package libqt5core5a:amd64.\n",
            "(Reading database ... 123633 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libqt5core5a_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libevdev2:amd64.\n",
            "Preparing to unpack .../01-libevdev2_1.12.1+dfsg-1_amd64.deb ...\n",
            "Unpacking libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Selecting previously unselected package libmtdev1:amd64.\n",
            "Preparing to unpack .../02-libmtdev1_1.1.6-1build4_amd64.deb ...\n",
            "Unpacking libmtdev1:amd64 (1.1.6-1build4) ...\n",
            "Selecting previously unselected package libgudev-1.0-0:amd64.\n",
            "Preparing to unpack .../03-libgudev-1.0-0_1%3a237-2build1_amd64.deb ...\n",
            "Unpacking libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Selecting previously unselected package libwacom-common.\n",
            "Preparing to unpack .../04-libwacom-common_2.2.0-1_all.deb ...\n",
            "Unpacking libwacom-common (2.2.0-1) ...\n",
            "Selecting previously unselected package libwacom9:amd64.\n",
            "Preparing to unpack .../05-libwacom9_2.2.0-1_amd64.deb ...\n",
            "Unpacking libwacom9:amd64 (2.2.0-1) ...\n",
            "Selecting previously unselected package libinput-bin.\n",
            "Preparing to unpack .../06-libinput-bin_1.20.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libinput-bin (1.20.0-1ubuntu0.3) ...\n",
            "Selecting previously unselected package libinput10:amd64.\n",
            "Preparing to unpack .../07-libinput10_1.20.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n",
            "Selecting previously unselected package libmd4c0:amd64.\n",
            "Preparing to unpack .../08-libmd4c0_0.4.8-1_amd64.deb ...\n",
            "Unpacking libmd4c0:amd64 (0.4.8-1) ...\n",
            "Selecting previously unselected package libqt5dbus5:amd64.\n",
            "Preparing to unpack .../09-libqt5dbus5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5network5:amd64.\n",
            "Preparing to unpack .../10-libqt5network5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libxcb-icccm4:amd64.\n",
            "Preparing to unpack .../11-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n",
            "Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Selecting previously unselected package libxcb-util1:amd64.\n",
            "Preparing to unpack .../12-libxcb-util1_0.4.0-1build2_amd64.deb ...\n",
            "Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Selecting previously unselected package libxcb-image0:amd64.\n",
            "Preparing to unpack .../13-libxcb-image0_0.4.0-2_amd64.deb ...\n",
            "Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Selecting previously unselected package libxcb-keysyms1:amd64.\n",
            "Preparing to unpack .../14-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n",
            "Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Selecting previously unselected package libxcb-render-util0:amd64.\n",
            "Preparing to unpack .../15-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n",
            "Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Selecting previously unselected package libxcb-xinerama0:amd64.\n",
            "Preparing to unpack .../16-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xinput0:amd64.\n",
            "Preparing to unpack .../17-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xkb1:amd64.\n",
            "Preparing to unpack .../18-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxkbcommon-x11-0:amd64.\n",
            "Preparing to unpack .../19-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n",
            "Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libqt5gui5:amd64.\n",
            "Preparing to unpack .../20-libqt5gui5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5widgets5:amd64.\n",
            "Preparing to unpack .../21-libqt5widgets5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5svg5:amd64.\n",
            "Preparing to unpack .../22-libqt5svg5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5svg5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package apbs-data.\n",
            "Preparing to unpack .../23-apbs-data_3.0.0+dfsg1-3build2_all.deb ...\n",
            "Unpacking apbs-data (3.0.0+dfsg1-3build2) ...\n",
            "Selecting previously unselected package libmaloc1.\n",
            "Preparing to unpack .../24-libmaloc1_1.5-1_amd64.deb ...\n",
            "Unpacking libmaloc1 (1.5-1) ...\n",
            "Selecting previously unselected package libapbs3:amd64.\n",
            "Preparing to unpack .../25-libapbs3_3.0.0+dfsg1-3build2_amd64.deb ...\n",
            "Unpacking libapbs3:amd64 (3.0.0+dfsg1-3build2) ...\n",
            "Selecting previously unselected package apbs.\n",
            "Preparing to unpack .../26-apbs_3.0.0+dfsg1-3build2_amd64.deb ...\n",
            "Unpacking apbs (3.0.0+dfsg1-3build2) ...\n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "Preparing to unpack .../27-freeglut3_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libqt5xml5:amd64.\n",
            "Preparing to unpack .../28-libqt5xml5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5xml5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5designer5:amd64.\n",
            "Preparing to unpack .../29-libqt5designer5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5designer5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package libqt5sql5:amd64.\n",
            "Preparing to unpack .../30-libqt5sql5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5sql5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5help5:amd64.\n",
            "Preparing to unpack .../31-libqt5help5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5help5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package libqt5opengl5:amd64.\n",
            "Preparing to unpack .../32-libqt5opengl5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5opengl5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5printsupport5:amd64.\n",
            "Preparing to unpack .../33-libqt5printsupport5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5printsupport5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5sql5-sqlite:amd64.\n",
            "Preparing to unpack .../34-libqt5sql5-sqlite_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5sql5-sqlite:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5test5:amd64.\n",
            "Preparing to unpack .../35-libqt5test5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5test5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libwacom-bin.\n",
            "Preparing to unpack .../36-libwacom-bin_2.2.0-1_amd64.deb ...\n",
            "Unpacking libwacom-bin (2.2.0-1) ...\n",
            "Selecting previously unselected package python3-numpy.\n",
            "Preparing to unpack .../37-python3-numpy_1%3a1.21.5-1ubuntu22.04.1_amd64.deb ...\n",
            "Unpacking python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../38-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package python3-opengl.\n",
            "Preparing to unpack .../39-python3-opengl_3.1.5+dfsg-1_all.deb ...\n",
            "Unpacking python3-opengl (3.1.5+dfsg-1) ...\n",
            "Selecting previously unselected package python3-pyqt5.sip.\n",
            "Preparing to unpack .../40-python3-pyqt5.sip_12.9.1-1build1_amd64.deb ...\n",
            "Unpacking python3-pyqt5.sip (12.9.1-1build1) ...\n",
            "Selecting previously unselected package python3-pyqt5.\n",
            "Preparing to unpack .../41-python3-pyqt5_5.15.6+dfsg-1ubuntu3_amd64.deb ...\n",
            "Unpacking python3-pyqt5 (5.15.6+dfsg-1ubuntu3) ...\n",
            "Selecting previously unselected package python3-pyqt5.qtopengl.\n",
            "Preparing to unpack .../42-python3-pyqt5.qtopengl_5.15.6+dfsg-1ubuntu3_amd64.deb ...\n",
            "Unpacking python3-pyqt5.qtopengl (5.15.6+dfsg-1ubuntu3) ...\n",
            "Selecting previously unselected package pymol-data.\n",
            "Preparing to unpack .../43-pymol-data_2.5.0+dfsg-1build1_all.deb ...\n",
            "Unpacking pymol-data (2.5.0+dfsg-1build1) ...\n",
            "Selecting previously unselected package python3-pymol.\n",
            "Preparing to unpack .../44-python3-pymol_2.5.0+dfsg-1build1_amd64.deb ...\n",
            "Unpacking python3-pymol (2.5.0+dfsg-1build1) ...\n",
            "Selecting previously unselected package pymol.\n",
            "Preparing to unpack .../45-pymol_2.5.0+dfsg-1build1_all.deb ...\n",
            "Unpacking pymol (2.5.0+dfsg-1build1) ...\n",
            "Selecting previously unselected package qt5-gtk-platformtheme:amd64.\n",
            "Preparing to unpack .../46-qt5-gtk-platformtheme_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package qttranslations5-l10n.\n",
            "Preparing to unpack .../47-qttranslations5-l10n_5.15.3-1_all.deb ...\n",
            "Unpacking qttranslations5-l10n (5.15.3-1) ...\n",
            "Setting up libmaloc1 (1.5-1) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-6) ...\n",
            "Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Setting up libapbs3:amd64 (3.0.0+dfsg1-3build2) ...\n",
            "Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Setting up apbs-data (3.0.0+dfsg1-3build2) ...\n",
            "Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up qttranslations5-l10n (5.15.3-1) ...\n",
            "Setting up pymol-data (2.5.0+dfsg-1build1) ...\n",
            "Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Setting up libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up python3-numpy (1:1.21.5-1ubuntu22.04.1) ...\n",
            "Setting up libmtdev1:amd64 (1.1.6-1build4) ...\n",
            "Setting up python3-pyqt5.sip (12.9.1-1build1) ...\n",
            "Setting up libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up apbs (3.0.0+dfsg1-3build2) ...\n",
            "Setting up libmd4c0:amd64 (0.4.8-1) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up libqt5test5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Setting up libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Setting up libwacom-common (2.2.0-1) ...\n",
            "Setting up libwacom9:amd64 (2.2.0-1) ...\n",
            "Setting up python3-opengl (3.1.5+dfsg-1) ...\n",
            "Setting up libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libinput-bin (1.20.0-1ubuntu0.3) ...\n",
            "Setting up libqt5sql5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5xml5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libwacom-bin (2.2.0-1) ...\n",
            "Setting up libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n",
            "Setting up libqt5sql5-sqlite:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5help5:amd64 (5.15.3-1) ...\n",
            "Setting up qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5printsupport5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5opengl5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5designer5:amd64 (5.15.3-1) ...\n",
            "Setting up libqt5svg5:amd64 (5.15.3-1) ...\n",
            "Setting up python3-pyqt5 (5.15.6+dfsg-1ubuntu3) ...\n",
            "Setting up python3-pyqt5.qtopengl (5.15.6+dfsg-1ubuntu3) ...\n",
            "Setting up python3-pymol (2.5.0+dfsg-1build1) ...\n",
            "Setting up pymol (2.5.0+dfsg-1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @markdown # Step 1: Install all neccessary packages\n",
        "# Install all necessary packages\n",
        "!pip install biopython\n",
        "!pip install --upgrade tqdm\n",
        "!apt-get install -y pymol\n",
        "\n",
        "# Import necessary modules\n",
        "from Bio.PDB import PDBParser, Selection, NeighborSearch\n",
        "from Bio.PDB.Polypeptide import is_aa\n",
        "from tqdm import tqdm\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q3_F6_hbkUp"
      },
      "outputs": [],
      "source": [
        "#@markdown # Step 2: Mutate the glycine to alanine\n",
        "#@markdown Please remove all water molecules and ligands before run\n",
        "\n",
        "# Import the necessary modules\n",
        "import pymol2\n",
        "\n",
        "#@markdown **Note:** Specify the paths to the input and output PDB files below.\n",
        "\n",
        "#@markdown ### Enter the path to your input PDB file:\n",
        "pdb_file_path = \"/content/3p43.pdb\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Enter the path to your output PDB file:\n",
        "output_file_path = \"/content/3p43_alanine.pdb\"  #@param {type:\"string\"}\n",
        "\n",
        "# Create an instance of the PyMOL session\n",
        "with pymol2.PyMOL() as pymol:\n",
        "    # Initialize PyMOL\n",
        "    pymol.cmd.reinitialize()\n",
        "\n",
        "    # Load the structure file\n",
        "    pymol.cmd.load(pdb_file_path)\n",
        "\n",
        "    # Identify glycine residues\n",
        "    glycine_residues = pymol.cmd.get_model(\"resn GLY\").atom\n",
        "\n",
        "    # Loop through glycine residues\n",
        "    for atom in glycine_residues:\n",
        "        residue_num = atom.resi\n",
        "        chain = atom.chain\n",
        "        # Construct the selection string in the format \"resi X and chain Y\"\n",
        "        selection_str = f\"resi {residue_num} and chain {chain}\"\n",
        "        # Apply the mutation using the mutagenesis command\n",
        "        pymol.cmd.wizard(\"mutagenesis\")\n",
        "        pymol.cmd.refresh_wizard()\n",
        "        pymol.cmd.get_wizard().do_select(selection_str)\n",
        "        pymol.cmd.get_wizard().set_mode(\"ALA\")\n",
        "        pymol.cmd.get_wizard().apply()\n",
        "        pymol.cmd.delete(selection_str)  # Delete the original residue to avoid clashes\n",
        "\n",
        "    # Save the mutated structure\n",
        "    pymol.cmd.save(output_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr9mhfr9R5zm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# Existing imports and setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from Bio.PDB import PDBParser\n",
        "import itertools\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 3A: Run the Metal-Installer\n",
        "\n",
        "# Import the necessary modules\n",
        "import pymol2\n",
        "from IPython.display import display, Markdown\n",
        "import requests  # Required for downloading files from GitHub\n",
        "\n",
        "# @markdown **Note:** Specify the paths to the input and output files below.\n",
        "\n",
        "# @markdown ### Enter the path to your input PDB file:\n",
        "pdb_file = \"/content/1EP0_alanine_dimer.pdb\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Enter the path to your output Excel file:\n",
        "output_excel_file = \"/content/1EP0_alanine_dimer_2His_1Asp_Full.xlsx\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "# @markdown ### Enter the path to your PyMOL script file:\n",
        "pymol_script_file = \"/content/1EP0_alanine_dimer_2His_1Asp_Full.pml\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Set the metal type to use:\n",
        "Metal = 'Zn'  # @param [\"Zn\", \"Mn\", \"Cu\", \"Fe\"]\n",
        "\n",
        "# @markdown ### Select the combination type:\n",
        "# @markdown **Note:** 2His/1Cys is only available to Cu\n",
        "Combinations = '2His_1Asp'  # @param [\"3His\", \"2His_1Asp\", \"2His_1Glu\", \"2His_1Cys\"]\n",
        "\n",
        "# @markdown ### Choose a threshold for analysis:\n",
        "Range = '2'  # @param [\"1\", \"2\", \"3\", \"4\",\"5\"]\n",
        "\n",
        "# @markdown ### Specify the specific residue number (use 0 for no specific residue):\n",
        "specific_residue_number = 0  # @param {type:\"integer\"}\n",
        "\n",
        "# Additional code to construct the URL for thresholds based on user input and download the file\n",
        "\n",
        "# Base URL for the thresholds files on GitHub\n",
        "base_url = \"https://raw.githubusercontent.com/SNU-Songlab/Metal-Installer-code/main/Threshold\"\n",
        "\n",
        "# Construct the full URL based on user input\n",
        "thresholds_url = f\"{base_url}/{Metal}/{Combinations}/{Range}.xlsx\"\n",
        "\n",
        "# Define the local path to save the downloaded file\n",
        "thresholds_file = \"/content/thresholds.xlsx\"  # This path will be used throughout the script\n",
        "\n",
        "# Download the file from GitHub\n",
        "response = requests.get(thresholds_url)\n",
        "\n",
        "# Check if the request was successful and save the file\n",
        "if response.status_code == 200:\n",
        "    with open(thresholds_file, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f\"File downloaded successfully from {thresholds_url} and saved as {thresholds_file}\")\n",
        "else:\n",
        "    raise ValueError(f\"Failed to download file from {thresholds_url}. Status code: {response.status_code}\")\n",
        "\n",
        "# Load thresholds from the downloaded Excel file\n",
        "thresholds_df = pd.read_excel(thresholds_file, sheet_name='Sheet1')\n",
        "\n",
        "# Extract threshold values\n",
        "thresholds = {}\n",
        "for _, row in thresholds_df.iterrows():\n",
        "    parameter = row['Parameter']\n",
        "    min_value = row['Min']\n",
        "    max_value = row['Max']\n",
        "\n",
        "    if pd.notna(min_value) and pd.notna(max_value):\n",
        "        thresholds[parameter] = (min_value, max_value)\n",
        "\n",
        "# Assign threshold values\n",
        "alpha_distance_range = thresholds['alpha_distance_range']\n",
        "beta_distance_range = thresholds['beta_distance_range']\n",
        "ratio_threshold_range = thresholds['ratio_threshold_range']\n",
        "pie_threshold_range = thresholds['pie_threshold_range']\n",
        "\n",
        "# PDB Parser setup\n",
        "parser = PDBParser(QUIET=True)\n",
        "structure = parser.get_structure('protein', pdb_file)\n",
        "model = structure[0]\n",
        "residues = [residue for residue in model.get_residues() if residue.get_id()[0] == ' ']\n",
        "\n",
        "# Step 1: Filter combinations to include specific residue number if specified\n",
        "if specific_residue_number != 0:\n",
        "    combinations = [\n",
        "        comb for comb in itertools.combinations(residues, 3)\n",
        "        if any(res.get_id()[1] == specific_residue_number for res in comb)\n",
        "    ]\n",
        "else:\n",
        "    combinations = list(itertools.combinations(residues, 3))\n",
        "\n",
        "# Distance filter\n",
        "filtered_data_distances = []\n",
        "\n",
        "for idx, combination in enumerate(combinations):\n",
        "    alpha_distances, beta_distances = [], []\n",
        "\n",
        "    try:\n",
        "        for res1, res2 in itertools.combinations(combination, 2):\n",
        "            if res1.has_id('CA') and res2.has_id('CA'):\n",
        "                ca1, ca2 = res1['CA'].coord, res2['CA'].coord\n",
        "                alpha_distance = np.linalg.norm(ca1 - ca2)\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            if res1.has_id('CB') and res2.has_id('CB'):\n",
        "                cb1, cb2 = res1['CB'].coord, res2['CB'].coord\n",
        "                beta_distance = np.linalg.norm(cb1 - cb2)\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            if (alpha_distance_range[0] <= alpha_distance <= alpha_distance_range[1] and\n",
        "                    beta_distance_range[0] <= beta_distance <= beta_distance_range[1]):\n",
        "                alpha_distances.append(alpha_distance)\n",
        "                beta_distances.append(beta_distance)\n",
        "\n",
        "        if len(alpha_distances) >= 3 and len(beta_distances) >= 3:\n",
        "            filtered_data_distances.append({\n",
        "                'PDB_ID': pdb_file,\n",
        "                'Combination': combination,\n",
        "                'Coord_chain_id_number1': combination[0].get_full_id()[2],\n",
        "                'Coord_residue_number1': combination[0].get_full_id()[3][1],\n",
        "                'Coord_residue_name1': combination[0].get_resname(),\n",
        "                'Coord_atom_name1': 'CA',\n",
        "                'Coord_chain_id_number2': combination[1].get_full_id()[2],\n",
        "                'Coord_residue_number2': combination[1].get_full_id()[3][1],\n",
        "                'Coord_residue_name2': combination[1].get_resname(),\n",
        "                'Coord_atom_name2': 'CA',\n",
        "                'Coord_chain_id_number3': combination[2].get_full_id()[2],\n",
        "                'Coord_residue_number3': combination[2].get_full_id()[3][1],\n",
        "                'Coord_residue_name3': combination[2].get_resname(),\n",
        "                'Coord_atom_name3': 'CA',\n",
        "                'Alpha Distance 1': alpha_distances[0],\n",
        "                'Alpha Distance 2': alpha_distances[1],\n",
        "                'Alpha Distance 3': alpha_distances[2],\n",
        "                'Beta Distance 1': beta_distances[0],\n",
        "                'Beta Distance 2': beta_distances[1],\n",
        "                'Beta Distance 3': beta_distances[2]\n",
        "            })\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error processing combination {combination}: {e}\")\n",
        "\n",
        "# Create DataFrame for distances\n",
        "column_order = [\n",
        "    'PDB_ID',\n",
        "    'Combination',\n",
        "    'Coord_chain_id_number1', 'Coord_residue_number1', 'Coord_residue_name1', 'Coord_atom_name1',\n",
        "    'Coord_chain_id_number2', 'Coord_residue_number2', 'Coord_residue_name2', 'Coord_atom_name2',\n",
        "    'Coord_chain_id_number3', 'Coord_residue_number3', 'Coord_residue_name3', 'Coord_atom_name3',\n",
        "    'Alpha Distance 1', 'Alpha Distance 2', 'Alpha Distance 3',\n",
        "    'Beta Distance 1', 'Beta Distance 2', 'Beta Distance 3'\n",
        "]\n",
        "\n",
        "df_distances = pd.DataFrame(filtered_data_distances)\n",
        "df_distances = df_distances[column_order]\n",
        "\n",
        "# Ratio filter\n",
        "filtered_data_ratio = []\n",
        "\n",
        "for idx, row in df_distances.iterrows():\n",
        "    alpha_distances = [row['Alpha Distance 1'], row['Alpha Distance 2'], row['Alpha Distance 3']]\n",
        "    beta_distances = [row['Beta Distance 1'], row['Beta Distance 2'], row['Beta Distance 3']]\n",
        "\n",
        "    for i in range(3):\n",
        "        alpha_distance_i = alpha_distances[i]\n",
        "        beta_distance_i = beta_distances[i]\n",
        "        ratio = alpha_distance_i / beta_distance_i\n",
        "\n",
        "        if not (ratio_threshold_range[0] <= ratio <= ratio_threshold_range[1]):\n",
        "            break\n",
        "    else:\n",
        "        filtered_data_ratio.append(row)\n",
        "\n",
        "df_ratio = pd.DataFrame(filtered_data_ratio)\n",
        "df_ratio = df_ratio[column_order]\n",
        "\n",
        "\n",
        "# Pie filter\n",
        "def calculate_pie(vector1, vector2):\n",
        "    dot_product = np.dot(vector1, vector2)\n",
        "    magnitude_product = np.linalg.norm(vector1) * np.linalg.norm(vector2)\n",
        "    if magnitude_product == 0:\n",
        "        return np.nan\n",
        "    cosine_angle = dot_product / magnitude_product\n",
        "    cosine_angle = np.clip(cosine_angle, -1.0, 1.0)\n",
        "    return np.degrees(np.arccos(cosine_angle))\n",
        "\n",
        "def process_row(row):\n",
        "    pdb_file_path = pdb_file\n",
        "    if not os.path.isfile(pdb_file_path):\n",
        "        print(f\"PDB file not found: {pdb_file_path}\")\n",
        "        return [None, None, None]\n",
        "\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure('protein', pdb_file_path)\n",
        "    model = structure[0]\n",
        "\n",
        "    try:\n",
        "        residues = row['Combination']\n",
        "        print(f\"Residues loaded: {residues}\")\n",
        "\n",
        "        pies = []\n",
        "        pairs = [(0, 1), (0, 2), (1, 2)]\n",
        "\n",
        "        for i, j in pairs:\n",
        "            try:\n",
        "                CA1 = residues[i]['CA']\n",
        "                CA2 = residues[j]['CA']\n",
        "                CB1 = residues[i]['CB'] if 'CB' in residues[i] else CA1\n",
        "                CB2 = residues[j]['CB'] if 'CB' in residues[j] else CA2\n",
        "\n",
        "                vector_CA = CA2.coord - CA1.coord\n",
        "                vector_CB = CB2.coord - CB1.coord\n",
        "\n",
        "                angle = calculate_pie(vector_CA, vector_CB)\n",
        "                pies.append(angle)\n",
        "            except KeyError as e:\n",
        "                print(f\"KeyError for residues {residues[i]} and {residues[j]}: {e}\")\n",
        "                pies.append(None)\n",
        "\n",
        "        return pies\n",
        "    except KeyError as e:\n",
        "        print(f\"KeyError: {e}\")\n",
        "        return [None, None, None]\n",
        "\n",
        "pie_results = df_ratio.apply(process_row, axis=1, result_type='expand')\n",
        "df_ratio[['Pie_1_2', 'Pie_1_3', 'Pie_2_3']] = pie_results\n",
        "\n",
        "# Create filter columns based on pie thresholds\n",
        "for col in ['Pie_1_2', 'Pie_1_3', 'Pie_2_3']:\n",
        "    df_ratio[f'{col}_Filter'] = df_ratio.apply(lambda row: pie_threshold_range[0] < row[col] < pie_threshold_range[1] if pd.notnull(row[col]) else False, axis=1)\n",
        "\n",
        "df_ratio['Pie_Filter'] = df_ratio[[f'{col}_Filter' for col in ['Pie_1_2', 'Pie_1_3', 'Pie_2_3']]].all(axis=1)\n",
        "\n",
        "df_final_filter = df_ratio[df_ratio['Pie_Filter']]\n",
        "\n",
        "# Save all DataFrames into a single Excel file with different tabs\n",
        "with pd.ExcelWriter(output_excel_file) as writer:\n",
        "    df_distances.to_excel(writer, sheet_name='Distances', index=False)\n",
        "    df_ratio.to_excel(writer, sheet_name='Ratio', index=False)\n",
        "    df_final_filter.to_excel(writer, sheet_name='Pie', index=False)\n",
        "\n",
        "# Generate PyMOL script file\n",
        "pymol_script_commands = []\n",
        "df_final_filter['Combination_Number'] = range(1, len(df_final_filter) + 1)\n",
        "\n",
        "for index, row in df_final_filter.iterrows():\n",
        "    combination = row['Combination']\n",
        "    chain1, res1 = combination[0].get_full_id()[2], combination[0].get_full_id()[3][1]\n",
        "    chain2, res2 = combination[1].get_full_id()[2], combination[1].get_full_id()[3][1]\n",
        "    chain3, res3 = combination[2].get_full_id()[2], combination[2].get_full_id()[3][1]\n",
        "\n",
        "    selection_name = f\"obj{row['Combination_Number']:02d}\"\n",
        "    pymol_script_commands.append(f\"select {selection_name}, (chain {chain1} and resi {res1}) or (chain {chain2} and resi {res2}) or (chain {chain3} and resi {res3})\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue1, /{pdb_file}//{chain1}/{res1}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue2, /{pdb_file}//{chain2}/{res2}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue3, /{pdb_file}//{chain3}/{res3}\")\n",
        "\n",
        "with open(pymol_script_file, 'w') as f:\n",
        "    f.write(\"# PyMOL script for visualizing filtered residue combinations\\n\\n\")\n",
        "    for command in pymol_script_commands:\n",
        "        f.write(command + '\\n')\n",
        "\n",
        "print(f\"\\nResults saved to {output_excel_file}\")\n",
        "print(f\"PyMOL script saved to {pymol_script_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9GaAf8WM8ke",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# Existing imports and setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from Bio.PDB import PDBParser\n",
        "import itertools\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 3B: Run the Metal-Installer\n",
        "\n",
        "# Import the necessary modules\n",
        "import pymol2\n",
        "from IPython.display import display, Markdown\n",
        "import requests  # Required for downloading files from GitHub\n",
        "\n",
        "# @markdown **Note:** Specify the paths to the input and output files below.\n",
        "\n",
        "# @markdown ### Enter the path to your input PDB file:\n",
        "pdb_file = \"/content/1EP0_alanine_dimer.pdb\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Enter the path to your output Excel file:\n",
        "output_excel_file = \"/content/1EP0_alanine_dimer_FE_2His_1asp_130.xlsx\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Enter the path to your PyMOL script file:\n",
        "pymol_script_file = \"/content/OmpF_dimer_alanine_3His_Full.pml\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Specify the specific residue number (use 0 for no specific residue):\n",
        "specific_residue_number = 0  # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ### Set the thresholds for analysis\n",
        "# @markdown **Alpha Distance**: Enter the minimum and maximum values.\n",
        "alpha_distance_min = 5.5  # @param {type:\"number\"}\n",
        "alpha_distance_max = 10  # @param {type:\"number\"}\n",
        "\n",
        "# @markdown **Beta Distance**: Enter the minimum and maximum values.\n",
        "beta_distance_min = 6.0  # @param {type:\"number\"}\n",
        "beta_distance_max = 9  # @param {type:\"number\"}\n",
        "\n",
        "# @markdown **Ratio Threshold**: Enter the minimum and maximum values.\n",
        "ratio_threshold_min = 0.7  # @param {type:\"number\"}\n",
        "ratio_threshold_max = 1.4  # @param {type:\"number\"}\n",
        "\n",
        "# @markdown **Pie Threshold**: Enter the minimum and maximum values.\n",
        "pie_threshold_min = 0  # @param {type:\"number\"}\n",
        "pie_threshold_max = 15  # @param {type:\"number\"}\n",
        "\n",
        "# Set thresholds based on user inputs\n",
        "alpha_distance_range = (alpha_distance_min, alpha_distance_max)\n",
        "beta_distance_range = (beta_distance_min, beta_distance_max)\n",
        "ratio_threshold_range = (ratio_threshold_min, ratio_threshold_max)\n",
        "pie_threshold_range = (pie_threshold_min, pie_threshold_max)\n",
        "\n",
        "# Output the ranges to confirm\n",
        "print(f\"Alpha Distance Range: {alpha_distance_range}\")\n",
        "print(f\"Beta Distance Range: {beta_distance_range}\")\n",
        "print(f\"Ratio Threshold Range: {ratio_threshold_range}\")\n",
        "print(f\"Pie Threshold Range: {pie_threshold_range}\")\n",
        "\n",
        "# Capture the inputs into variables\n",
        "alpha_distance_range = (alpha_distance_min, alpha_distance_max)\n",
        "beta_distance_range = (beta_distance_min, beta_distance_max)\n",
        "ratio_threshold_range = (ratio_threshold_min, ratio_threshold_max)\n",
        "pie_threshold_range = (pie_threshold_min, pie_threshold_max)\n",
        "\n",
        "# Continue with the script using these threshold values\n",
        "print(f\"Alpha Distance Range: {alpha_distance_range}\")\n",
        "print(f\"Beta Distance Range: {beta_distance_range}\")\n",
        "print(f\"Ratio Threshold Range: {ratio_threshold_range}\")\n",
        "print(f\"Pie Threshold Range: {pie_threshold_range}\")\n",
        "\n",
        "# PDB Parser setup\n",
        "parser = PDBParser(QUIET=True)\n",
        "structure = parser.get_structure('protein', pdb_file)\n",
        "model = structure[0]\n",
        "residues = [residue for residue in model.get_residues() if residue.get_id()[0] == ' ']\n",
        "\n",
        "# Step 1: Filter combinations to include specific residue number if specified\n",
        "if specific_residue_number != 0:\n",
        "    combinations = [\n",
        "        comb for comb in itertools.combinations(residues, 3)\n",
        "        if any(res.get_id()[1] == specific_residue_number for res in comb)\n",
        "    ]\n",
        "else:\n",
        "    combinations = list(itertools.combinations(residues, 3))\n",
        "\n",
        "\n",
        "# Distance filter\n",
        "filtered_data_distances = []\n",
        "\n",
        "for idx, combination in enumerate(combinations):\n",
        "    alpha_distances, beta_distances = [], []\n",
        "\n",
        "    try:\n",
        "        for res1, res2 in itertools.combinations(combination, 2):\n",
        "            if res1.has_id('CA') and res2.has_id('CA'):\n",
        "                ca1, ca2 = res1['CA'].coord, res2['CA'].coord\n",
        "                alpha_distance = np.linalg.norm(ca1 - ca2)\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            if res1.has_id('CB') and res2.has_id('CB'):\n",
        "                cb1, cb2 = res1['CB'].coord, res2['CB'].coord\n",
        "                beta_distance = np.linalg.norm(cb1 - cb2)\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            if (alpha_distance_range[0] <= alpha_distance <= alpha_distance_range[1] and\n",
        "                    beta_distance_range[0] <= beta_distance <= beta_distance_range[1]):\n",
        "                alpha_distances.append(alpha_distance)\n",
        "                beta_distances.append(beta_distance)\n",
        "\n",
        "        if len(alpha_distances) >= 3 and len(beta_distances) >= 3:\n",
        "            filtered_data_distances.append({\n",
        "                'PDB_ID': pdb_file,\n",
        "                'Combination': combination,\n",
        "                'Coord_chain_id_number1': combination[0].get_full_id()[2],\n",
        "                'Coord_residue_number1': combination[0].get_full_id()[3][1],\n",
        "                'Coord_residue_name1': combination[0].get_resname(),\n",
        "                'Coord_atom_name1': 'CA',\n",
        "                'Coord_chain_id_number2': combination[1].get_full_id()[2],\n",
        "                'Coord_residue_number2': combination[1].get_full_id()[3][1],\n",
        "                'Coord_residue_name2': combination[1].get_resname(),\n",
        "                'Coord_atom_name2': 'CA',\n",
        "                'Coord_chain_id_number3': combination[2].get_full_id()[2],\n",
        "                'Coord_residue_number3': combination[2].get_full_id()[3][1],\n",
        "                'Coord_residue_name3': combination[2].get_resname(),\n",
        "                'Coord_atom_name3': 'CA',\n",
        "                'Alpha Distance 1': alpha_distances[0],\n",
        "                'Alpha Distance 2': alpha_distances[1],\n",
        "                'Alpha Distance 3': alpha_distances[2],\n",
        "                'Beta Distance 1': beta_distances[0],\n",
        "                'Beta Distance 2': beta_distances[1],\n",
        "                'Beta Distance 3': beta_distances[2]\n",
        "            })\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error processing combination {combination}: {e}\")\n",
        "\n",
        "# Create DataFrame for distances\n",
        "column_order = [\n",
        "    'PDB_ID',\n",
        "    'Combination',\n",
        "    'Coord_chain_id_number1', 'Coord_residue_number1', 'Coord_residue_name1', 'Coord_atom_name1',\n",
        "    'Coord_chain_id_number2', 'Coord_residue_number2', 'Coord_residue_name2', 'Coord_atom_name2',\n",
        "    'Coord_chain_id_number3', 'Coord_residue_number3', 'Coord_residue_name3', 'Coord_atom_name3',\n",
        "    'Alpha Distance 1', 'Alpha Distance 2', 'Alpha Distance 3',\n",
        "    'Beta Distance 1', 'Beta Distance 2', 'Beta Distance 3'\n",
        "]\n",
        "\n",
        "df_distances = pd.DataFrame(filtered_data_distances)\n",
        "df_distances = df_distances[column_order]\n",
        "\n",
        "# Ratio filter\n",
        "filtered_data_ratio = []\n",
        "\n",
        "for idx, row in df_distances.iterrows():\n",
        "    alpha_distances = [row['Alpha Distance 1'], row['Alpha Distance 2'], row['Alpha Distance 3']]\n",
        "    beta_distances = [row['Beta Distance 1'], row['Beta Distance 2'], row['Beta Distance 3']]\n",
        "\n",
        "    for i in range(3):\n",
        "        alpha_distance_i = alpha_distances[i]\n",
        "        beta_distance_i = beta_distances[i]\n",
        "        ratio = alpha_distance_i / beta_distance_i\n",
        "\n",
        "        if not (ratio_threshold_range[0] <= ratio <= ratio_threshold_range[1]):\n",
        "            break\n",
        "    else:\n",
        "        filtered_data_ratio.append(row)\n",
        "\n",
        "df_ratio = pd.DataFrame(filtered_data_ratio)\n",
        "df_ratio = df_ratio[column_order]\n",
        "\n",
        "# Pie filter\n",
        "def calculate_pie(vector1, vector2):\n",
        "    dot_product = np.dot(vector1, vector2)\n",
        "    magnitude_product = np.linalg.norm(vector1) * np.linalg.norm(vector2)\n",
        "    if magnitude_product == 0:\n",
        "        return np.nan\n",
        "    cosine_angle = dot_product / magnitude_product\n",
        "    cosine_angle = np.clip(cosine_angle, -1.0, 1.0)\n",
        "    return np.degrees(np.arccos(cosine_angle))\n",
        "\n",
        "def process_row(row):\n",
        "    pdb_file_path = pdb_file\n",
        "    if not os.path.isfile(pdb_file_path):\n",
        "        print(f\"PDB file not found: {pdb_file_path}\")\n",
        "        return [None, None, None]\n",
        "\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure('protein', pdb_file_path)\n",
        "    model = structure[0]\n",
        "\n",
        "    try:\n",
        "        residues = row['Combination']\n",
        "        print(f\"Residues loaded: {residues}\")\n",
        "\n",
        "        pies = []\n",
        "        pairs = [(0, 1), (0, 2), (1, 2)]\n",
        "\n",
        "        for i, j in pairs:\n",
        "            try:\n",
        "                CA1 = residues[i]['CA']\n",
        "                CA2 = residues[j]['CA']\n",
        "                CB1 = residues[i]['CB'] if 'CB' in residues[i] else CA1\n",
        "                CB2 = residues[j]['CB'] if 'CB' in residues[j] else CA2\n",
        "\n",
        "                vector_CA = CA2.coord - CA1.coord\n",
        "                vector_CB = CB2.coord - CB1.coord\n",
        "\n",
        "                angle = calculate_pie(vector_CA, vector_CB)\n",
        "                pies.append(angle)\n",
        "            except KeyError as e:\n",
        "                print(f\"KeyError for residues {residues[i]} and {residues[j]}: {e}\")\n",
        "                pies.append(None)\n",
        "\n",
        "        return pies\n",
        "    except KeyError as e:\n",
        "        print(f\"KeyError: {e}\")\n",
        "        return [None, None, None]\n",
        "\n",
        "pie_results = df_ratio.apply(process_row, axis=1, result_type='expand')\n",
        "df_ratio[['Pie_1_2', 'Pie_1_3', 'Pie_2_3']] = pie_results\n",
        "\n",
        "# Create filter columns based on pie thresholds\n",
        "for col in ['Pie_1_2', 'Pie_1_3', 'Pie_2_3']:\n",
        "    df_ratio[f'{col}_Filter'] = df_ratio.apply(lambda row: pie_threshold_range[0] < row[col] < pie_threshold_range[1] if pd.notnull(row[col]) else False, axis=1)\n",
        "\n",
        "df_ratio['Pie_Filter'] = df_ratio[[f'{col}_Filter' for col in ['Pie_1_2', 'Pie_1_3', 'Pie_2_3']]].all(axis=1)\n",
        "\n",
        "df_final_filter = df_ratio[df_ratio['Pie_Filter']]\n",
        "# Remove '.pdb' from the PDB_ID in the final filtered DataFrame\n",
        "df_final_filter['PDB_ID'] = df_final_filter['PDB_ID'].str.replace('.pdb', '', regex=False)\n",
        "# Save all DataFrames into a single Excel file with different tabs\n",
        "with pd.ExcelWriter(output_excel_file) as writer:\n",
        "    df_distances.to_excel(writer, sheet_name='Distances', index=False)\n",
        "    df_ratio.to_excel(writer, sheet_name='Ratio', index=False)\n",
        "    df_final_filter.to_excel(writer, sheet_name='Pie', index=False)\n",
        "\n",
        "# Generate PyMOL script file\n",
        "pymol_script_commands = []\n",
        "df_final_filter['Combination_Number'] = range(1, len(df_final_filter) + 1)\n",
        "\n",
        "for index, row in df_final_filter.iterrows():\n",
        "    combination = row['Combination']\n",
        "    chain1, res1 = combination[0].get_full_id()[2], combination[0].get_full_id()[3][1]\n",
        "    chain2, res2 = combination[1].get_full_id()[2], combination[1].get_full_id()[3][1]\n",
        "    chain3, res3 = combination[2].get_full_id()[2], combination[2].get_full_id()[3][1]\n",
        "\n",
        "    selection_name = f\"obj{row['Combination_Number']:02d}\"\n",
        "    pymol_script_commands.append(f\"select {selection_name}, (chain {chain1} and resi {res1}) or (chain {chain2} and resi {res2}) or (chain {chain3} and resi {res3})\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue1, /{pdb_file}//{chain1}/{res1}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue2, /{pdb_file}//{chain2}/{res2}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue3, /{pdb_file}//{chain3}/{res3}\")\n",
        "\n",
        "with open(pymol_script_file, 'w') as f:\n",
        "    f.write(\"# PyMOL script for visualizing filtered residue combinations\\n\\n\")\n",
        "    for command in pymol_script_commands:\n",
        "        f.write(command + '\\n')\n",
        "\n",
        "print(f\"\\nResults saved to {output_excel_file}\")\n",
        "print(f\"PyMOL script saved to {pymol_script_file}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AaV2VRpFNhW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio.PDB import PDBParser\n",
        "import pandas as pd\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 4A: Preparation steps for metal-sites expectation (Coordinates extraction)\n",
        "\n",
        "# @markdown **Note:** Specify the paths to the input and output files below.\n",
        "# @markdown ### Enter the path to your input excel file (The result of the step 3)\n",
        "input_file = '/content/1CA2_Full_3His.xlsx' # @param {type:\"string\"}\n",
        "df_pie = pd.read_excel(input_file, sheet_name='Pie')\n",
        "\n",
        "# @markdown ### Enter the path to your input PDB file:\n",
        "pdb_file = \"/content/1CA2_alanine.pdb\"  # @param {type:\"string\"}\n",
        "parser = PDBParser(QUIET=True)\n",
        "structure = parser.get_structure('protein', pdb_file)\n",
        "\n",
        "# Extract the PDB ID by removing the directory and `.pdb` extension\n",
        "pdb_id = os.path.basename(pdb_file).replace('.pdb', '')\n",
        "\n",
        "# Function to extract Cα and Cβ coordinates for a given residue\n",
        "def extract_coordinates(chain, res_id, atom_name):\n",
        "    try:\n",
        "        residue = chain[res_id]\n",
        "        atom_coord = residue[atom_name].coord\n",
        "        return atom_coord\n",
        "    except KeyError:\n",
        "        return [None, None, None]\n",
        "\n",
        "# Pre-fetch chains to avoid repetitive lookups\n",
        "chains = {chain.id: chain for chain in structure[0]}\n",
        "\n",
        "# Loop through each row in the Excel file and extract coordinates\n",
        "ca_coords = []\n",
        "cb_coords = []\n",
        "\n",
        "for idx, row in df_pie.iterrows():\n",
        "    chain1 = chains.get(row['Coord_chain_id_number1'])\n",
        "    chain2 = chains.get(row['Coord_chain_id_number2'])\n",
        "    chain3 = chains.get(row['Coord_chain_id_number3'])\n",
        "\n",
        "    # Extract chain, residue, and atom info for each of the three residues\n",
        "    res1_coord = extract_coordinates(chain1, row['Coord_residue_number1'], 'CA')\n",
        "    res2_coord = extract_coordinates(chain2, row['Coord_residue_number2'], 'CA')\n",
        "    res3_coord = extract_coordinates(chain3, row['Coord_residue_number3'], 'CA')\n",
        "\n",
        "    # Add coordinates for each residue\n",
        "    ca_coords.append([*res1_coord, *res2_coord, *res3_coord])\n",
        "\n",
        "    # If Cβ is also needed:\n",
        "    res1_cb = extract_coordinates(chain1, row['Coord_residue_number1'], 'CB')\n",
        "    res2_cb = extract_coordinates(chain2, row['Coord_residue_number2'], 'CB')\n",
        "    res3_cb = extract_coordinates(chain3, row['Coord_residue_number3'], 'CB')\n",
        "\n",
        "    cb_coords.append([*res1_cb, *res2_cb, *res3_cb])\n",
        "\n",
        "# Convert the extracted coordinates to DataFrames\n",
        "ca_columns = ['CA1_X', 'CA1_Y', 'CA1_Z', 'CA2_X', 'CA2_Y', 'CA2_Z', 'CA3_X', 'CA3_Y', 'CA3_Z']\n",
        "cb_columns = ['CB1_X', 'CB1_Y', 'CB1_Z', 'CB2_X', 'CB2_Y', 'CB2_Z', 'CB3_X', 'CB3_Y', 'CB3_Z']\n",
        "\n",
        "df_ca = pd.DataFrame(ca_coords, columns=ca_columns)\n",
        "df_cb = pd.DataFrame(cb_coords, columns=cb_columns)\n",
        "\n",
        "# Merge the coordinates with the original DataFrame\n",
        "df_pie = pd.concat([df_pie.reset_index(drop=True), df_ca, df_cb], axis=1)\n",
        "\n",
        "# Remove `.pdb` from the `PDB_ID` column if it exists\n",
        "if 'PDB_ID' in df_pie.columns:\n",
        "    df_pie['PDB_ID'] = df_pie['PDB_ID'].str.replace('.pdb', '', regex=False)\n",
        "# @markdown ### Enter the path to your output Excel file:\n",
        "output_file = '/content/1CA2_Full_3His_coordinates.xlsx'   # @param {type:\"string\"}\n",
        "df_pie.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Coordinates extracted and saved to {output_file}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vlddZ35YMLWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "979288a7-ebc5-44ee-c7ed-52c12a27b077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coordinates extracted and saved to /content/1CA2_Full_3His_coordinates.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Final (Dynamically:Last_One+edge): 진짜 이거 ratio 까지 되는거 (마지막):찐찐찐\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from Bio.PDB import PDBParser\n",
        "import requests\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 4B: Run the metal-sites expectation\n",
        "\n",
        "# Define input and output file paths\n",
        "# @markdown ### Enter the path to your input excel file (The result of the step 4A)\n",
        "input_coords_file = '/content/1EP0_alanine_dimer_3His_coordinates.xlsx' # @param {type:\"string\"}\n",
        "\n",
        "# Load input file\n",
        "df_alanine = pd.read_excel(input_coords_file)\n",
        "\n",
        "# Define file download paths\n",
        "prob_map_file = '/content/map.xlsx'\n",
        "thresholds_file = '/content/threshold.xlsx'\n",
        "\n",
        "# Download files from GitHub\n",
        "base_url = \"https://raw.githubusercontent.com/SNU-Songlab/Metal-Installer-code/main/probability/\"\n",
        "# @markdown ### Set the metal type to use:\n",
        "Metal = 'Zn'  # @param [\"Zn\", \"Mn\", \"Cu\", \"Fe\"]\n",
        "# @markdown ### Select the combination type:\n",
        "# @markdown **Note:** 3His:Zn/Cu/Fe & 2His/1Asp:Zn/Fe/Mn & 2His/1Glu: Zn/Fe/Mn & 2His/1Cys: Cu\n",
        "Combinations = '3His'  # @param [\"3His\", \"2His_1Asp\", \"2His_1Glu\", \"2His_1Cys\"]\n",
        "\n",
        "map_url = f\"{base_url}/{Metal}/{Combinations}/map.xlsx\"\n",
        "thresholds_url = f\"{base_url}/{Metal}/{Combinations}/threshold.xlsx\"\n",
        "\n",
        "# Download probability map\n",
        "response = requests.get(map_url)\n",
        "if response.status_code == 200:\n",
        "    with open(prob_map_file, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "else:\n",
        "    raise ValueError(f\"Failed to download file from {map_url}. Status code: {response.status_code}\")\n",
        "\n",
        "# Download thresholds file\n",
        "response = requests.get(thresholds_url)\n",
        "if response.status_code == 200:\n",
        "    with open(thresholds_file, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "else:\n",
        "    raise ValueError(f\"Failed to download file from {thresholds_url}. Status code: {response.status_code}\")\n",
        "\n",
        "# Load downloaded Excel files\n",
        "thresholds_df = pd.read_excel(thresholds_file, sheet_name='Sheet1')\n",
        "df_precomputed_prob_map = pd.read_excel(prob_map_file)\n",
        "\n",
        "def calculate_ratio(current_point, ca_xyz, cb_xyz):\n",
        "    # Calculate distances to Ca and Cb atoms\n",
        "    ca_distances = np.linalg.norm(ca_xyz - current_point, axis=1)\n",
        "    cb_distances = np.linalg.norm(cb_xyz - current_point, axis=1)\n",
        "    # Return ratios for each residue\n",
        "    return ca_distances / cb_distances\n",
        "\n",
        "# Extract thresholds into a dictionary\n",
        "thresholds = {}\n",
        "for _, row in thresholds_df.iterrows():\n",
        "    parameter = row['Parameter']\n",
        "    min_value = row['Min']\n",
        "    max_value = row['Max']\n",
        "    if pd.notna(min_value) and pd.notna(max_value):\n",
        "        thresholds[parameter] = (min_value, max_value)\n",
        "\n",
        "required_keys = ['ca_distances_calc', 'cb_distances_calc', 'ratio', 'angle']\n",
        "\n",
        "for key in required_keys:\n",
        "    if key not in thresholds:\n",
        "        raise KeyError(f\"Missing key '{key}' in thresholds file.\")\n",
        "\n",
        "\n",
        "# Define bin edges for CA-Zn distances, CB-Zn distances, and angles\n",
        "prob_map_file = '/content/map.xlsx'\n",
        "df_precomputed_prob_map = pd.read_excel(prob_map_file)\n",
        "\n",
        "ca_bins = np.sort(df_precomputed_prob_map['Calpha_Zn_Dist'].unique())\n",
        "cb_bins = np.sort(df_precomputed_prob_map['Cbeta_Zn_Dist'].unique())\n",
        "angle_bins = np.sort(df_precomputed_prob_map['CA-Zn-CB_Angle'].unique())\n",
        "\n",
        "# Pivot the probability map into a 3D array format\n",
        "pivoted_prob_map = df_precomputed_prob_map.pivot_table(\n",
        "    index='Calpha_Zn_Dist', columns=['Cbeta_Zn_Dist', 'CA-Zn-CB_Angle'], values='Probability', fill_value=0\n",
        ")\n",
        "prob_map_3d = pivoted_prob_map.values.reshape((len(ca_bins), len(cb_bins), len(angle_bins)))\n",
        "\n",
        "# Function to load a PDB file based on entry ID\n",
        "def load_pdb_structure(entry_id, pdb_directory):\n",
        "    pdb_parser = PDBParser()\n",
        "    pdb_file_path = os.path.join(pdb_directory, f\"{entry_id}.pdb\")\n",
        "    structure = pdb_parser.get_structure(entry_id, pdb_file_path)\n",
        "    return structure\n",
        "\n",
        "# Function to score Zn positions\n",
        "def score_zn_predictions(ca_distances, cb_distances, angles, prob_map_3d, ca_bins, cb_bins, angle_bins):\n",
        "    ca_bin_indices = np.digitize(ca_distances, ca_bins) - 1\n",
        "    cb_bin_indices = np.digitize(cb_distances, cb_bins) - 1\n",
        "    angle_bin_indices = np.digitize(angles, angle_bins) - 1\n",
        "    probabilities = []\n",
        "    valid = True\n",
        "    for cbin, bbin, abin in zip(ca_bin_indices, cb_bin_indices, angle_bin_indices):\n",
        "        if 0 <= cbin < prob_map_3d.shape[0] and 0 <= bbin < prob_map_3d.shape[1] and 0 <= abin < prob_map_3d.shape[2]:\n",
        "            prob_value = prob_map_3d[cbin, bbin, abin]\n",
        "            if prob_value == 0:\n",
        "                valid = False\n",
        "                break\n",
        "            probabilities.append(prob_value)\n",
        "        else:\n",
        "            valid = False\n",
        "            break\n",
        "    final_score = np.prod(probabilities) if valid else None\n",
        "    return final_score\n",
        "\n",
        "# Function to calculate angles between Zn-Cα and Zn-Cβ vectors for each triplet\n",
        "def calculate_angles(zn_coords, ca_coords_triplet, cb_coords_triplet):\n",
        "    angles = []\n",
        "    for i in range(3):\n",
        "        v1 = ca_coords_triplet[i] - zn_coords\n",
        "        v2 = cb_coords_triplet[i] - zn_coords\n",
        "        cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
        "        angle = np.arccos(np.clip(cos_theta, -1.0, 1.0))\n",
        "        angles.append(np.degrees(angle))\n",
        "    return angles\n",
        "\n",
        "# Function to filter Zn candidates by distance thresholds\n",
        "def filter_by_distance_threshold(ca_coords, cb_coords, zn_candidates, ca_xyz, cb_xyz):\n",
        "    filtered_candidates = []\n",
        "    for zn_candidate in zn_candidates:\n",
        "        # Calculate distances to Cα and Cβ\n",
        "        ca_distances_calc = np.linalg.norm(zn_candidate - ca_coords, axis=1)\n",
        "        cb_distances_calc = np.linalg.norm(zn_candidate - cb_coords, axis=1)\n",
        "\n",
        "        # Calculate Zn-Cα/Zn-Cβ ratios\n",
        "        ratio = ca_distances_calc / cb_distances_calc\n",
        "\n",
        "        # Calculate angles\n",
        "        angles = np.array(calculate_angles(zn_candidate, ca_xyz, cb_xyz))\n",
        "\n",
        "        # Apply thresholds\n",
        "        if (np.all((thresholds['ca_distances_calc'][0] <= ca_distances_calc) & (ca_distances_calc <= thresholds['ca_distances_calc'][1])) and\n",
        "            np.all((thresholds['cb_distances_calc'][0] <= cb_distances_calc) & (cb_distances_calc <= thresholds['cb_distances_calc'][1])) and\n",
        "            np.all((thresholds['ratio'][0] <= ratio) & (ratio <= thresholds['ratio'][1]))):\n",
        "            filtered_candidates.append(zn_candidate)\n",
        "\n",
        "    return np.array(filtered_candidates)\n",
        "\n",
        "\n",
        "\n",
        "def define_excluded_triads(triad_residues, structure):\n",
        "    excluded_residues = set()\n",
        "    for _, residue_number in triad_residues:\n",
        "        for model in structure:\n",
        "            for chain in model:\n",
        "                for residue in chain:\n",
        "                    if residue.get_id()[1] == residue_number:\n",
        "                        excluded_residues.add((chain.id, residue.get_id()[1]))\n",
        "    return excluded_residues\n",
        "\n",
        "# Function to perform proximity filtering and record nearby amino acids\n",
        "def find_proximity_amino_acids(structure, zn_candidate, excluded_residues, exclusion_radius=2.5):\n",
        "    nearby_amino_acids = []\n",
        "\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            for residue in chain:\n",
        "                # Skip if the residue is in the excluded set\n",
        "                if (chain.id, residue.get_id()[1]) in excluded_residues:\n",
        "                    continue\n",
        "\n",
        "                for atom in residue:\n",
        "                    atom_coords = atom.coord\n",
        "                    distance_to_atom = np.linalg.norm(zn_candidate - atom_coords)\n",
        "                    if distance_to_atom < exclusion_radius:\n",
        "                        nearby_amino_acids.append({\n",
        "                            'Chain_ID': chain.id,\n",
        "                            'Residue_Number': residue.get_id()[1],\n",
        "                            'Residue_Name': residue.get_resname(),\n",
        "                            'Atom_Name': atom.get_name(),\n",
        "                            'Distance_to_Zn': distance_to_atom\n",
        "                        })\n",
        "                        break  # Log only once per residue within radius\n",
        "    return nearby_amino_acids\n",
        "def define_excluded_triads(triad_residues, structure):\n",
        "    excluded_residues = set()\n",
        "    for _, residue_number in triad_residues:\n",
        "        for model in structure:\n",
        "            for chain in model:\n",
        "                for residue in chain:\n",
        "                    if residue.get_id()[1] == residue_number:\n",
        "                        excluded_residues.add((chain.id, residue.get_id()[1]))\n",
        "    return excluded_residues\n",
        "# Function for proximity filtering with explicit exclusion of defined triads\n",
        "def proximity_filter(structure, zn_candidate, excluded_residues, exclusion_radius=2.5):\n",
        "    \"\"\"\n",
        "    Perform proximity filtering, excluding residues with the same residue number across chains.\n",
        "    \"\"\"\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            for residue in chain:\n",
        "                chain_id = chain.id\n",
        "                residue_number = residue.get_id()[1]  # Residue sequence number\n",
        "\n",
        "                # Skip residues if they match any in the exclusion set\n",
        "                if (chain_id, residue_number) in excluded_residues:\n",
        "                    continue\n",
        "\n",
        "                for atom in residue:\n",
        "                    atom_coords = atom.coord\n",
        "                    distance_to_atom = np.linalg.norm(zn_candidate - atom_coords)\n",
        "                    if distance_to_atom < exclusion_radius:\n",
        "                        return False  # Invalid candidate due to proximity to excluded residue\n",
        "\n",
        "    return True\n",
        "\n",
        "# Main function to estimate Zn candidates with precise boundary handling from Excel\n",
        "def estimate_zn_iterative(ca_coords, cb_coords, prob_map_3d, ca_bins, cb_bins, angle_bins, pdb_directory, grid_resolution=0.2):\n",
        "    # Extract thresholds from the DataFrame\n",
        "    thresholds = {}\n",
        "    for _, row in thresholds_df.iterrows():\n",
        "        parameter = row['Parameter']\n",
        "        min_value = row['Min']\n",
        "        max_value = row['Max']\n",
        "        if pd.notna(min_value) and pd.notna(max_value):\n",
        "            thresholds[parameter] = (min_value, max_value)\n",
        "\n",
        "    required_keys = ['ca_distances_calc', 'cb_distances_calc', 'ratio', 'angle']\n",
        "\n",
        "    for key in required_keys:\n",
        "        if key not in thresholds:\n",
        "            raise KeyError(f\"Missing key '{key}' in thresholds file.\")\n",
        "\n",
        "    zn_coords_list = []\n",
        "    best_scores = []\n",
        "    angle_list = []\n",
        "    proximity_data = []  # Store proximity information for each valid Zn candidate\n",
        "\n",
        "    for i in range(len(ca_coords)):\n",
        "        entry_id = df_alanine['PDB_ID'][i]\n",
        "        structure = load_pdb_structure(entry_id, pdb_directory)\n",
        "\n",
        "        # Extract and reshape Cα and Cβ coordinates\n",
        "        ca_xyz = ca_coords.iloc[i].values.reshape(3, 3)\n",
        "        cb_xyz = cb_coords.iloc[i].values.reshape(3, 3)\n",
        "\n",
        "        # Define triad residues (ignoring chain IDs initially)\n",
        "        triad_residues = [\n",
        "            (None, df_alanine.at[i, 'Coord_residue_number1']),\n",
        "            (None, df_alanine.at[i, 'Coord_residue_number2']),\n",
        "            (None, df_alanine.at[i, 'Coord_residue_number3'])\n",
        "        ]\n",
        "\n",
        "        # Define excluded residues considering all chains with the same residue numbers\n",
        "        excluded_residues = define_excluded_triads(triad_residues, structure)\n",
        "\n",
        "        # Initialize shared region boundaries\n",
        "        shared_x_min = -np.inf\n",
        "        shared_x_max = np.inf\n",
        "        shared_y_min = -np.inf\n",
        "        shared_y_max = np.inf\n",
        "        shared_z_min = -np.inf\n",
        "        shared_z_max = np.inf\n",
        "\n",
        "        # Define inner and outer box boundaries from thresholds\n",
        "        inner_boxes = []\n",
        "        for j in range(3):\n",
        "            x_min_inner = min(ca_xyz[j, 0], cb_xyz[j, 0]) - thresholds['ca_distances_calc'][0]\n",
        "            x_max_inner = max(ca_xyz[j, 0], cb_xyz[j, 0]) + thresholds['ca_distances_calc'][0]\n",
        "\n",
        "            y_min_inner = min(ca_xyz[j, 1], cb_xyz[j, 1]) - thresholds['cb_distances_calc'][0]\n",
        "            y_max_inner = max(ca_xyz[j, 1], cb_xyz[j, 1]) + thresholds['cb_distances_calc'][0]\n",
        "\n",
        "            z_min_inner = min(ca_xyz[j, 2], cb_xyz[j, 2]) - thresholds['ca_distances_calc'][0]\n",
        "            z_max_inner = max(ca_xyz[j, 2], cb_xyz[j, 2]) + thresholds['ca_distances_calc'][0]\n",
        "\n",
        "            inner_boxes.append((x_min_inner, x_max_inner, y_min_inner, y_max_inner, z_min_inner, z_max_inner))\n",
        "\n",
        "            x_min_outer = min(ca_xyz[j, 0], cb_xyz[j, 0]) - thresholds['ca_distances_calc'][1]\n",
        "            x_max_outer = max(ca_xyz[j, 0], cb_xyz[j, 0]) + thresholds['ca_distances_calc'][1]\n",
        "\n",
        "            y_min_outer = min(ca_xyz[j, 1], cb_xyz[j, 1]) - thresholds['cb_distances_calc'][1]\n",
        "            y_max_outer = max(ca_xyz[j, 1], cb_xyz[j, 1]) + thresholds['cb_distances_calc'][1]\n",
        "\n",
        "            z_min_outer = min(ca_xyz[j, 2], cb_xyz[j, 2]) - thresholds['ca_distances_calc'][1]\n",
        "            z_max_outer = max(ca_xyz[j, 2], cb_xyz[j, 2]) + thresholds['ca_distances_calc'][1]\n",
        "\n",
        "            # Update shared region with intersection\n",
        "            shared_x_min = max(shared_x_min, x_min_outer - grid_resolution)\n",
        "            shared_x_max = min(shared_x_max, x_max_outer + grid_resolution)\n",
        "            shared_y_min = max(shared_y_min, y_min_outer - grid_resolution)\n",
        "            shared_y_max = min(shared_y_max, y_max_outer + grid_resolution)\n",
        "            shared_z_min = max(shared_z_min, z_min_outer - grid_resolution)\n",
        "            shared_z_max = min(shared_z_max, z_max_outer + grid_resolution)\n",
        "\n",
        "        # Ensure valid search space exists\n",
        "        if shared_x_min >= shared_x_max or shared_y_min >= shared_y_max or shared_z_min >= shared_z_max:\n",
        "            print(f\"No shared search space for Entry {i}: {entry_id}\")\n",
        "            zn_coords_list.append(\"no metal\")\n",
        "            best_scores.append(0)\n",
        "            angle_list.append([None, None, None])\n",
        "            continue\n",
        "\n",
        "        # Debug print for shared search region\n",
        "        print(f\"Shared Region for Entry {i}: {entry_id}\")\n",
        "        print(f\"x_min: {shared_x_min}, x_max: {shared_x_max}\")\n",
        "        print(f\"y_min: {shared_y_min}, y_max: {shared_y_max}\")\n",
        "        print(f\"z_min: {shared_z_min}, z_max: {shared_z_max}\")\n",
        "\n",
        "        # Generate Zn candidates grid within the shared region excluding inner boxes\n",
        "        zn_candidates = []\n",
        "        total_grid_points = 0\n",
        "        distance_valid_points = 0\n",
        "        angle_valid_points = 0\n",
        "        ratio_valid_points = 0\n",
        "        probability_valid_points = 0\n",
        "\n",
        "        # First find shared region with coarse grid\n",
        "        shared_region_found = False\n",
        "        if shared_x_min < shared_x_max and shared_y_min < shared_y_max and shared_z_min < shared_z_max:\n",
        "            shared_region_found = True\n",
        "\n",
        "                # If shared region exists, search with finer grid\n",
        "        if shared_region_found:\n",
        "            grid_resolution = 0.2  # Use the input parameter\n",
        "            total_grid_points = 0\n",
        "            distance_valid_points = 0\n",
        "            angle_valid_points = 0\n",
        "            ratio_valid_points = 0  # Renamed for clarity\n",
        "            probability_valid_points = 0\n",
        "            valid_points = []\n",
        "            all_scores = []\n",
        "\n",
        "            for x in np.arange(shared_x_min, shared_x_max + 1e-8, grid_resolution):\n",
        "                for y in np.arange(shared_y_min, shared_y_max + 1e-8, grid_resolution):\n",
        "                    for z in np.arange(shared_z_min, shared_z_max + 1e-8, grid_resolution):\n",
        "                        total_grid_points += 1\n",
        "\n",
        "                        # Check both corner and center points\n",
        "                        corner_point = np.array([x, y, z])\n",
        "                        center_point = np.array([\n",
        "                            x + grid_resolution/2,\n",
        "                            y + grid_resolution/2,\n",
        "                            z + grid_resolution/2\n",
        "                        ])\n",
        "\n",
        "                        for point in [corner_point, center_point]:\n",
        "                            # Distance check\n",
        "                            distances_ca = np.linalg.norm(ca_xyz - point, axis=1)\n",
        "                            distances_cb = np.linalg.norm(cb_xyz - point, axis=1)\n",
        "\n",
        "                            distance_condition = (np.all((thresholds['ca_distances_calc'][0] <= distances_ca) &\n",
        "                                                       (distances_ca <= thresholds['ca_distances_calc'][1])) and\n",
        "                                               np.all((thresholds['cb_distances_calc'][0] <= distances_cb) &\n",
        "                                                       (distances_cb <= thresholds['cb_distances_calc'][1])))\n",
        "\n",
        "                            if distance_condition:\n",
        "                                distance_valid_points += 1\n",
        "\n",
        "                                # Calculate angles\n",
        "                                angles = calculate_angles(point, ca_xyz, cb_xyz)\n",
        "                                angle_condition = all(thresholds['angle'][0] <= angle <= thresholds['angle'][1]\n",
        "                                                   for angle in angles)\n",
        "\n",
        "                                if angle_condition:\n",
        "                                    angle_valid_points += 1\n",
        "\n",
        "                                    # Calculate ratios\n",
        "                                    ratios = calculate_ratio(point, ca_xyz, cb_xyz)\n",
        "                                    ratio_condition = np.all((thresholds['ratio'][0] <= ratios) &\n",
        "                                                           (ratios <= thresholds['ratio'][1]))\n",
        "\n",
        "                                    if ratio_condition:\n",
        "                                        ratio_valid_points += 1  # Only increment if ratio check passes\n",
        "\n",
        "                                        # Calculate probability score\n",
        "                                        score = score_zn_predictions(\n",
        "                                            distances_ca,\n",
        "                                            distances_cb,\n",
        "                                            angles,\n",
        "                                            prob_map_3d, ca_bins, cb_bins, angle_bins)\n",
        "\n",
        "                                        if score is not None and score > 0:\n",
        "                                            probability_valid_points += 1  # Only increment if probability check passes\n",
        "                                            valid_points.append(point)\n",
        "                                            all_scores.append(score)\n",
        "                                            zn_candidates.append([x, y, z])\n",
        "\n",
        "            # Print filtering statistics\n",
        "            print(f\"Total grid points searched: {total_grid_points}\")\n",
        "            print(f\"Points passing distance criteria: {distance_valid_points}\")\n",
        "            print(f\"Points passing angle criteria: {angle_valid_points}\")\n",
        "            print(f\"Points passing ratio criteria: {ratio_valid_points}\")\n",
        "            print(f\"Points passing probability criteria: {probability_valid_points}\")\n",
        "\n",
        "        zn_candidates = np.array(zn_candidates)\n",
        "\n",
        "        # Filter Zn candidates by distance and proximity\n",
        "        distance_filtered_candidates = filter_by_distance_threshold(ca_xyz, cb_xyz, zn_candidates, ca_xyz, cb_xyz)\n",
        "\n",
        "        for zn_candidate in distance_filtered_candidates:\n",
        "            angles = calculate_angles(zn_candidate, ca_xyz, cb_xyz)\n",
        "            if any(angle > thresholds['angle'][1] or angle < thresholds['angle'][0] for angle in angles):\n",
        "                continue\n",
        "\n",
        "            score = score_zn_predictions(\n",
        "                np.linalg.norm(zn_candidate - ca_xyz, axis=1),\n",
        "                np.linalg.norm(zn_candidate - cb_xyz, axis=1),\n",
        "                angles,\n",
        "                prob_map_3d, ca_bins, cb_bins, angle_bins\n",
        "            )\n",
        "\n",
        "            if score is not None and score > 0:\n",
        "                valid = proximity_filter(structure, zn_candidate, excluded_residues)\n",
        "                if valid:\n",
        "                    zn_coords_list.append(zn_candidate)\n",
        "                    best_scores.append(score)\n",
        "                    angle_list.append(angles)\n",
        "                    break\n",
        "\n",
        "        if len(zn_coords_list) <= i:\n",
        "            zn_coords_list.append(\"no metal\")\n",
        "            best_scores.append(0)\n",
        "            angle_list.append([None, None, None])\n",
        "\n",
        "    return zn_coords_list, best_scores, angle_list, proximity_data\n",
        "\n",
        "\n",
        "# Define coordinates for Zn estimation and specify PDB directory\n",
        "ca_coords = df_alanine[['CA1_X', 'CA1_Y', 'CA1_Z', 'CA2_X', 'CA2_Y', 'CA2_Z', 'CA3_X', 'CA3_Y', 'CA3_Z']]\n",
        "cb_coords = df_alanine[['CB1_X', 'CB1_Y', 'CB1_Z', 'CB2_X', 'CB2_Y', 'CB2_Z', 'CB3_X', 'CB3_Y', 'CB3_Z']]\n",
        "pdb_directory = '/content/3p43_alanine.pdb'  # Replace with actual path to PDB files\n",
        "\n",
        "# Run Zn estimation with grid generation, scoring, and iterative proximity filtering\n",
        "estimated_zn_coords_grid, zn_scores, angles_list, proximity_data = estimate_zn_iterative(\n",
        "    ca_coords, cb_coords, prob_map_3d, ca_bins, cb_bins, angle_bins, pdb_directory, grid_resolution=0.2\n",
        ")\n",
        "\n",
        "# After calculating Zn coordinates, scores, and angles\n",
        "df_alanine['Zn_X_Grid'] = [coords[0] if not isinstance(coords, str) else None for coords in estimated_zn_coords_grid]\n",
        "df_alanine['Zn_Y_Grid'] = [coords[1] if not isinstance(coords, str) else None for coords in estimated_zn_coords_grid]\n",
        "df_alanine['Zn_Z_Grid'] = [coords[2] if not isinstance(coords, str) else None for coords in estimated_zn_coords_grid]\n",
        "df_alanine['Zn_Score'] = zn_scores\n",
        "df_alanine['Angle_1'], df_alanine['Angle_2'], df_alanine['Angle_3'] = zip(*angles_list)\n",
        "\n",
        "# Remove rows where Zn_Score is 0\n",
        "df_alanine = df_alanine[df_alanine['Zn_Score'] != 0]\n",
        "\n",
        "# @markdown ### Save the Filtered DataFrame to an Excel File\n",
        "output_file_path = '/content/1EP0_alanine_dimer_3His_coordinates_0.2_0.2.xlsx'  # @param {type:\"string\"}\n",
        "df_alanine.to_excel(output_file_path, index=False)\n",
        "# @markdown **Filtered Zn coordinates, scores, and angles saved.**\n",
        "print(f\"Filtered Zn coordinates, scores, and angles saved to '{output_file_path}'\")\n",
        "\n",
        "# @markdown ### Save the Proximity Information to an Excel File\n",
        "df_proximity = pd.DataFrame(proximity_data)\n",
        "output_proximity_file = '/content/test_proximity3.xlsx' # @param {type:\"string\"}\n",
        "df_proximity.to_excel(output_proximity_file, index=False)\n",
        "# @markdown **Proximity amino acid details saved.**\n",
        "print(f\"Proximity amino acid details saved to '{output_proximity_file}'\")"
      ],
      "metadata": {
        "id": "2yb2fkkN2IKl",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from Bio.PDB import PDBParser\n",
        "import requests\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 5: Analysis the result (Apply to the PDB file)\n",
        "\n",
        "# Load input file\n",
        "input_file_path = \"/content/1EP0_Fe_130_2His_1Asp_expect_original.xlsx\" # @param {type:\"string\"}\n",
        "df_new = pd.read_excel(input_file_path)\n",
        "\n",
        "# Generate PyMOL script file\n",
        "pymol_script_commands = []\n",
        "df_new['Combination_Number'] = range(1, len(df_new) + 1)\n",
        "\n",
        "# Generate the PyMOL script for both valid and invalid Zn binding forms\n",
        "for index, row in df_new.iterrows():\n",
        "    # Retrieve chain and residue information\n",
        "    chain1, res1 = row['Coord_chain_id_number1'], row['Coord_residue_number1']\n",
        "    chain2, res2 = row['Coord_chain_id_number2'], row['Coord_residue_number2']\n",
        "    chain3, res3 = row['Coord_chain_id_number3'], row['Coord_residue_number3']\n",
        "\n",
        "    # Retrieve Zn coordinates\n",
        "    zn_x, zn_y, zn_z = row['Zn_X_Grid'], row['Zn_Y_Grid'], row['Zn_Z_Grid']\n",
        "\n",
        "    selection_name = f\"obj{row['Combination_Number']:02d}\"\n",
        "\n",
        "    # Select the residues\n",
        "    pymol_script_commands.append(f\"select {selection_name}, (chain {chain1} and resi {res1}) or (chain {chain2} and resi {res2}) or (chain {chain3} and resi {res3})\")\n",
        "\n",
        "    # Create the objects for the residues\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue1, /{row['PDB_ID']}//{chain1}/{res1}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue2, /{row['PDB_ID']}//{chain2}/{res2}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue3, /{row['PDB_ID']}//{chain3}/{res3}\")\n",
        "\n",
        "    # Check if Zn coordinates are available\n",
        "    if not pd.isna(zn_x) and not pd.isna(zn_y) and not pd.isna(zn_z):\n",
        "        # Zn coordinates are present, add the Zn pseudoatom\n",
        "        zn_name = f\"{selection_name}_Zn\"\n",
        "        pymol_script_commands.append(f\"pseudoatom {zn_name}, pos=[{zn_x}, {zn_y}, {zn_z}], elem=Zn, name={zn_name}\")\n",
        "        pymol_script_commands.append(f\"show sphere, {zn_name}\")\n",
        "    else:\n",
        "        # Zn coordinates are missing, mark this combination as non-binding\n",
        "        pymol_script_commands.append(f\"# {selection_name} does not bind Zn\")\n",
        "\n",
        "# Save the commands into a PyMOL script\n",
        "pymol_script_file = \"/content/1ca2_filtered.pml\" # @param {type:\"string\"}\n",
        "with open(pymol_script_file, 'w') as f:\n",
        "    f.write(\"# PyMOL script for visualizing both Zn-binding and non-binding residue combinations\\n\\n\")\n",
        "    for command in pymol_script_commands:\n",
        "        f.write(command + '\\n')\n",
        "\n",
        "print(f\"PyMOL script saved to {pymol_script_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8VwAlZ7nSEw",
        "outputId": "00d3fe8c-7085-4a05-89b3-b616b569d93c",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyMOL script saved to /content/1ca2_filtered.pml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 5: Analysis the result (Sort the result based on the metal-ligating ligands)\n",
        "\n",
        "\n",
        "# Load the provided Excel file\n",
        "file_path = 'D:/241113_Metal_Intaller_Data_Final/1BK0/1BK0_Full_Fe_2His_1Asp_expect_2.xlsx' # @param {type:\"string\"}\n",
        "excel_data = pd.ExcelFile(file_path)\n",
        "\n",
        "# Load the data from the first sheet\n",
        "df = excel_data.parse('Sheet1')\n",
        "\n",
        "# Define function to count specific residues in the 'Combination' column\n",
        "def count_residues(row):\n",
        "    # Count occurrences of specific residue names in the 'Combination' column\n",
        "    residue_names = ['HIS', 'CYS', 'GLU', 'ASP']\n",
        "    count = sum(row['Combination'].count(residue) for residue in residue_names)\n",
        "    return count\n",
        "\n",
        "# Apply the function to each row and store the result in a new column 'Residue_Count'\n",
        "df['Residue_Count'] = df.apply(count_residues, axis=1)\n",
        "\n",
        "# Split the data based on the count of residues and save to separate sheets in a new Excel file\n",
        "output_file_path = 'D:/241113_Metal_Intaller_Data_Final/1BK0/1BK0_Full_Fe_2His_1Asp_expect_split_by_residue_count.xlsx'  # @param {type:\"string\"}\n",
        "with pd.ExcelWriter(output_file_path) as writer:\n",
        "    for count in df['Residue_Count'].unique():\n",
        "        df_filtered = df[df['Residue_Count'] == count]\n",
        "        df_filtered.to_excel(writer, sheet_name=f'Residue_Count_{count}', index=False)\n",
        "\n",
        "print(\"File saved at:\", output_file_path)"
      ],
      "metadata": {
        "id": "kU_wIAFoS_Yk",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}