{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b0YnbjBDl3zq",
        "outputId": "a11b4b34-f3db-4113-874c-831c00cad7d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pinned packages:\n",
            "  - python 3.11.*\n",
            "  - python 3.11.*\n",
            "  - python_abi 3.11.* *cp311*\n",
            "  - cuda-version 12.*\n",
            "\n",
            "\n",
            "Transaction\n",
            "\n",
            "  Prefix: /usr/local\n",
            "\n",
            "  Updating specs:\n",
            "\n",
            "   - pymol-open-source\n",
            "   - ca-certificates\n",
            "   - certifi\n",
            "   - openssl\n",
            "\n",
            "\n",
            "  Package                         Version  Build                 Channel           Size\n",
            "─────────────────────────────────────────────────────────────────────────────────────────\n",
            "  Install:\n",
            "─────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "  \u001b[32m+ icu                      \u001b[0m        75.1  he02047a_0            conda-forge       12MB\n",
            "  \u001b[32m+ glm                      \u001b[0m     0.9.9.8  h00ab1b0_0            conda-forge      218kB\n",
            "  \u001b[32m+ pmw                      \u001b[0m       2.0.1  py311h38be061_1008    conda-forge      640kB\n",
            "  \u001b[32m+ libcups                  \u001b[0m       2.3.3  h4637d8d_4            conda-forge        5MB\n",
            "  \u001b[32m+ alsa-lib                 \u001b[0m      1.2.13  hb9d3cd8_0            conda-forge      560kB\n",
            "  \u001b[32m+ nspr                     \u001b[0m        4.36  h5888daf_0            conda-forge      230kB\n",
            "  \u001b[32m+ libogg                   \u001b[0m       1.3.5  h4ab18f5_0            conda-forge      206kB\n",
            "  \u001b[32m+ libpciaccess             \u001b[0m        0.18  hd590300_0            conda-forge       28kB\n",
            "  \u001b[32m+ libpng                   \u001b[0m      1.6.47  h943b412_0            conda-forge      289kB\n",
            "  \u001b[32m+ expat                    \u001b[0m       2.6.4  h5888daf_0            conda-forge      138kB\n",
            "  \u001b[32m+ pthread-stubs            \u001b[0m         0.4  hb9d3cd8_1002         conda-forge        8kB\n",
            "  \u001b[32m+ xorg-libxdmcp            \u001b[0m       1.1.5  hb9d3cd8_0            conda-forge       20kB\n",
            "  \u001b[32m+ xorg-libxau              \u001b[0m      1.0.12  hb9d3cd8_0            conda-forge       15kB\n",
            "  \u001b[32m+ lame                     \u001b[0m       3.100  h166bdaf_1003         conda-forge      508kB\n",
            "  \u001b[32m+ libopus                  \u001b[0m       1.3.1  h7f98852_1            conda-forge      261kB\n",
            "  \u001b[32m+ mpg123                   \u001b[0m      1.32.9  hc50e24c_0            conda-forge      491kB\n",
            "  \u001b[32m+ libgfortran5             \u001b[0m      14.2.0  hf1ad2bd_2            conda-forge        1MB\n",
            "  \u001b[32m+ pcre2                    \u001b[0m       10.44  hba22ea6_2            conda-forge      952kB\n",
            "  \u001b[32m+ libgpg-error             \u001b[0m        1.51  hbd13f7d_1            conda-forge      269kB\n",
            "  \u001b[32m+ gettext-tools            \u001b[0m      0.23.1  h5888daf_0            conda-forge        3MB\n",
            "  \u001b[32m+ libasprintf              \u001b[0m      0.23.1  h8e693c7_0            conda-forge       43kB\n",
            "  \u001b[32m+ libgettextpo             \u001b[0m      0.23.1  h5888daf_0            conda-forge      167kB\n",
            "  \u001b[32m+ attr                     \u001b[0m       2.5.1  h166bdaf_1            conda-forge       71kB\n",
            "  \u001b[32m+ libglvnd                 \u001b[0m       1.7.0  ha4b6fd6_2            conda-forge      132kB\n",
            "  \u001b[32m+ libjpeg-turbo            \u001b[0m       3.0.0  hd590300_1            conda-forge      619kB\n",
            "  \u001b[32m+ xorg-libice              \u001b[0m       1.1.2  hb9d3cd8_0            conda-forge       59kB\n",
            "  \u001b[32m+ graphite2                \u001b[0m      1.3.13  h59595ed_1003         conda-forge       97kB\n",
            "  \u001b[32m+ pixman                   \u001b[0m      0.44.2  h29eaf8c_0            conda-forge      381kB\n",
            "  \u001b[32m+ libntlm                  \u001b[0m         1.8  hb9d3cd8_0            conda-forge       33kB\n",
            "  \u001b[32m+ zlib                     \u001b[0m       1.3.1  hb9d3cd8_2            conda-forge       92kB\n",
            "  \u001b[32m+ libaec                   \u001b[0m       1.1.3  h59595ed_0            conda-forge       35kB\n",
            "  \u001b[32m+ snappy                   \u001b[0m       1.2.1  h8bd8927_1            conda-forge       43kB\n",
            "  \u001b[32m+ nss                      \u001b[0m       3.107  hdf54f9c_0            conda-forge        2MB\n",
            "  \u001b[32m+ libvorbis                \u001b[0m       1.3.7  h9c3ff4c_0            conda-forge      286kB\n",
            "  \u001b[32m+ libdrm                   \u001b[0m     2.4.124  hb9d3cd8_0            conda-forge      243kB\n",
            "  \u001b[32m+ freetype                 \u001b[0m      2.12.1  h267a509_2            conda-forge      635kB\n",
            "  \u001b[32m+ libxcb                   \u001b[0m      1.17.0  h8a09558_0            conda-forge      396kB\n",
            "  \u001b[32m+ libgfortran              \u001b[0m      14.2.0  h69a702a_2            conda-forge       54kB\n",
            "  \u001b[32m+ libglib                  \u001b[0m      2.82.2  h2ff4ddf_1            conda-forge        4MB\n",
            "  \u001b[32m+ libgcrypt-lib            \u001b[0m      1.11.0  hb9d3cd8_2            conda-forge      586kB\n",
            "  \u001b[32m+ libasprintf-devel        \u001b[0m      0.23.1  h8e693c7_0            conda-forge       34kB\n",
            "  \u001b[32m+ libgettextpo-devel       \u001b[0m      0.23.1  h5888daf_0            conda-forge       37kB\n",
            "  \u001b[32m+ libcap                   \u001b[0m        2.71  h39aace5_0            conda-forge      102kB\n",
            "  \u001b[32m+ libegl                   \u001b[0m       1.7.0  ha4b6fd6_2            conda-forge       45kB\n",
            "  \u001b[32m+ hdf4                     \u001b[0m      4.2.15  h2a13503_7            conda-forge      757kB\n",
            "  \u001b[32m+ xorg-libsm               \u001b[0m       1.2.5  he73a12e_0            conda-forge       27kB\n",
            "  \u001b[32m+ blosc                    \u001b[0m      1.21.6  he440d0b_1            conda-forge       48kB\n",
            "  \u001b[32m+ libzip                   \u001b[0m      1.11.2  h6991a6a_0            conda-forge      109kB\n",
            "  \u001b[32m+ mysql-common             \u001b[0m       9.0.1  h266115a_4            conda-forge      620kB\n",
            "  \u001b[32m+ cyrus-sasl               \u001b[0m      2.1.27  h54b06d7_7            conda-forge      220kB\n",
            "  \u001b[32m+ libevent                 \u001b[0m      2.1.12  hf998b51_1            conda-forge      427kB\n",
            "  \u001b[32m+ libllvm19                \u001b[0m      19.1.7  ha7bfdaf_1            conda-forge       40MB\n",
            "  \u001b[32m+ fontconfig               \u001b[0m      2.15.0  h7e30c49_1            conda-forge      266kB\n",
            "  \u001b[32m+ xcb-util-wm              \u001b[0m       0.4.2  hb711507_0            conda-forge       52kB\n",
            "  \u001b[32m+ xcb-util-renderutil      \u001b[0m      0.3.10  hb711507_0            conda-forge       17kB\n",
            "  \u001b[32m+ xcb-util-keysyms         \u001b[0m       0.4.1  hb711507_0            conda-forge       14kB\n",
            "  \u001b[32m+ xcb-util                 \u001b[0m       0.4.1  hb711507_2            conda-forge       20kB\n",
            "  \u001b[32m+ xorg-libx11              \u001b[0m      1.8.11  h4f16b4b_0            conda-forge      835kB\n",
            "  \u001b[32m+ hdf5                     \u001b[0m      1.14.4  nompi_h2d575fe_105    conda-forge        4MB\n",
            "  \u001b[32m+ libopenblas              \u001b[0m      0.3.29  pthreads_h94d23a6_0   conda-forge        6MB\n",
            "  \u001b[32m+ glib-tools               \u001b[0m      2.82.2  h4833e2c_1            conda-forge      115kB\n",
            "  \u001b[32m+ dbus                     \u001b[0m      1.13.6  h5008d03_3            conda-forge      619kB\n",
            "  \u001b[32m+ gettext                  \u001b[0m      0.23.1  h5888daf_0            conda-forge      484kB\n",
            "  \u001b[32m+ libsystemd0              \u001b[0m       257.2  h3dc2cb9_0            conda-forge      488kB\n",
            "  \u001b[32m+ mysql-libs               \u001b[0m       9.0.1  he0572af_4            conda-forge        1MB\n",
            "  \u001b[32m+ openldap                 \u001b[0m       2.6.9  he970967_0            conda-forge      784kB\n",
            "  \u001b[32m+ libclang13               \u001b[0m      19.1.7  default_h9c6a7e4_1    conda-forge       12MB\n",
            "  \u001b[32m+ libclang-cpp19.1         \u001b[0m      19.1.7  default_hb5137d0_1    conda-forge       21MB\n",
            "  \u001b[32m+ xcb-util-image           \u001b[0m       0.4.0  hb711507_2            conda-forge       25kB\n",
            "  \u001b[32m+ xkeyboard-config         \u001b[0m        2.43  hb9d3cd8_0            conda-forge      389kB\n",
            "  \u001b[32m+ libglx                   \u001b[0m       1.7.0  ha4b6fd6_2            conda-forge       76kB\n",
            "  \u001b[32m+ xorg-libxrender          \u001b[0m      0.9.12  hb9d3cd8_0            conda-forge       33kB\n",
            "  \u001b[32m+ xorg-libxext             \u001b[0m       1.3.6  hb9d3cd8_0            conda-forge       50kB\n",
            "  \u001b[32m+ xorg-libxfixes           \u001b[0m       6.0.1  hb9d3cd8_0            conda-forge       20kB\n",
            "  \u001b[32m+ libnetcdf                \u001b[0m       4.9.2  nompi_h5ddbaa4_116    conda-forge      833kB\n",
            "  \u001b[32m+ libblas                  \u001b[0m       3.9.0  31_h59b9bed_openblas  conda-forge       17kB\n",
            "  \u001b[32m+ glib                     \u001b[0m      2.82.2  h07242d1_1            conda-forge      602kB\n",
            "  \u001b[32m+ libflac                  \u001b[0m       1.4.3  h59595ed_0            conda-forge      394kB\n",
            "  \u001b[32m+ libpq                    \u001b[0m        17.4  h27ae623_0            conda-forge        3MB\n",
            "  \u001b[32m+ libxkbcommon             \u001b[0m       1.8.0  hc4a0caf_0            conda-forge      642kB\n",
            "  \u001b[32m+ libgl                    \u001b[0m       1.7.0  ha4b6fd6_2            conda-forge      135kB\n",
            "  \u001b[32m+ xorg-libxxf86vm          \u001b[0m       1.1.6  hb9d3cd8_0            conda-forge       18kB\n",
            "  \u001b[32m+ xorg-libxdamage          \u001b[0m       1.1.6  hb9d3cd8_0            conda-forge       13kB\n",
            "  \u001b[32m+ libcblas                 \u001b[0m       3.9.0  31_he106b2a_openblas  conda-forge       17kB\n",
            "  \u001b[32m+ liblapack                \u001b[0m       3.9.0  31_h7ac8fdf_openblas  conda-forge       17kB\n",
            "  \u001b[32m+ gstreamer                \u001b[0m      1.24.7  hf3bb09a_0            conda-forge        2MB\n",
            "  \u001b[32m+ libsndfile               \u001b[0m       1.2.2  hc60ed4a_1            conda-forge      354kB\n",
            "  \u001b[32m+ libglu                   \u001b[0m       9.0.3  h03adeef_0            conda-forge      325kB\n",
            "  \u001b[32m+ numpy                    \u001b[0m       2.2.3  py311h5d046bc_0       conda-forge        9MB\n",
            "  \u001b[32m+ gst-plugins-base         \u001b[0m      1.24.7  h0a52356_0            conda-forge        3MB\n",
            "  \u001b[32m+ pulseaudio-client        \u001b[0m        17.0  hb77b528_0            conda-forge      758kB\n",
            "  \u001b[32m+ glew                     \u001b[0m       2.1.0  h9c3ff4c_2            conda-forge      663kB\n",
            "  \u001b[32m+ toml                     \u001b[0m      0.10.2  pyhd8ed1ab_1          conda-forge       22kB\n",
            "  \u001b[32m+ font-ttf-dejavu-sans-mono\u001b[0m        2.37  hab24e00_0            conda-forge      397kB\n",
            "  \u001b[32m+ font-ttf-inconsolata     \u001b[0m       3.000  h77eed37_0            conda-forge       97kB\n",
            "  \u001b[32m+ font-ttf-source-code-pro \u001b[0m       2.038  h77eed37_0            conda-forge      701kB\n",
            "  \u001b[32m+ font-ttf-ubuntu          \u001b[0m        0.83  h77eed37_3            conda-forge        2MB\n",
            "  \u001b[32m+ ply                      \u001b[0m        3.11  pyhd8ed1ab_3          conda-forge       49kB\n",
            "  \u001b[32m+ tomli                    \u001b[0m       2.2.1  pyhd8ed1ab_1          conda-forge       19kB\n",
            "  \u001b[32m+ fonts-conda-forge        \u001b[0m           1  0                     conda-forge        4kB\n",
            "  \u001b[32m+ fonts-conda-ecosystem    \u001b[0m           1  0                     conda-forge        4kB\n",
            "  \u001b[32m+ sip                      \u001b[0m      6.7.12  py311hb755f60_0       conda-forge      585kB\n",
            "  \u001b[32m+ cairo                    \u001b[0m      1.18.4  h3394656_0            conda-forge      978kB\n",
            "  \u001b[32m+ pyqt5-sip                \u001b[0m     12.12.2  py311hb755f60_5       conda-forge       85kB\n",
            "  \u001b[32m+ harfbuzz                 \u001b[0m      10.4.0  h76408a6_0            conda-forge        2MB\n",
            "  \u001b[32m+ qt-main                  \u001b[0m     5.15.15  hc3cb62f_2            conda-forge       53MB\n",
            "  \u001b[32m+ pyqt                     \u001b[0m      5.15.9  py311hf0fb5b6_5       conda-forge        5MB\n",
            "  \u001b[32m+ pymol-open-source        \u001b[0m       3.1.0  py311h392c68e_0       conda-forge        7MB\n",
            "\n",
            "  Change:\n",
            "─────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "  \u001b[31m- libxml2                  \u001b[0m      2.13.5  h0d44e9d_1            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ libxml2                  \u001b[0m      2.13.5  h8d12d68_1            conda-forge      691kB\n",
            "\n",
            "  Upgrade:\n",
            "─────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "  \u001b[31m- ca-certificates          \u001b[0m  2024.12.14  hbcca054_0            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ ca-certificates          \u001b[0m   2025.1.31  hbcca054_0            conda-forge      158kB\n",
            "  \u001b[31m- openssl                  \u001b[0m       3.4.0  h7b32b05_1            conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ openssl                  \u001b[0m       3.4.1  h7b32b05_0            conda-forge        3MB\n",
            "  \u001b[31m- certifi                  \u001b[0m  2024.12.14  pyhd8ed1ab_0          conda-forge\u001b[32m     Cached\u001b[0m\n",
            "  \u001b[32m+ certifi                  \u001b[0m   2025.1.31  pyhd8ed1ab_0          conda-forge      163kB\n",
            "\n",
            "  Summary:\n",
            "\n",
            "  Install: 108 packages\n",
            "  Change: 1 packages\n",
            "  Upgrade: 3 packages\n",
            "\n",
            "  Total download: 223MB\n",
            "\n",
            "─────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "\n",
            "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
            "Downloading        0%\n",
            "Extracting         0%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
            "Downloading  (5)   1%\n",
            "Extracting         0%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gglm                                                217.8kB @   2.0MB/s  0.1s\n",
            "ca-certificates                                    158.1kB @   1.2MB/s  0.1s\n",
            "pmw                                                640.2kB @   4.2MB/s  0.2s\n",
            "alsa-lib                                           560.2kB @   3.5MB/s  0.1s\n",
            "libpciaccess                                        28.4kB @ 159.8kB/s  0.0s\n",
            "pthread-stubs                                        8.3kB @  41.2kB/s  0.0s\n",
            "[+] 0.2s\n",
            "Downloading  (5)   4%\n",
            "Extracting   (5)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibcups                                              4.5MB @  21.2MB/s  0.2s\n",
            "lame                                               508.3kB @   2.2MB/s  0.1s\n",
            "libasprintf                                         43.2kB @ 171.0kB/s  0.0s\n",
            "xorg-libice                                         58.6kB @ 214.5kB/s  0.0s\n",
            "libgfortran5                                         1.5MB @   5.2MB/s  0.1s\n",
            "[+] 0.3s\n",
            "Downloading  (5)   7%\n",
            "Extracting  (10)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Ggraphite2                                           96.9kB @ 323.7kB/s  0.0s\n",
            "snappy                                              42.7kB @ 134.7kB/s  0.0s\n",
            "gettext-tools                                        3.0MB @   9.1MB/s  0.1s\n",
            "libvorbis                                          286.3kB @ 847.1kB/s  0.0s\n",
            "nss                                                  2.0MB @   5.5MB/s  0.1s\n",
            "libgettextpo-devel                                  36.8kB @ 100.2kB/s  0.0s\n",
            "[+] 0.4s\n",
            "Downloading  (5)  11%\n",
            "Extracting  (15)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibzip                                             109.0kB @ 262.9kB/s  0.0s\n",
            "hdf4                                               756.7kB @   1.8MB/s  0.1s\n",
            "mysql-common                                       619.5kB @   1.4MB/s  0.1s\n",
            "xcb-util-wm                                         51.7kB @ 113.9kB/s  0.0s\n",
            "xcb-util-renderutil                                 17.0kB @  37.4kB/s  0.0s\n",
            "icu                                                 12.1MB @  25.2MB/s  0.5s\n",
            "libglib                                              3.9MB @   8.1MB/s  0.2s\n",
            "[+] 0.5s\n",
            "Downloading  (5)  15%\n",
            "Extracting  (22)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gxcb-util-image                                      24.6kB @  45.4kB/s  0.1s\n",
            "xorg-libxrender                                     33.0kB @  61.0kB/s  0.1s\n",
            "gettext                                            484.3kB @ 863.9kB/s  0.1s\n",
            "libsystemd0                                        487.7kB @ 861.0kB/s  0.1s\n",
            "libblas                                             16.9kB @  28.8kB/s  0.0s\n",
            "libnetcdf                                          832.8kB @   1.4MB/s  0.0s\n",
            "[+] 0.6s\n",
            "Downloading  (5)  16%\n",
            "Extracting  (26)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibxkbcommon                                       642.3kB @   1.1MB/s  0.0s\n",
            "libopenblas                                          5.9MB @   9.5MB/s  0.2s\n",
            "libsndfile                                         354.4kB @ 546.0kB/s  0.1s\n",
            "certifi                                            162.7kB @ 243.5kB/s  0.1s\n",
            "font-ttf-inconsolata                                96.5kB @ 143.1kB/s  0.0s\n",
            "[+] 0.7s\n",
            "Downloading  (5)  19%\n",
            "Extracting  (31)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gtomli                                               19.2kB @  27.3kB/s  0.0s\n",
            "ply                                                 49.1kB @  68.7kB/s  0.0s\n",
            "libpq                                                2.6MB @   3.6MB/s  0.2s\n",
            "sip                                                585.2kB @ 803.5kB/s  0.1s\n",
            "gst-plugins-base                                     2.8MB @   3.7MB/s  0.2s\n",
            "xorg-libxdmcp                                       19.9kB @  25.7kB/s  0.0s\n",
            "xorg-libxau                                         14.8kB @  19.1kB/s  0.1s\n",
            "[+] 0.8s\n",
            "Downloading  (5)  22%\n",
            "Extracting  (38)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibgettextpo                                       166.9kB @ 204.5kB/s  0.0s\n",
            "attr                                                71.0kB @  87.0kB/s  0.0s\n",
            "libglvnd                                           132.5kB @ 162.2kB/s  0.0s\n",
            "libdrm                                             242.5kB @ 282.7kB/s  0.0s\n",
            "[+] 0.9s\n",
            "Downloading  (5)  27%\n",
            "Extracting  (41)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gxorg-libsm                                          27.2kB @  30.0kB/s  0.1s\n",
            "libxml2                                            690.6kB @ 759.6kB/s  0.1s\n",
            "freetype                                           635.0kB @ 696.4kB/s  0.1s\n",
            "pyqt                                                 5.3MB @   5.8MB/s  0.2s\n",
            "pymol-open-source                                    6.9MB @   7.4MB/s  0.2s\n",
            "blosc                                               48.4kB @  51.2kB/s  0.0s\n",
            "fontconfig                                         265.6kB @ 279.7kB/s  0.0s\n",
            "xorg-libx11                                        835.2kB @ 874.8kB/s  0.0s\n",
            "[+] 1.0s\n",
            "Downloading  (5)  29%\n",
            "Extracting  (48)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gxorg-libxext                                        50.1kB @  50.3kB/s  0.1s\n",
            "openldap                                           784.5kB @ 782.0kB/s  0.1s\n",
            "libflac                                            394.4kB @ 387.2kB/s  0.1s\n",
            "xorg-libxdamage                                     13.2kB @  12.9kB/s  0.1s\n",
            "libglu                                             325.4kB @ 312.1kB/s  0.0s\n",
            "mysql-libs                                           1.4MB @   1.3MB/s  0.1s\n",
            "toml                                                22.1kB @  20.7kB/s  0.1s\n",
            "pyqt5-sip                                           85.2kB @  78.9kB/s  0.0s\n",
            "[+] 1.1s\n",
            "Downloading  (6)  30%\n",
            "Extracting  (56)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gfont-ttf-dejavu-sans-mono                          397.4kB @ 363.8kB/s  0.1s\n",
            "libopus                                            260.7kB @ 231.8kB/s  0.0s\n",
            "libaec                                              35.4kB @  30.5kB/s  0.0s\n",
            "libjpeg-turbo                                      618.6kB @ 526.6kB/s  0.1s\n",
            "gstreamer                                            2.0MB @   1.7MB/s  0.2s\n",
            "[+] 1.2s\n",
            "Downloading  (5)  32%\n",
            "Extracting  (60)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibgfortran                                         53.7kB @  44.5kB/s  0.0s\n",
            "harfbuzz                                             1.7MB @   1.4MB/s  0.1s\n",
            "libcap                                             102.3kB @  83.7kB/s  0.0s\n",
            "libegl                                              44.8kB @  36.3kB/s  0.1s\n",
            "xcb-util-keysyms                                    14.3kB @  11.4kB/s  0.0s\n",
            "glib-tools                                         115.5kB @  91.5kB/s  0.0s\n",
            "[+] 1.3s\n",
            "Downloading  (5)  34%\n",
            "Extracting  (65)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibgl                                              134.7kB @ 102.2kB/s  0.1s\n",
            "xkeyboard-config                                   389.5kB @ 294.9kB/s  0.1s\n",
            "glib                                               602.3kB @ 454.7kB/s  0.1s\n",
            "pulseaudio-client                                  757.6kB @ 571.2kB/s  0.1s\n",
            "libpng                                             288.7kB @ 211.3kB/s  0.0s\n",
            "glew                                               662.6kB @ 484.2kB/s  0.1s\n",
            "expat                                              138.1kB @ 100.8kB/s  0.0s\n",
            "fonts-conda-ecosystem                                3.7kB @   2.7kB/s  0.1s\n",
            "[+] 1.4s\n",
            "Downloading  (5)  37%\n",
            "Extracting  (73)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibntlm                                             33.4kB @  23.8kB/s  0.0s\n",
            "libxcb                                             395.9kB @ 280.6kB/s  0.0s\n",
            "libgcrypt-lib                                      586.2kB @ 415.4kB/s  0.0s\n",
            "xcb-util                                            20.0kB @  14.0kB/s  0.0s\n",
            "xorg-libxxf86vm                                     17.8kB @  12.3kB/s  0.0s\n",
            "xorg-libxfixes                                      19.6kB @  13.4kB/s  0.1s\n",
            "[+] 1.5s\n",
            "Downloading  (5)  43%\n",
            "Extracting  (77)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnspr                                               230.2kB @ 149.7kB/s  0.1s\n",
            "libogg                                             205.9kB @ 133.9kB/s  0.1s\n",
            "font-ttf-ubuntu                                      1.6MB @   1.0MB/s  0.1s\n",
            "zlib                                                92.3kB @  58.3kB/s  0.0s\n",
            "[+] 1.6s\n",
            "Downloading  (5)  46%\n",
            "Extracting  (80)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibglx                                              75.5kB @  46.7kB/s  0.0s\n",
            "openssl                                              2.9MB @   1.8MB/s  0.1s\n",
            "[+] 1.7s\n",
            "Downloading  (5)  52%\n",
            "Extracting  (81)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gcairo                                              978.1kB @ 554.2kB/s  0.1s\n",
            "hdf5                                                 4.0MB @   2.2MB/s  0.2s\n",
            "[+] 1.8s\n",
            "Downloading  (5)  55%\n",
            "Extracting  (82)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibgpg-error                                       268.7kB @ 146.8kB/s  0.1s\n",
            "cyrus-sasl                                         219.5kB @ 120.0kB/s  0.1s\n",
            "libclang13                                          11.8MB @   6.3MB/s  0.5s\n",
            "[+] 1.9s\n",
            "Downloading  (5)  61%\n",
            "Extracting  (83)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gdbus                                               618.6kB @ 325.5kB/s  0.1s\n",
            "mpg123                                             491.1kB @ 252.0kB/s  0.1s\n",
            "libasprintf-devel                                   34.3kB @  17.6kB/s  0.0s\n",
            "numpy                                                9.1MB @   4.6MB/s  0.4s\n",
            "liblapack                                           16.8kB @   8.5kB/s  0.0s\n",
            "libcblas                                            16.8kB @   8.4kB/s  0.0s\n",
            "[+] 2.0s\n",
            "Downloading  (5)  65%\n",
            "Extracting  (87)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibevent                                           427.4kB @ 209.2kB/s  0.1s\n",
            "pcre2                                              952.3kB @ 464.5kB/s  0.1s\n",
            "fonts-conda-forge                                    4.1kB @   2.0kB/s  0.0s\n",
            "font-ttf-source-code-pro                           700.8kB @ 334.3kB/s  0.1s\n",
            "[+] 2.1s\n",
            "Downloading  (4)  72%\n",
            "Extracting  (89)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpixman                                             381.1kB @ 178.1kB/s  0.0s\n",
            "[+] 2.2s\n",
            "Downloading  (3)  85%\n",
            "Extracting  (92)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibclang-cpp19.1                                    20.5MB @   9.3MB/s  0.4s\n",
            "qt-main                                             52.6MB @  23.7MB/s  1.1s\n",
            "[+] 2.3s\n",
            "Downloading  (1)  91%\n",
            "Extracting  (92)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.4s\n",
            "Downloading  (1)  94%\n",
            "Extracting  (92)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
            "Downloading  (1)  95%\n",
            "Extracting  (91)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.6s\n",
            "Downloading  (1)  98%\n",
            "Extracting  (90)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibllvm19                                           40.1MB @  15.0MB/s  0.7s\n",
            "[+] 2.7s\n",
            "Downloading      100%\n",
            "Extracting  (91)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
            "Downloading      100%\n",
            "Extracting  (91)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.9s\n",
            "Downloading      100%\n",
            "Extracting  (91)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.0s\n",
            "Downloading      100%\n",
            "Extracting  (90)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.1s\n",
            "Downloading      100%\n",
            "Extracting  (89)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.2s\n",
            "Downloading      100%\n",
            "Extracting  (88)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.3s\n",
            "Downloading      100%\n",
            "Extracting  (86)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.4s\n",
            "Downloading      100%\n",
            "Extracting  (84)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.5s\n",
            "Downloading      100%\n",
            "Extracting  (82)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.6s\n",
            "Downloading      100%\n",
            "Extracting  (80)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.7s\n",
            "Downloading      100%\n",
            "Extracting  (79)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.8s\n",
            "Downloading      100%\n",
            "Extracting  (76)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.9s\n",
            "Downloading      100%\n",
            "Extracting  (73)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.0s\n",
            "Downloading      100%\n",
            "Extracting  (72)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.1s\n",
            "Downloading      100%\n",
            "Extracting  (72)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.2s\n",
            "Downloading      100%\n",
            "Extracting  (72)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.3s\n",
            "Downloading      100%\n",
            "Extracting  (72)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.4s\n",
            "Downloading      100%\n",
            "Extracting  (72)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.5s\n",
            "Downloading      100%\n",
            "Extracting  (72)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.6s\n",
            "Downloading      100%\n",
            "Extracting  (72)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.7s\n",
            "Downloading      100%\n",
            "Extracting  (71)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.8s\n",
            "Downloading      100%\n",
            "Extracting  (71)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.9s\n",
            "Downloading      100%\n",
            "Extracting  (71)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.0s\n",
            "Downloading      100%\n",
            "Extracting  (71)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.1s\n",
            "Downloading      100%\n",
            "Extracting  (71)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.2s\n",
            "Downloading      100%\n",
            "Extracting  (71)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.3s\n",
            "Downloading      100%\n",
            "Extracting  (71)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.4s\n",
            "Downloading      100%\n",
            "Extracting  (71)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.5s\n",
            "Downloading      100%\n",
            "Extracting  (71)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.6s\n",
            "Downloading      100%\n",
            "Extracting  (71)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.7s\n",
            "Downloading      100%\n",
            "Extracting  (70)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.8s\n",
            "Downloading      100%\n",
            "Extracting  (70)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.9s\n",
            "Downloading      100%\n",
            "Extracting  (70)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.0s\n",
            "Downloading      100%\n",
            "Extracting  (70)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.1s\n",
            "Downloading      100%\n",
            "Extracting  (70)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.2s\n",
            "Downloading      100%\n",
            "Extracting  (70)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.3s\n",
            "Downloading      100%\n",
            "Extracting  (69)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.4s\n",
            "Downloading      100%\n",
            "Extracting  (69)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.5s\n",
            "Downloading      100%\n",
            "Extracting  (69)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.6s\n",
            "Downloading      100%\n",
            "Extracting  (69)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.7s\n",
            "Downloading      100%\n",
            "Extracting  (69)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.8s\n",
            "Downloading      100%\n",
            "Extracting  (68)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.9s\n",
            "Downloading      100%\n",
            "Extracting  (67)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.0s\n",
            "Downloading      100%\n",
            "Extracting  (66)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.1s\n",
            "Downloading      100%\n",
            "Extracting  (64)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.2s\n",
            "Downloading      100%\n",
            "Extracting  (63)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.3s\n",
            "Downloading      100%\n",
            "Extracting  (63)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.4s\n",
            "Downloading      100%\n",
            "Extracting  (63)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.5s\n",
            "Downloading      100%\n",
            "Extracting  (62)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.6s\n",
            "Downloading      100%\n",
            "Extracting  (61)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.7s\n",
            "Downloading      100%\n",
            "Extracting  (61)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.8s\n",
            "Downloading      100%\n",
            "Extracting  (61)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.9s\n",
            "Downloading      100%\n",
            "Extracting  (60)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.0s\n",
            "Downloading      100%\n",
            "Extracting  (59)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.1s\n",
            "Downloading      100%\n",
            "Extracting  (59)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.2s\n",
            "Downloading      100%\n",
            "Extracting  (58)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.3s\n",
            "Downloading      100%\n",
            "Extracting  (56)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.4s\n",
            "Downloading      100%\n",
            "Extracting  (55)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.5s\n",
            "Downloading      100%\n",
            "Extracting  (54)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.6s\n",
            "Downloading      100%\n",
            "Extracting  (53)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.7s\n",
            "Downloading      100%\n",
            "Extracting  (53)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.8s\n",
            "Downloading      100%\n",
            "Extracting  (52)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.9s\n",
            "Downloading      100%\n",
            "Extracting  (51)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.0s\n",
            "Downloading      100%\n",
            "Extracting  (51)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.1s\n",
            "Downloading      100%\n",
            "Extracting  (51)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.2s\n",
            "Downloading      100%\n",
            "Extracting  (51)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.3s\n",
            "Downloading      100%\n",
            "Extracting  (51)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.4s\n",
            "Downloading      100%\n",
            "Extracting  (51)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.5s\n",
            "Downloading      100%\n",
            "Extracting  (51)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.6s\n",
            "Downloading      100%\n",
            "Extracting  (51)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.7s\n",
            "Downloading      100%\n",
            "Extracting  (50)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.8s\n",
            "Downloading      100%\n",
            "Extracting  (49)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.9s\n",
            "Downloading      100%\n",
            "Extracting  (48)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.0s\n",
            "Downloading      100%\n",
            "Extracting  (48)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.1s\n",
            "Downloading      100%\n",
            "Extracting  (48)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.2s\n",
            "Downloading      100%\n",
            "Extracting  (48)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.3s\n",
            "Downloading      100%\n",
            "Extracting  (48)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.4s\n",
            "Downloading      100%\n",
            "Extracting  (47)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.5s\n",
            "Downloading      100%\n",
            "Extracting  (47)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.6s\n",
            "Downloading      100%\n",
            "Extracting  (46)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.7s\n",
            "Downloading      100%\n",
            "Extracting  (46)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.8s\n",
            "Downloading      100%\n",
            "Extracting  (45)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.9s\n",
            "Downloading      100%\n",
            "Extracting  (44)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.0s\n",
            "Downloading      100%\n",
            "Extracting  (44)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.1s\n",
            "Downloading      100%\n",
            "Extracting  (44)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.2s\n",
            "Downloading      100%\n",
            "Extracting  (44)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.3s\n",
            "Downloading      100%\n",
            "Extracting  (44)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.4s\n",
            "Downloading      100%\n",
            "Extracting  (43)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.5s\n",
            "Downloading      100%\n",
            "Extracting  (43)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.6s\n",
            "Downloading      100%\n",
            "Extracting  (43)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.7s\n",
            "Downloading      100%\n",
            "Extracting  (43)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.8s\n",
            "Downloading      100%\n",
            "Extracting  (43)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.9s\n",
            "Downloading      100%\n",
            "Extracting  (42)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.0s\n",
            "Downloading      100%\n",
            "Extracting  (41)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.1s\n",
            "Downloading      100%\n",
            "Extracting  (40)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.2s\n",
            "Downloading      100%\n",
            "Extracting  (40)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.3s\n",
            "Downloading      100%\n",
            "Extracting  (39)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.4s\n",
            "Downloading      100%\n",
            "Extracting  (38)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.5s\n",
            "Downloading      100%\n",
            "Extracting  (37)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.6s\n",
            "Downloading      100%\n",
            "Extracting  (37)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.7s\n",
            "Downloading      100%\n",
            "Extracting  (36)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.8s\n",
            "Downloading      100%\n",
            "Extracting  (35)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.9s\n",
            "Downloading      100%\n",
            "Extracting  (35)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.0s\n",
            "Downloading      100%\n",
            "Extracting  (34)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.1s\n",
            "Downloading      100%\n",
            "Extracting  (34)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.2s\n",
            "Downloading      100%\n",
            "Extracting  (34)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.3s\n",
            "Downloading      100%\n",
            "Extracting  (34)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.4s\n",
            "Downloading      100%\n",
            "Extracting  (32)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.5s\n",
            "Downloading      100%\n",
            "Extracting  (31)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.6s\n",
            "Downloading      100%\n",
            "Extracting  (30)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.7s\n",
            "Downloading      100%\n",
            "Extracting  (29)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.8s\n",
            "Downloading      100%\n",
            "Extracting  (28)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.9s\n",
            "Downloading      100%\n",
            "Extracting  (26)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.0s\n",
            "Downloading      100%\n",
            "Extracting  (26)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.1s\n",
            "Downloading      100%\n",
            "Extracting  (24)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.2s\n",
            "Downloading      100%\n",
            "Extracting  (21)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.3s\n",
            "Downloading      100%\n",
            "Extracting  (20)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.4s\n",
            "Downloading      100%\n",
            "Extracting  (18)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.5s\n",
            "Downloading      100%\n",
            "Extracting  (16)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.6s\n",
            "Downloading      100%\n",
            "Extracting  (14)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.7s\n",
            "Downloading      100%\n",
            "Extracting  (11)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.8s\n",
            "Downloading      100%\n",
            "Extracting   (9)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.9s\n",
            "Downloading      100%\n",
            "Extracting   (8)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 15.0s\n",
            "Downloading      100%\n",
            "Extracting   (7)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 15.1s\n",
            "Downloading      100%\n",
            "Extracting   (6)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 15.2s\n",
            "Downloading      100%\n",
            "Extracting   (4)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 15.3s\n",
            "Downloading      100%\n",
            "Extracting   (3)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 15.4s\n",
            "Downloading      100%\n",
            "Extracting   (2)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\n",
            "Downloading and Extracting Packages:\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n"
          ]
        }
      ],
      "source": [
        "# @markdown # Step 1: Install all neccessary packages\n",
        "# Install all necessary packages\n",
        "!pip install biopython\n",
        "!pip install --upgrade tqdm\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "# Install PyMOL using Conda\n",
        "!mamba install -c conda-forge pymol-open-source -y\n",
        "\n",
        "# Import necessary modules\n",
        "from Bio.PDB import PDBParser, Selection, NeighborSearch\n",
        "from Bio.PDB.Polypeptide import is_aa\n",
        "from tqdm import tqdm\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6Q3_F6_hbkUp"
      },
      "outputs": [],
      "source": [
        "#@markdown # Step 2: Mutate the glycine to alanine\n",
        "#@markdown # **Please remove all water molecules and ligands before running.**\n",
        "\n",
        "# Import the necessary modules\n",
        "import pymol2\n",
        "\n",
        "#@markdown **Note:** Specify the paths to the input and output PDB files below.\n",
        "\n",
        "#@markdown ### Enter the path to your input PDB file:\n",
        "pdb_file_path = \"/content/3tis_run.pdb\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Enter the path to your output PDB file:\n",
        "output_file_path = \"/content/3tis_run_alanine.pdb\"  #@param {type:\"string\"}\n",
        "\n",
        "# Create an instance of the PyMOL session\n",
        "with pymol2.PyMOL() as pymol:\n",
        "    # Initialize PyMOL\n",
        "    pymol.cmd.reinitialize()\n",
        "\n",
        "    # Load the structure file\n",
        "    pymol.cmd.load(pdb_file_path)\n",
        "\n",
        "    # Identify glycine residues\n",
        "    glycine_residues = pymol.cmd.get_model(\"resn GLY\").atom\n",
        "\n",
        "    # Loop through glycine residues\n",
        "    for atom in glycine_residues:\n",
        "        residue_num = atom.resi\n",
        "        chain = atom.chain\n",
        "        # Construct the selection string in the format \"resi X and chain Y\"\n",
        "        selection_str = f\"resi {residue_num} and chain {chain}\"\n",
        "        # Apply the mutation using the mutagenesis command\n",
        "        pymol.cmd.wizard(\"mutagenesis\")\n",
        "        pymol.cmd.refresh_wizard()\n",
        "        pymol.cmd.get_wizard().do_select(selection_str)\n",
        "        pymol.cmd.get_wizard().set_mode(\"ALA\")\n",
        "        pymol.cmd.get_wizard().apply()\n",
        "        pymol.cmd.delete(selection_str)  # Delete the original residue to avoid clashes\n",
        "\n",
        "    # Save the mutated structure\n",
        "    pymol.cmd.save(output_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sr9mhfr9R5zm"
      },
      "outputs": [],
      "source": [
        "# Existing imports and setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from Bio.PDB import PDBParser\n",
        "import itertools\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 3A: Run the Metal-Installer\n",
        "\n",
        "# Import the necessary modules\n",
        "import pymol2\n",
        "from IPython.display import display, Markdown\n",
        "import requests  # Required for downloading files from GitHub\n",
        "\n",
        "# @markdown **Note:** Specify the paths to the input and output files below.\n",
        "\n",
        "# @markdown ### Enter the path to your input PDB file:\n",
        "pdb_file = \"/content/3tis_run_alanine.pdb\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Enter the path to your output Excel file:\n",
        "output_excel_file = \"/content/3tis_run_alanine_Cu_3His.xlsx\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "# @markdown ### Enter the path to your PyMOL script file:\n",
        "pymol_script_file = \"/content/3tis_run_alanine_Cu_3His.pml\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Set the metal type to use:\n",
        "Metal = 'Cu'  # @param [\"Zn\", \"Mn\", \"Cu\", \"Fe\"]\n",
        "\n",
        "# @markdown ### Select the combination type:\n",
        "# @markdown **Note:** 2His/1Cys is only available to Cu\n",
        "Combinations = '3His'  # @param [\"3His\", \"2His_1Asp\", \"2His_1Glu\", \"2His_1Cys\"]\n",
        "\n",
        "# @markdown ### Choose a threshold for analysis:\n",
        "Range = '4'  # @param [\"1\", \"2\", \"3\", \"4\",\"5\"]\n",
        "\n",
        "# @markdown ### Specify the specific residue number (use 0 for no specific residue):\n",
        "specific_residue_number = 24  # @param {type:\"integer\"}\n",
        "\n",
        "# Additional code to construct the URL for thresholds based on user input and download the file\n",
        "\n",
        "# Base URL for the thresholds files on GitHub\n",
        "base_url = \"https://raw.githubusercontent.com/SNU-Songlab/Metal-Installer-code/main/Threshold\"\n",
        "\n",
        "# Construct the full URL based on user input\n",
        "thresholds_url = f\"{base_url}/{Metal}/{Combinations}/{Range}.xlsx\"\n",
        "\n",
        "# Define the local path to save the downloaded file\n",
        "thresholds_file = \"/content/thresholds.xlsx\"  # This path will be used throughout the script\n",
        "\n",
        "# Download the file from GitHub\n",
        "response = requests.get(thresholds_url)\n",
        "\n",
        "# Check if the request was successful and save the file\n",
        "if response.status_code == 200:\n",
        "    with open(thresholds_file, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f\"File downloaded successfully from {thresholds_url} and saved as {thresholds_file}\")\n",
        "else:\n",
        "    raise ValueError(f\"Failed to download file from {thresholds_url}. Status code: {response.status_code}\")\n",
        "\n",
        "# Load thresholds from the downloaded Excel file\n",
        "thresholds_df = pd.read_excel(thresholds_file, sheet_name='Sheet1')\n",
        "\n",
        "# Extract threshold values\n",
        "thresholds = {}\n",
        "for _, row in thresholds_df.iterrows():\n",
        "    parameter = row['Parameter']\n",
        "    min_value = row['Min']\n",
        "    max_value = row['Max']\n",
        "\n",
        "    if pd.notna(min_value) and pd.notna(max_value):\n",
        "        thresholds[parameter] = (min_value, max_value)\n",
        "\n",
        "# Assign threshold values\n",
        "alpha_distance_range = thresholds['alpha_distance_range']\n",
        "beta_distance_range = thresholds['beta_distance_range']\n",
        "ratio_threshold_range = thresholds['ratio_threshold_range']\n",
        "pie_threshold_range = thresholds['pie_threshold_range']\n",
        "\n",
        "# PDB Parser setup\n",
        "parser = PDBParser(QUIET=True)\n",
        "structure = parser.get_structure('protein', pdb_file)\n",
        "model = structure[0]\n",
        "residues = [residue for residue in model.get_residues() if residue.get_id()[0] == ' ']\n",
        "\n",
        "# Step 1: Filter combinations to include specific residue number if specified\n",
        "if specific_residue_number != 0:\n",
        "    combinations = [\n",
        "        comb for comb in itertools.combinations(residues, 3)\n",
        "        if any(res.get_id()[1] == specific_residue_number for res in comb)\n",
        "    ]\n",
        "else:\n",
        "    combinations = list(itertools.combinations(residues, 3))\n",
        "\n",
        "# Distance filter\n",
        "filtered_data_distances = []\n",
        "\n",
        "for idx, combination in enumerate(combinations):\n",
        "    alpha_distances, beta_distances = [], []\n",
        "\n",
        "    try:\n",
        "        for res1, res2 in itertools.combinations(combination, 2):\n",
        "            if res1.has_id('CA') and res2.has_id('CA'):\n",
        "                ca1, ca2 = res1['CA'].coord, res2['CA'].coord\n",
        "                alpha_distance = np.linalg.norm(ca1 - ca2)\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            if res1.has_id('CB') and res2.has_id('CB'):\n",
        "                cb1, cb2 = res1['CB'].coord, res2['CB'].coord\n",
        "                beta_distance = np.linalg.norm(cb1 - cb2)\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            if (alpha_distance_range[0] <= alpha_distance <= alpha_distance_range[1] and\n",
        "                    beta_distance_range[0] <= beta_distance <= beta_distance_range[1]):\n",
        "                alpha_distances.append(alpha_distance)\n",
        "                beta_distances.append(beta_distance)\n",
        "\n",
        "        if len(alpha_distances) >= 3 and len(beta_distances) >= 3:\n",
        "            filtered_data_distances.append({\n",
        "                'PDB_ID': pdb_file,\n",
        "                'Combination': combination,\n",
        "                'Coord_chain_id_number1': combination[0].get_full_id()[2],\n",
        "                'Coord_residue_number1': combination[0].get_full_id()[3][1],\n",
        "                'Coord_residue_name1': combination[0].get_resname(),\n",
        "                'Coord_atom_name1': 'CA',\n",
        "                'Coord_chain_id_number2': combination[1].get_full_id()[2],\n",
        "                'Coord_residue_number2': combination[1].get_full_id()[3][1],\n",
        "                'Coord_residue_name2': combination[1].get_resname(),\n",
        "                'Coord_atom_name2': 'CA',\n",
        "                'Coord_chain_id_number3': combination[2].get_full_id()[2],\n",
        "                'Coord_residue_number3': combination[2].get_full_id()[3][1],\n",
        "                'Coord_residue_name3': combination[2].get_resname(),\n",
        "                'Coord_atom_name3': 'CA',\n",
        "                'Alpha Distance 1': alpha_distances[0],\n",
        "                'Alpha Distance 2': alpha_distances[1],\n",
        "                'Alpha Distance 3': alpha_distances[2],\n",
        "                'Beta Distance 1': beta_distances[0],\n",
        "                'Beta Distance 2': beta_distances[1],\n",
        "                'Beta Distance 3': beta_distances[2]\n",
        "            })\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error processing combination {combination}: {e}\")\n",
        "\n",
        "# Create DataFrame for distances\n",
        "column_order = [\n",
        "    'PDB_ID',\n",
        "    'Combination',\n",
        "    'Coord_chain_id_number1', 'Coord_residue_number1', 'Coord_residue_name1', 'Coord_atom_name1',\n",
        "    'Coord_chain_id_number2', 'Coord_residue_number2', 'Coord_residue_name2', 'Coord_atom_name2',\n",
        "    'Coord_chain_id_number3', 'Coord_residue_number3', 'Coord_residue_name3', 'Coord_atom_name3',\n",
        "    'Alpha Distance 1', 'Alpha Distance 2', 'Alpha Distance 3',\n",
        "    'Beta Distance 1', 'Beta Distance 2', 'Beta Distance 3'\n",
        "]\n",
        "\n",
        "df_distances = pd.DataFrame(filtered_data_distances)\n",
        "df_distances = df_distances[column_order]\n",
        "\n",
        "# Ratio filter\n",
        "filtered_data_ratio = []\n",
        "\n",
        "for idx, row in df_distances.iterrows():\n",
        "    alpha_distances = [row['Alpha Distance 1'], row['Alpha Distance 2'], row['Alpha Distance 3']]\n",
        "    beta_distances = [row['Beta Distance 1'], row['Beta Distance 2'], row['Beta Distance 3']]\n",
        "\n",
        "    for i in range(3):\n",
        "        alpha_distance_i = alpha_distances[i]\n",
        "        beta_distance_i = beta_distances[i]\n",
        "        ratio = alpha_distance_i / beta_distance_i\n",
        "\n",
        "        if not (ratio_threshold_range[0] <= ratio <= ratio_threshold_range[1]):\n",
        "            break\n",
        "    else:\n",
        "        filtered_data_ratio.append(row)\n",
        "\n",
        "df_ratio = pd.DataFrame(filtered_data_ratio)\n",
        "df_ratio = df_ratio[column_order]\n",
        "\n",
        "\n",
        "# Pie filter\n",
        "def calculate_pie(vector1, vector2):\n",
        "    dot_product = np.dot(vector1, vector2)\n",
        "    magnitude_product = np.linalg.norm(vector1) * np.linalg.norm(vector2)\n",
        "    if magnitude_product == 0:\n",
        "        return np.nan\n",
        "    cosine_angle = dot_product / magnitude_product\n",
        "    cosine_angle = np.clip(cosine_angle, -1.0, 1.0)\n",
        "    return np.degrees(np.arccos(cosine_angle))\n",
        "\n",
        "def process_row(row):\n",
        "    pdb_file_path = pdb_file\n",
        "    if not os.path.isfile(pdb_file_path):\n",
        "        print(f\"PDB file not found: {pdb_file_path}\")\n",
        "        return [None, None, None]\n",
        "\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure('protein', pdb_file_path)\n",
        "    model = structure[0]\n",
        "\n",
        "    try:\n",
        "        residues = row['Combination']\n",
        "        print(f\"Residues loaded: {residues}\")\n",
        "\n",
        "        pies = []\n",
        "        pairs = [(0, 1), (0, 2), (1, 2)]\n",
        "\n",
        "        for i, j in pairs:\n",
        "            try:\n",
        "                CA1 = residues[i]['CA']\n",
        "                CA2 = residues[j]['CA']\n",
        "                CB1 = residues[i]['CB'] if 'CB' in residues[i] else CA1\n",
        "                CB2 = residues[j]['CB'] if 'CB' in residues[j] else CA2\n",
        "\n",
        "                vector_CA = CA2.coord - CA1.coord\n",
        "                vector_CB = CB2.coord - CB1.coord\n",
        "\n",
        "                angle = calculate_pie(vector_CA, vector_CB)\n",
        "                pies.append(angle)\n",
        "            except KeyError as e:\n",
        "                print(f\"KeyError for residues {residues[i]} and {residues[j]}: {e}\")\n",
        "                pies.append(None)\n",
        "\n",
        "        return pies\n",
        "    except KeyError as e:\n",
        "        print(f\"KeyError: {e}\")\n",
        "        return [None, None, None]\n",
        "\n",
        "pie_results = df_ratio.apply(process_row, axis=1, result_type='expand')\n",
        "df_ratio[['Pie_1_2', 'Pie_1_3', 'Pie_2_3']] = pie_results\n",
        "\n",
        "# Create filter columns based on pie thresholds\n",
        "for col in ['Pie_1_2', 'Pie_1_3', 'Pie_2_3']:\n",
        "    df_ratio[f'{col}_Filter'] = df_ratio.apply(lambda row: pie_threshold_range[0] < row[col] < pie_threshold_range[1] if pd.notnull(row[col]) else False, axis=1)\n",
        "\n",
        "df_ratio['Pie_Filter'] = df_ratio[[f'{col}_Filter' for col in ['Pie_1_2', 'Pie_1_3', 'Pie_2_3']]].all(axis=1)\n",
        "\n",
        "df_final_filter = df_ratio[df_ratio['Pie_Filter']]\n",
        "\n",
        "# Save all DataFrames into a single Excel file with different tabs\n",
        "with pd.ExcelWriter(output_excel_file) as writer:\n",
        "    df_distances.to_excel(writer, sheet_name='Distances', index=False)\n",
        "    df_ratio.to_excel(writer, sheet_name='Ratio', index=False)\n",
        "    df_final_filter.to_excel(writer, sheet_name='Pie', index=False)\n",
        "\n",
        "# Generate PyMOL script file\n",
        "pymol_script_commands = []\n",
        "df_final_filter['Combination_Number'] = range(1, len(df_final_filter) + 1)\n",
        "\n",
        "for index, row in df_final_filter.iterrows():\n",
        "    combination = row['Combination']\n",
        "    chain1, res1 = combination[0].get_full_id()[2], combination[0].get_full_id()[3][1]\n",
        "    chain2, res2 = combination[1].get_full_id()[2], combination[1].get_full_id()[3][1]\n",
        "    chain3, res3 = combination[2].get_full_id()[2], combination[2].get_full_id()[3][1]\n",
        "\n",
        "    selection_name = f\"obj{row['Combination_Number']:02d}\"\n",
        "    pymol_script_commands.append(f\"select {selection_name}, (chain {chain1} and resi {res1}) or (chain {chain2} and resi {res2}) or (chain {chain3} and resi {res3})\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue1, /{pdb_file}//{chain1}/{res1}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue2, /{pdb_file}//{chain2}/{res2}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue3, /{pdb_file}//{chain3}/{res3}\")\n",
        "\n",
        "with open(pymol_script_file, 'w') as f:\n",
        "    f.write(\"# PyMOL script for visualizing filtered residue combinations\\n\\n\")\n",
        "    for command in pymol_script_commands:\n",
        "        f.write(command + '\\n')\n",
        "\n",
        "print(f\"\\nResults saved to {output_excel_file}\")\n",
        "print(f\"PyMOL script saved to {pymol_script_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "i9GaAf8WM8ke"
      },
      "outputs": [],
      "source": [
        "# Existing imports and setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from Bio.PDB import PDBParser\n",
        "import itertools\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 3B: Run the Metal-Installer\n",
        "\n",
        "# Import the necessary modules\n",
        "import pymol2\n",
        "from IPython.display import display, Markdown\n",
        "import requests  # Required for downloading files from GitHub\n",
        "\n",
        "# @markdown **Note:** Specify the paths to the input and output files below.\n",
        "\n",
        "# @markdown ### Enter the path to your input PDB file:\n",
        "pdb_file = \"/content/1EP0_alanine_dimer.pdb\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Enter the path to your output Excel file:\n",
        "output_excel_file = \"/content/1EP0_alanine_dimer_FE_2His_1asp_130.xlsx\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Enter the path to your PyMOL script file:\n",
        "pymol_script_file = \"/content/OmpF_dimer_alanine_3His_Full.pml\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Specify the specific residue number (use 0 for no specific residue):\n",
        "specific_residue_number = 0  # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ### Set the thresholds for analysis\n",
        "# @markdown **Alpha Distance**: Enter the minimum and maximum values.\n",
        "alpha_distance_min = 5.5  # @param {type:\"number\"}\n",
        "alpha_distance_max = 10  # @param {type:\"number\"}\n",
        "\n",
        "# @markdown **Beta Distance**: Enter the minimum and maximum values.\n",
        "beta_distance_min = 6.0  # @param {type:\"number\"}\n",
        "beta_distance_max = 9  # @param {type:\"number\"}\n",
        "\n",
        "# @markdown **Ratio Threshold**: Enter the minimum and maximum values.\n",
        "ratio_threshold_min = 0.7  # @param {type:\"number\"}\n",
        "ratio_threshold_max = 1.4  # @param {type:\"number\"}\n",
        "\n",
        "# @markdown **Pie Threshold**: Enter the minimum and maximum values.\n",
        "pie_threshold_min = 0  # @param {type:\"number\"}\n",
        "pie_threshold_max = 15  # @param {type:\"number\"}\n",
        "\n",
        "# Set thresholds based on user inputs\n",
        "alpha_distance_range = (alpha_distance_min, alpha_distance_max)\n",
        "beta_distance_range = (beta_distance_min, beta_distance_max)\n",
        "ratio_threshold_range = (ratio_threshold_min, ratio_threshold_max)\n",
        "pie_threshold_range = (pie_threshold_min, pie_threshold_max)\n",
        "\n",
        "# Output the ranges to confirm\n",
        "print(f\"Alpha Distance Range: {alpha_distance_range}\")\n",
        "print(f\"Beta Distance Range: {beta_distance_range}\")\n",
        "print(f\"Ratio Threshold Range: {ratio_threshold_range}\")\n",
        "print(f\"Pie Threshold Range: {pie_threshold_range}\")\n",
        "\n",
        "# Capture the inputs into variables\n",
        "alpha_distance_range = (alpha_distance_min, alpha_distance_max)\n",
        "beta_distance_range = (beta_distance_min, beta_distance_max)\n",
        "ratio_threshold_range = (ratio_threshold_min, ratio_threshold_max)\n",
        "pie_threshold_range = (pie_threshold_min, pie_threshold_max)\n",
        "\n",
        "# Continue with the script using these threshold values\n",
        "print(f\"Alpha Distance Range: {alpha_distance_range}\")\n",
        "print(f\"Beta Distance Range: {beta_distance_range}\")\n",
        "print(f\"Ratio Threshold Range: {ratio_threshold_range}\")\n",
        "print(f\"Pie Threshold Range: {pie_threshold_range}\")\n",
        "\n",
        "# PDB Parser setup\n",
        "parser = PDBParser(QUIET=True)\n",
        "structure = parser.get_structure('protein', pdb_file)\n",
        "model = structure[0]\n",
        "residues = [residue for residue in model.get_residues() if residue.get_id()[0] == ' ']\n",
        "\n",
        "# Step 1: Filter combinations to include specific residue number if specified\n",
        "if specific_residue_number != 0:\n",
        "    combinations = [\n",
        "        comb for comb in itertools.combinations(residues, 3)\n",
        "        if any(res.get_id()[1] == specific_residue_number for res in comb)\n",
        "    ]\n",
        "else:\n",
        "    combinations = list(itertools.combinations(residues, 3))\n",
        "\n",
        "\n",
        "# Distance filter\n",
        "filtered_data_distances = []\n",
        "\n",
        "for idx, combination in enumerate(combinations):\n",
        "    alpha_distances, beta_distances = [], []\n",
        "\n",
        "    try:\n",
        "        for res1, res2 in itertools.combinations(combination, 2):\n",
        "            if res1.has_id('CA') and res2.has_id('CA'):\n",
        "                ca1, ca2 = res1['CA'].coord, res2['CA'].coord\n",
        "                alpha_distance = np.linalg.norm(ca1 - ca2)\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            if res1.has_id('CB') and res2.has_id('CB'):\n",
        "                cb1, cb2 = res1['CB'].coord, res2['CB'].coord\n",
        "                beta_distance = np.linalg.norm(cb1 - cb2)\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            if (alpha_distance_range[0] <= alpha_distance <= alpha_distance_range[1] and\n",
        "                    beta_distance_range[0] <= beta_distance <= beta_distance_range[1]):\n",
        "                alpha_distances.append(alpha_distance)\n",
        "                beta_distances.append(beta_distance)\n",
        "\n",
        "        if len(alpha_distances) >= 3 and len(beta_distances) >= 3:\n",
        "            filtered_data_distances.append({\n",
        "                'PDB_ID': pdb_file,\n",
        "                'Combination': combination,\n",
        "                'Coord_chain_id_number1': combination[0].get_full_id()[2],\n",
        "                'Coord_residue_number1': combination[0].get_full_id()[3][1],\n",
        "                'Coord_residue_name1': combination[0].get_resname(),\n",
        "                'Coord_atom_name1': 'CA',\n",
        "                'Coord_chain_id_number2': combination[1].get_full_id()[2],\n",
        "                'Coord_residue_number2': combination[1].get_full_id()[3][1],\n",
        "                'Coord_residue_name2': combination[1].get_resname(),\n",
        "                'Coord_atom_name2': 'CA',\n",
        "                'Coord_chain_id_number3': combination[2].get_full_id()[2],\n",
        "                'Coord_residue_number3': combination[2].get_full_id()[3][1],\n",
        "                'Coord_residue_name3': combination[2].get_resname(),\n",
        "                'Coord_atom_name3': 'CA',\n",
        "                'Alpha Distance 1': alpha_distances[0],\n",
        "                'Alpha Distance 2': alpha_distances[1],\n",
        "                'Alpha Distance 3': alpha_distances[2],\n",
        "                'Beta Distance 1': beta_distances[0],\n",
        "                'Beta Distance 2': beta_distances[1],\n",
        "                'Beta Distance 3': beta_distances[2]\n",
        "            })\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error processing combination {combination}: {e}\")\n",
        "\n",
        "# Create DataFrame for distances\n",
        "column_order = [\n",
        "    'PDB_ID',\n",
        "    'Combination',\n",
        "    'Coord_chain_id_number1', 'Coord_residue_number1', 'Coord_residue_name1', 'Coord_atom_name1',\n",
        "    'Coord_chain_id_number2', 'Coord_residue_number2', 'Coord_residue_name2', 'Coord_atom_name2',\n",
        "    'Coord_chain_id_number3', 'Coord_residue_number3', 'Coord_residue_name3', 'Coord_atom_name3',\n",
        "    'Alpha Distance 1', 'Alpha Distance 2', 'Alpha Distance 3',\n",
        "    'Beta Distance 1', 'Beta Distance 2', 'Beta Distance 3'\n",
        "]\n",
        "\n",
        "df_distances = pd.DataFrame(filtered_data_distances)\n",
        "df_distances = df_distances[column_order]\n",
        "\n",
        "# Ratio filter\n",
        "filtered_data_ratio = []\n",
        "\n",
        "for idx, row in df_distances.iterrows():\n",
        "    alpha_distances = [row['Alpha Distance 1'], row['Alpha Distance 2'], row['Alpha Distance 3']]\n",
        "    beta_distances = [row['Beta Distance 1'], row['Beta Distance 2'], row['Beta Distance 3']]\n",
        "\n",
        "    for i in range(3):\n",
        "        alpha_distance_i = alpha_distances[i]\n",
        "        beta_distance_i = beta_distances[i]\n",
        "        ratio = alpha_distance_i / beta_distance_i\n",
        "\n",
        "        if not (ratio_threshold_range[0] <= ratio <= ratio_threshold_range[1]):\n",
        "            break\n",
        "    else:\n",
        "        filtered_data_ratio.append(row)\n",
        "\n",
        "df_ratio = pd.DataFrame(filtered_data_ratio)\n",
        "df_ratio = df_ratio[column_order]\n",
        "\n",
        "# Pie filter\n",
        "def calculate_pie(vector1, vector2):\n",
        "    dot_product = np.dot(vector1, vector2)\n",
        "    magnitude_product = np.linalg.norm(vector1) * np.linalg.norm(vector2)\n",
        "    if magnitude_product == 0:\n",
        "        return np.nan\n",
        "    cosine_angle = dot_product / magnitude_product\n",
        "    cosine_angle = np.clip(cosine_angle, -1.0, 1.0)\n",
        "    return np.degrees(np.arccos(cosine_angle))\n",
        "\n",
        "def process_row(row):\n",
        "    pdb_file_path = pdb_file\n",
        "    if not os.path.isfile(pdb_file_path):\n",
        "        print(f\"PDB file not found: {pdb_file_path}\")\n",
        "        return [None, None, None]\n",
        "\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    structure = parser.get_structure('protein', pdb_file_path)\n",
        "    model = structure[0]\n",
        "\n",
        "    try:\n",
        "        residues = row['Combination']\n",
        "        print(f\"Residues loaded: {residues}\")\n",
        "\n",
        "        pies = []\n",
        "        pairs = [(0, 1), (0, 2), (1, 2)]\n",
        "\n",
        "        for i, j in pairs:\n",
        "            try:\n",
        "                CA1 = residues[i]['CA']\n",
        "                CA2 = residues[j]['CA']\n",
        "                CB1 = residues[i]['CB'] if 'CB' in residues[i] else CA1\n",
        "                CB2 = residues[j]['CB'] if 'CB' in residues[j] else CA2\n",
        "\n",
        "                vector_CA = CA2.coord - CA1.coord\n",
        "                vector_CB = CB2.coord - CB1.coord\n",
        "\n",
        "                angle = calculate_pie(vector_CA, vector_CB)\n",
        "                pies.append(angle)\n",
        "            except KeyError as e:\n",
        "                print(f\"KeyError for residues {residues[i]} and {residues[j]}: {e}\")\n",
        "                pies.append(None)\n",
        "\n",
        "        return pies\n",
        "    except KeyError as e:\n",
        "        print(f\"KeyError: {e}\")\n",
        "        return [None, None, None]\n",
        "\n",
        "pie_results = df_ratio.apply(process_row, axis=1, result_type='expand')\n",
        "df_ratio[['Pie_1_2', 'Pie_1_3', 'Pie_2_3']] = pie_results\n",
        "\n",
        "# Create filter columns based on pie thresholds\n",
        "for col in ['Pie_1_2', 'Pie_1_3', 'Pie_2_3']:\n",
        "    df_ratio[f'{col}_Filter'] = df_ratio.apply(lambda row: pie_threshold_range[0] < row[col] < pie_threshold_range[1] if pd.notnull(row[col]) else False, axis=1)\n",
        "\n",
        "df_ratio['Pie_Filter'] = df_ratio[[f'{col}_Filter' for col in ['Pie_1_2', 'Pie_1_3', 'Pie_2_3']]].all(axis=1)\n",
        "\n",
        "df_final_filter = df_ratio[df_ratio['Pie_Filter']]\n",
        "# Remove '.pdb' from the PDB_ID in the final filtered DataFrame\n",
        "df_final_filter['PDB_ID'] = df_final_filter['PDB_ID'].str.replace('.pdb', '', regex=False)\n",
        "# Save all DataFrames into a single Excel file with different tabs\n",
        "with pd.ExcelWriter(output_excel_file) as writer:\n",
        "    df_distances.to_excel(writer, sheet_name='Distances', index=False)\n",
        "    df_ratio.to_excel(writer, sheet_name='Ratio', index=False)\n",
        "    df_final_filter.to_excel(writer, sheet_name='Pie', index=False)\n",
        "\n",
        "# Generate PyMOL script file\n",
        "pymol_script_commands = []\n",
        "df_final_filter['Combination_Number'] = range(1, len(df_final_filter) + 1)\n",
        "\n",
        "for index, row in df_final_filter.iterrows():\n",
        "    combination = row['Combination']\n",
        "    chain1, res1 = combination[0].get_full_id()[2], combination[0].get_full_id()[3][1]\n",
        "    chain2, res2 = combination[1].get_full_id()[2], combination[1].get_full_id()[3][1]\n",
        "    chain3, res3 = combination[2].get_full_id()[2], combination[2].get_full_id()[3][1]\n",
        "\n",
        "    selection_name = f\"obj{row['Combination_Number']:02d}\"\n",
        "    pymol_script_commands.append(f\"select {selection_name}, (chain {chain1} and resi {res1}) or (chain {chain2} and resi {res2}) or (chain {chain3} and resi {res3})\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue1, /{pdb_file}//{chain1}/{res1}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue2, /{pdb_file}//{chain2}/{res2}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue3, /{pdb_file}//{chain3}/{res3}\")\n",
        "\n",
        "with open(pymol_script_file, 'w') as f:\n",
        "    f.write(\"# PyMOL script for visualizing filtered residue combinations\\n\\n\")\n",
        "    for command in pymol_script_commands:\n",
        "        f.write(command + '\\n')\n",
        "\n",
        "print(f\"\\nResults saved to {output_excel_file}\")\n",
        "print(f\"PyMOL script saved to {pymol_script_file}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlddZ35YMLWD",
        "outputId": "85473933-07c3-489b-d38a-d2a3bbf7e1d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coordinates extracted and saved to /content/3ttis_coordinates.xlsx\n"
          ]
        }
      ],
      "source": [
        "from Bio.PDB import PDBParser\n",
        "import pandas as pd\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 4A: Preparation steps for metal-sites expectation (Coordinates extraction)\n",
        "\n",
        "# @markdown **Note:** Specify the paths to the input and output files below.\n",
        "# @markdown ### Enter the path to your input excel file (The result of the step 3)\n",
        "input_file = '/content/3tis_run_alanine_Cu_3His.xlsx' # @param {type:\"string\"}\n",
        "df_pie = pd.read_excel(input_file, sheet_name='Pie')\n",
        "\n",
        "# @markdown ### Enter the path to your input PDB file:\n",
        "pdb_file = \"/content/3tis_run_alanine.pdb\"  # @param {type:\"string\"}\n",
        "parser = PDBParser(QUIET=True)\n",
        "structure = parser.get_structure('protein', pdb_file)\n",
        "\n",
        "# Extract the PDB ID by removing the directory and `.pdb` extension\n",
        "pdb_id = os.path.basename(pdb_file).replace('.pdb', '')\n",
        "\n",
        "# Function to extract Cα and Cβ coordinates for a given residue\n",
        "def extract_coordinates(chain, res_id, atom_name):\n",
        "    try:\n",
        "        residue = chain[res_id]\n",
        "        atom_coord = residue[atom_name].coord\n",
        "        return atom_coord\n",
        "    except KeyError:\n",
        "        return [None, None, None]\n",
        "\n",
        "# Pre-fetch chains to avoid repetitive lookups\n",
        "chains = {chain.id: chain for chain in structure[0]}\n",
        "\n",
        "# Loop through each row in the Excel file and extract coordinates\n",
        "ca_coords = []\n",
        "cb_coords = []\n",
        "\n",
        "for idx, row in df_pie.iterrows():\n",
        "    chain1 = chains.get(row['Coord_chain_id_number1'])\n",
        "    chain2 = chains.get(row['Coord_chain_id_number2'])\n",
        "    chain3 = chains.get(row['Coord_chain_id_number3'])\n",
        "\n",
        "    # Extract chain, residue, and atom info for each of the three residues\n",
        "    res1_coord = extract_coordinates(chain1, row['Coord_residue_number1'], 'CA')\n",
        "    res2_coord = extract_coordinates(chain2, row['Coord_residue_number2'], 'CA')\n",
        "    res3_coord = extract_coordinates(chain3, row['Coord_residue_number3'], 'CA')\n",
        "\n",
        "    # Add coordinates for each residue\n",
        "    ca_coords.append([*res1_coord, *res2_coord, *res3_coord])\n",
        "\n",
        "    # If Cβ is also needed:\n",
        "    res1_cb = extract_coordinates(chain1, row['Coord_residue_number1'], 'CB')\n",
        "    res2_cb = extract_coordinates(chain2, row['Coord_residue_number2'], 'CB')\n",
        "    res3_cb = extract_coordinates(chain3, row['Coord_residue_number3'], 'CB')\n",
        "\n",
        "    cb_coords.append([*res1_cb, *res2_cb, *res3_cb])\n",
        "\n",
        "# Convert the extracted coordinates to DataFrames\n",
        "ca_columns = ['CA1_X', 'CA1_Y', 'CA1_Z', 'CA2_X', 'CA2_Y', 'CA2_Z', 'CA3_X', 'CA3_Y', 'CA3_Z']\n",
        "cb_columns = ['CB1_X', 'CB1_Y', 'CB1_Z', 'CB2_X', 'CB2_Y', 'CB2_Z', 'CB3_X', 'CB3_Y', 'CB3_Z']\n",
        "\n",
        "df_ca = pd.DataFrame(ca_coords, columns=ca_columns)\n",
        "df_cb = pd.DataFrame(cb_coords, columns=cb_columns)\n",
        "\n",
        "# Merge the coordinates with the original DataFrame\n",
        "df_pie = pd.concat([df_pie.reset_index(drop=True), df_ca, df_cb], axis=1)\n",
        "\n",
        "# Remove `.pdb` from the `PDB_ID` column if it exists\n",
        "if 'PDB_ID' in df_pie.columns:\n",
        "    df_pie['PDB_ID'] = df_pie['PDB_ID'].str.replace('.pdb', '', regex=False)\n",
        "# @markdown ### Enter the path to your output Excel file:\n",
        "output_file = '/content/3ttis_coordinates.xlsx'   # @param {type:\"string\"}\n",
        "df_pie.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Coordinates extracted and saved to {output_file}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2yb2fkkN2IKl"
      },
      "outputs": [],
      "source": [
        "#Final (Dynamically:Last_One+edge): 진짜 이거 ratio 까지 되는거 (마지막):찐찐찐\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from Bio.PDB import PDBParser\n",
        "import requests\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 4B: Run the metal-sites expectation\n",
        "\n",
        "# Define input and output file paths\n",
        "# @markdown ### Enter the path to your input excel file (The result of the step 4A)\n",
        "input_coords_file = '/content/3ttis_coordinates_1.xlsx' # @param {type:\"string\"}\n",
        "\n",
        "# Load input file\n",
        "df_alanine = pd.read_excel(input_coords_file)\n",
        "\n",
        "# Define file download paths\n",
        "prob_map_file = '/content/map.xlsx'\n",
        "thresholds_file = '/content/threshold.xlsx'\n",
        "\n",
        "# Download files from GitHub\n",
        "base_url = \"https://raw.githubusercontent.com/SNU-Songlab/Metal-Installer-code/main/probability/\"\n",
        "# @markdown ### Set the metal type to use:\n",
        "Metal = 'Cu'  # @param [\"Zn\", \"Mn\", \"Cu\", \"Fe\"]\n",
        "# @markdown ### Select the combination type:\n",
        "# @markdown **Note:** 3His:Zn/Cu/Fe & 2His/1Asp:Zn/Fe/Mn & 2His/1Glu: Zn/Fe/Mn & 2His/1Cys: Cu\n",
        "Combinations = '3His'  # @param [\"3His\", \"2His_1Asp\", \"2His_1Glu\", \"2His_1Cys\"]\n",
        "\n",
        "map_url = f\"{base_url}/{Metal}/{Combinations}/map.xlsx\"\n",
        "thresholds_url = f\"{base_url}/{Metal}/{Combinations}/threshold.xlsx\"\n",
        "\n",
        "# Download probability map\n",
        "response = requests.get(map_url)\n",
        "if response.status_code == 200:\n",
        "    with open(prob_map_file, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "else:\n",
        "    raise ValueError(f\"Failed to download file from {map_url}. Status code: {response.status_code}\")\n",
        "\n",
        "# Download thresholds file\n",
        "response = requests.get(thresholds_url)\n",
        "if response.status_code == 200:\n",
        "    with open(thresholds_file, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "else:\n",
        "    raise ValueError(f\"Failed to download file from {thresholds_url}. Status code: {response.status_code}\")\n",
        "\n",
        "# Load downloaded Excel files\n",
        "thresholds_df = pd.read_excel(thresholds_file, sheet_name='Sheet1')\n",
        "df_precomputed_prob_map = pd.read_excel(prob_map_file)\n",
        "\n",
        "def calculate_ratio(current_point, ca_xyz, cb_xyz):\n",
        "    # Calculate distances to Ca and Cb atoms\n",
        "    ca_distances = np.linalg.norm(ca_xyz - current_point, axis=1)\n",
        "    cb_distances = np.linalg.norm(cb_xyz - current_point, axis=1)\n",
        "    # Return ratios for each residue\n",
        "    return ca_distances / cb_distances\n",
        "\n",
        "# Extract thresholds into a dictionary\n",
        "thresholds = {}\n",
        "for _, row in thresholds_df.iterrows():\n",
        "    parameter = row['Parameter']\n",
        "    min_value = row['Min']\n",
        "    max_value = row['Max']\n",
        "    if pd.notna(min_value) and pd.notna(max_value):\n",
        "        thresholds[parameter] = (min_value, max_value)\n",
        "\n",
        "required_keys = ['ca_distances_calc', 'cb_distances_calc', 'ratio', 'angle']\n",
        "\n",
        "for key in required_keys:\n",
        "    if key not in thresholds:\n",
        "        raise KeyError(f\"Missing key '{key}' in thresholds file.\")\n",
        "\n",
        "\n",
        "# Define bin edges for CA-Zn distances, CB-Zn distances, and angles\n",
        "prob_map_file = '/content/map.xlsx'\n",
        "df_precomputed_prob_map = pd.read_excel(prob_map_file)\n",
        "\n",
        "ca_bins = np.sort(df_precomputed_prob_map['Calpha_Zn_Dist'].unique())\n",
        "cb_bins = np.sort(df_precomputed_prob_map['Cbeta_Zn_Dist'].unique())\n",
        "angle_bins = np.sort(df_precomputed_prob_map['CA-Zn-CB_Angle'].unique())\n",
        "\n",
        "# Pivot the probability map into a 3D array format\n",
        "pivoted_prob_map = df_precomputed_prob_map.pivot_table(\n",
        "    index='Calpha_Zn_Dist', columns=['Cbeta_Zn_Dist', 'CA-Zn-CB_Angle'], values='Probability', fill_value=0\n",
        ")\n",
        "prob_map_3d = pivoted_prob_map.values.reshape((len(ca_bins), len(cb_bins), len(angle_bins)))\n",
        "\n",
        "# Function to load a PDB file based on entry ID\n",
        "def load_pdb_structure(entry_id, pdb_directory):\n",
        "    pdb_parser = PDBParser()\n",
        "    pdb_file_path = os.path.join(pdb_directory, f\"{entry_id}.pdb\")\n",
        "    structure = pdb_parser.get_structure(entry_id, pdb_file_path)\n",
        "    return structure\n",
        "\n",
        "# Function to score Zn positions\n",
        "def score_zn_predictions(ca_distances, cb_distances, angles, prob_map_3d, ca_bins, cb_bins, angle_bins):\n",
        "    ca_bin_indices = np.digitize(ca_distances, ca_bins) - 1\n",
        "    cb_bin_indices = np.digitize(cb_distances, cb_bins) - 1\n",
        "    angle_bin_indices = np.digitize(angles, angle_bins) - 1\n",
        "    probabilities = []\n",
        "    valid = True\n",
        "    for cbin, bbin, abin in zip(ca_bin_indices, cb_bin_indices, angle_bin_indices):\n",
        "        if 0 <= cbin < prob_map_3d.shape[0] and 0 <= bbin < prob_map_3d.shape[1] and 0 <= abin < prob_map_3d.shape[2]:\n",
        "            prob_value = prob_map_3d[cbin, bbin, abin]\n",
        "            if prob_value == 0:\n",
        "                valid = False\n",
        "                break\n",
        "            probabilities.append(prob_value)\n",
        "        else:\n",
        "            valid = False\n",
        "            break\n",
        "    final_score = np.prod(probabilities) if valid else None\n",
        "    return final_score\n",
        "\n",
        "# Function to calculate angles between Zn-Cα and Zn-Cβ vectors for each triplet\n",
        "def calculate_angles(zn_coords, ca_coords_triplet, cb_coords_triplet):\n",
        "    angles = []\n",
        "    for i in range(3):\n",
        "        v1 = ca_coords_triplet[i] - zn_coords\n",
        "        v2 = cb_coords_triplet[i] - zn_coords\n",
        "        cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
        "        angle = np.arccos(np.clip(cos_theta, -1.0, 1.0))\n",
        "        angles.append(np.degrees(angle))\n",
        "    return angles\n",
        "\n",
        "# Function to filter Zn candidates by distance thresholds\n",
        "def filter_by_distance_threshold(ca_coords, cb_coords, zn_candidates, ca_xyz, cb_xyz):\n",
        "    filtered_candidates = []\n",
        "    for zn_candidate in zn_candidates:\n",
        "        # Calculate distances to Cα and Cβ\n",
        "        ca_distances_calc = np.linalg.norm(zn_candidate - ca_coords, axis=1)\n",
        "        cb_distances_calc = np.linalg.norm(zn_candidate - cb_coords, axis=1)\n",
        "\n",
        "        # Calculate Zn-Cα/Zn-Cβ ratios\n",
        "        ratio = ca_distances_calc / cb_distances_calc\n",
        "\n",
        "        # Calculate angles\n",
        "        angles = np.array(calculate_angles(zn_candidate, ca_xyz, cb_xyz))\n",
        "\n",
        "        # Apply thresholds\n",
        "        if (np.all((thresholds['ca_distances_calc'][0] <= ca_distances_calc) & (ca_distances_calc <= thresholds['ca_distances_calc'][1])) and\n",
        "            np.all((thresholds['cb_distances_calc'][0] <= cb_distances_calc) & (cb_distances_calc <= thresholds['cb_distances_calc'][1])) and\n",
        "            np.all((thresholds['ratio'][0] <= ratio) & (ratio <= thresholds['ratio'][1]))):\n",
        "            filtered_candidates.append(zn_candidate)\n",
        "\n",
        "    return np.array(filtered_candidates)\n",
        "\n",
        "\n",
        "\n",
        "def define_excluded_triads(triad_residues, structure):\n",
        "    excluded_residues = set()\n",
        "    for _, residue_number in triad_residues:\n",
        "        for model in structure:\n",
        "            for chain in model:\n",
        "                for residue in chain:\n",
        "                    if residue.get_id()[1] == residue_number:\n",
        "                        excluded_residues.add((chain.id, residue.get_id()[1]))\n",
        "    return excluded_residues\n",
        "\n",
        "# Function to perform proximity filtering and record nearby amino acids\n",
        "def find_proximity_amino_acids(structure, zn_candidate, excluded_residues, exclusion_radius=2.5):\n",
        "    nearby_amino_acids = []\n",
        "\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            for residue in chain:\n",
        "                # Skip if the residue is in the excluded set\n",
        "                if (chain.id, residue.get_id()[1]) in excluded_residues:\n",
        "                    continue\n",
        "\n",
        "                for atom in residue:\n",
        "                    atom_coords = atom.coord\n",
        "                    distance_to_atom = np.linalg.norm(zn_candidate - atom_coords)\n",
        "                    if distance_to_atom < exclusion_radius:\n",
        "                        nearby_amino_acids.append({\n",
        "                            'Chain_ID': chain.id,\n",
        "                            'Residue_Number': residue.get_id()[1],\n",
        "                            'Residue_Name': residue.get_resname(),\n",
        "                            'Atom_Name': atom.get_name(),\n",
        "                            'Distance_to_Zn': distance_to_atom\n",
        "                        })\n",
        "                        break  # Log only once per residue within radius\n",
        "    return nearby_amino_acids\n",
        "def define_excluded_triads(triad_residues, structure):\n",
        "    excluded_residues = set()\n",
        "    for _, residue_number in triad_residues:\n",
        "        for model in structure:\n",
        "            for chain in model:\n",
        "                for residue in chain:\n",
        "                    if residue.get_id()[1] == residue_number:\n",
        "                        excluded_residues.add((chain.id, residue.get_id()[1]))\n",
        "    return excluded_residues\n",
        "# Function for proximity filtering with explicit exclusion of defined triads\n",
        "def proximity_filter(structure, zn_candidate, excluded_residues, exclusion_radius=2.5):\n",
        "    \"\"\"\n",
        "    Perform proximity filtering, excluding residues with the same residue number across chains.\n",
        "    \"\"\"\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            for residue in chain:\n",
        "                chain_id = chain.id\n",
        "                residue_number = residue.get_id()[1]  # Residue sequence number\n",
        "\n",
        "                # Skip residues if they match any in the exclusion set\n",
        "                if (chain_id, residue_number) in excluded_residues:\n",
        "                    continue\n",
        "\n",
        "                for atom in residue:\n",
        "                    atom_coords = atom.coord\n",
        "                    distance_to_atom = np.linalg.norm(zn_candidate - atom_coords)\n",
        "                    if distance_to_atom < exclusion_radius:\n",
        "                        return False  # Invalid candidate due to proximity to excluded residue\n",
        "\n",
        "    return True\n",
        "\n",
        "# Main function to estimate Zn candidates with precise boundary handling from Excel\n",
        "def estimate_zn_iterative(ca_coords, cb_coords, prob_map_3d, ca_bins, cb_bins, angle_bins, pdb_directory, grid_resolution=0.2):\n",
        "    # Extract thresholds from the DataFrame\n",
        "    thresholds = {}\n",
        "    for _, row in thresholds_df.iterrows():\n",
        "        parameter = row['Parameter']\n",
        "        min_value = row['Min']\n",
        "        max_value = row['Max']\n",
        "        if pd.notna(min_value) and pd.notna(max_value):\n",
        "            thresholds[parameter] = (min_value, max_value)\n",
        "\n",
        "    required_keys = ['ca_distances_calc', 'cb_distances_calc', 'ratio', 'angle']\n",
        "\n",
        "    for key in required_keys:\n",
        "        if key not in thresholds:\n",
        "            raise KeyError(f\"Missing key '{key}' in thresholds file.\")\n",
        "\n",
        "    zn_coords_list = []\n",
        "    best_scores = []\n",
        "    angle_list = []\n",
        "    proximity_data = []  # Store proximity information for each valid Zn candidate\n",
        "\n",
        "    for i in range(len(ca_coords)):\n",
        "        entry_id = df_alanine['PDB_ID'][i]\n",
        "        structure = load_pdb_structure(entry_id, pdb_directory)\n",
        "\n",
        "        # Extract and reshape Cα and Cβ coordinates\n",
        "        ca_xyz = ca_coords.iloc[i].values.reshape(3, 3)\n",
        "        cb_xyz = cb_coords.iloc[i].values.reshape(3, 3)\n",
        "\n",
        "        # Define triad residues (ignoring chain IDs initially)\n",
        "        triad_residues = [\n",
        "            (None, df_alanine.at[i, 'Coord_residue_number1']),\n",
        "            (None, df_alanine.at[i, 'Coord_residue_number2']),\n",
        "            (None, df_alanine.at[i, 'Coord_residue_number3'])\n",
        "        ]\n",
        "\n",
        "        # Define excluded residues considering all chains with the same residue numbers\n",
        "        excluded_residues = define_excluded_triads(triad_residues, structure)\n",
        "\n",
        "        # Initialize shared region boundaries\n",
        "        shared_x_min = -np.inf\n",
        "        shared_x_max = np.inf\n",
        "        shared_y_min = -np.inf\n",
        "        shared_y_max = np.inf\n",
        "        shared_z_min = -np.inf\n",
        "        shared_z_max = np.inf\n",
        "\n",
        "        # Define inner and outer box boundaries from thresholds\n",
        "        inner_boxes = []\n",
        "        for j in range(3):\n",
        "            x_min_inner = min(ca_xyz[j, 0], cb_xyz[j, 0]) - thresholds['ca_distances_calc'][0]\n",
        "            x_max_inner = max(ca_xyz[j, 0], cb_xyz[j, 0]) + thresholds['ca_distances_calc'][0]\n",
        "\n",
        "            y_min_inner = min(ca_xyz[j, 1], cb_xyz[j, 1]) - thresholds['cb_distances_calc'][0]\n",
        "            y_max_inner = max(ca_xyz[j, 1], cb_xyz[j, 1]) + thresholds['cb_distances_calc'][0]\n",
        "\n",
        "            z_min_inner = min(ca_xyz[j, 2], cb_xyz[j, 2]) - thresholds['ca_distances_calc'][0]\n",
        "            z_max_inner = max(ca_xyz[j, 2], cb_xyz[j, 2]) + thresholds['ca_distances_calc'][0]\n",
        "\n",
        "            inner_boxes.append((x_min_inner, x_max_inner, y_min_inner, y_max_inner, z_min_inner, z_max_inner))\n",
        "\n",
        "            x_min_outer = min(ca_xyz[j, 0], cb_xyz[j, 0]) - thresholds['ca_distances_calc'][1]\n",
        "            x_max_outer = max(ca_xyz[j, 0], cb_xyz[j, 0]) + thresholds['ca_distances_calc'][1]\n",
        "\n",
        "            y_min_outer = min(ca_xyz[j, 1], cb_xyz[j, 1]) - thresholds['cb_distances_calc'][1]\n",
        "            y_max_outer = max(ca_xyz[j, 1], cb_xyz[j, 1]) + thresholds['cb_distances_calc'][1]\n",
        "\n",
        "            z_min_outer = min(ca_xyz[j, 2], cb_xyz[j, 2]) - thresholds['ca_distances_calc'][1]\n",
        "            z_max_outer = max(ca_xyz[j, 2], cb_xyz[j, 2]) + thresholds['ca_distances_calc'][1]\n",
        "\n",
        "            # Update shared region with intersection\n",
        "            shared_x_min = max(shared_x_min, x_min_outer - grid_resolution)\n",
        "            shared_x_max = min(shared_x_max, x_max_outer + grid_resolution)\n",
        "            shared_y_min = max(shared_y_min, y_min_outer - grid_resolution)\n",
        "            shared_y_max = min(shared_y_max, y_max_outer + grid_resolution)\n",
        "            shared_z_min = max(shared_z_min, z_min_outer - grid_resolution)\n",
        "            shared_z_max = min(shared_z_max, z_max_outer + grid_resolution)\n",
        "\n",
        "        # Ensure valid search space exists\n",
        "        if shared_x_min >= shared_x_max or shared_y_min >= shared_y_max or shared_z_min >= shared_z_max:\n",
        "            print(f\"No shared search space for Entry {i}: {entry_id}\")\n",
        "            zn_coords_list.append(\"no metal\")\n",
        "            best_scores.append(0)\n",
        "            angle_list.append([None, None, None])\n",
        "            continue\n",
        "\n",
        "        # Debug print for shared search region\n",
        "        print(f\"Shared Region for Entry {i}: {entry_id}\")\n",
        "        print(f\"x_min: {shared_x_min}, x_max: {shared_x_max}\")\n",
        "        print(f\"y_min: {shared_y_min}, y_max: {shared_y_max}\")\n",
        "        print(f\"z_min: {shared_z_min}, z_max: {shared_z_max}\")\n",
        "\n",
        "        # Generate Zn candidates grid within the shared region excluding inner boxes\n",
        "        zn_candidates = []\n",
        "        total_grid_points = 0\n",
        "        distance_valid_points = 0\n",
        "        angle_valid_points = 0\n",
        "        ratio_valid_points = 0\n",
        "        probability_valid_points = 0\n",
        "\n",
        "        # First find shared region with coarse grid\n",
        "        shared_region_found = False\n",
        "        if shared_x_min < shared_x_max and shared_y_min < shared_y_max and shared_z_min < shared_z_max:\n",
        "            shared_region_found = True\n",
        "\n",
        "                # If shared region exists, search with finer grid\n",
        "        if shared_region_found:\n",
        "            grid_resolution = 0.2  # Use the input parameter\n",
        "            total_grid_points = 0\n",
        "            distance_valid_points = 0\n",
        "            angle_valid_points = 0\n",
        "            ratio_valid_points = 0  # Renamed for clarity\n",
        "            probability_valid_points = 0\n",
        "            valid_points = []\n",
        "            all_scores = []\n",
        "\n",
        "            for x in np.arange(shared_x_min, shared_x_max + 1e-8, grid_resolution):\n",
        "                for y in np.arange(shared_y_min, shared_y_max + 1e-8, grid_resolution):\n",
        "                    for z in np.arange(shared_z_min, shared_z_max + 1e-8, grid_resolution):\n",
        "                        total_grid_points += 1\n",
        "\n",
        "                        # Check both corner and center points\n",
        "                        corner_point = np.array([x, y, z])\n",
        "                        center_point = np.array([\n",
        "                            x + grid_resolution/2,\n",
        "                            y + grid_resolution/2,\n",
        "                            z + grid_resolution/2\n",
        "                        ])\n",
        "\n",
        "                        for point in [corner_point, center_point]:\n",
        "                            # Distance check\n",
        "                            distances_ca = np.linalg.norm(ca_xyz - point, axis=1)\n",
        "                            distances_cb = np.linalg.norm(cb_xyz - point, axis=1)\n",
        "\n",
        "                            distance_condition = (np.all((thresholds['ca_distances_calc'][0] <= distances_ca) &\n",
        "                                                       (distances_ca <= thresholds['ca_distances_calc'][1])) and\n",
        "                                               np.all((thresholds['cb_distances_calc'][0] <= distances_cb) &\n",
        "                                                       (distances_cb <= thresholds['cb_distances_calc'][1])))\n",
        "\n",
        "                            if distance_condition:\n",
        "                                distance_valid_points += 1\n",
        "\n",
        "                                # Calculate angles\n",
        "                                angles = calculate_angles(point, ca_xyz, cb_xyz)\n",
        "                                angle_condition = all(thresholds['angle'][0] <= angle <= thresholds['angle'][1]\n",
        "                                                   for angle in angles)\n",
        "\n",
        "                                if angle_condition:\n",
        "                                    angle_valid_points += 1\n",
        "\n",
        "                                    # Calculate ratios\n",
        "                                    ratios = calculate_ratio(point, ca_xyz, cb_xyz)\n",
        "                                    ratio_condition = np.all((thresholds['ratio'][0] <= ratios) &\n",
        "                                                           (ratios <= thresholds['ratio'][1]))\n",
        "\n",
        "                                    if ratio_condition:\n",
        "                                        ratio_valid_points += 1  # Only increment if ratio check passes\n",
        "\n",
        "                                        # Calculate probability score\n",
        "                                        score = score_zn_predictions(\n",
        "                                            distances_ca,\n",
        "                                            distances_cb,\n",
        "                                            angles,\n",
        "                                            prob_map_3d, ca_bins, cb_bins, angle_bins)\n",
        "\n",
        "                                        if score is not None and score > 0:\n",
        "                                            probability_valid_points += 1  # Only increment if probability check passes\n",
        "                                            valid_points.append(point)\n",
        "                                            all_scores.append(score)\n",
        "                                            zn_candidates.append([x, y, z])\n",
        "\n",
        "            # Print filtering statistics\n",
        "            print(f\"Total grid points searched: {total_grid_points}\")\n",
        "            print(f\"Points passing distance criteria: {distance_valid_points}\")\n",
        "            print(f\"Points passing angle criteria: {angle_valid_points}\")\n",
        "            print(f\"Points passing ratio criteria: {ratio_valid_points}\")\n",
        "            print(f\"Points passing probability criteria: {probability_valid_points}\")\n",
        "\n",
        "        zn_candidates = np.array(zn_candidates)\n",
        "\n",
        "        # Filter Zn candidates by distance and proximity\n",
        "        distance_filtered_candidates = filter_by_distance_threshold(ca_xyz, cb_xyz, zn_candidates, ca_xyz, cb_xyz)\n",
        "\n",
        "        for zn_candidate in distance_filtered_candidates:\n",
        "            angles = calculate_angles(zn_candidate, ca_xyz, cb_xyz)\n",
        "            if any(angle > thresholds['angle'][1] or angle < thresholds['angle'][0] for angle in angles):\n",
        "                continue\n",
        "\n",
        "            score = score_zn_predictions(\n",
        "                np.linalg.norm(zn_candidate - ca_xyz, axis=1),\n",
        "                np.linalg.norm(zn_candidate - cb_xyz, axis=1),\n",
        "                angles,\n",
        "                prob_map_3d, ca_bins, cb_bins, angle_bins\n",
        "            )\n",
        "\n",
        "            if score is not None and score > 0:\n",
        "                valid = proximity_filter(structure, zn_candidate, excluded_residues)\n",
        "                if valid:\n",
        "                    zn_coords_list.append(zn_candidate)\n",
        "                    best_scores.append(score)\n",
        "                    angle_list.append(angles)\n",
        "                    break\n",
        "\n",
        "        if len(zn_coords_list) <= i:\n",
        "            zn_coords_list.append(\"no metal\")\n",
        "            best_scores.append(0)\n",
        "            angle_list.append([None, None, None])\n",
        "\n",
        "    return zn_coords_list, best_scores, angle_list, proximity_data\n",
        "\n",
        "\n",
        "# Define coordinates for Zn estimation and specify PDB directory\n",
        "ca_coords = df_alanine[['CA1_X', 'CA1_Y', 'CA1_Z', 'CA2_X', 'CA2_Y', 'CA2_Z', 'CA3_X', 'CA3_Y', 'CA3_Z']]\n",
        "cb_coords = df_alanine[['CB1_X', 'CB1_Y', 'CB1_Z', 'CB2_X', 'CB2_Y', 'CB2_Z', 'CB3_X', 'CB3_Y', 'CB3_Z']]\n",
        "pdb_directory = '/content/3p43_alanine.pdb'  # Replace with actual path to PDB files\n",
        "\n",
        "# Run Zn estimation with grid generation, scoring, and iterative proximity filtering\n",
        "estimated_zn_coords_grid, zn_scores, angles_list, proximity_data = estimate_zn_iterative(\n",
        "    ca_coords, cb_coords, prob_map_3d, ca_bins, cb_bins, angle_bins, pdb_directory, grid_resolution=0.2\n",
        ")\n",
        "\n",
        "# After calculating Zn coordinates, scores, and angles\n",
        "df_alanine['Zn_X_Grid'] = [coords[0] if not isinstance(coords, str) else None for coords in estimated_zn_coords_grid]\n",
        "df_alanine['Zn_Y_Grid'] = [coords[1] if not isinstance(coords, str) else None for coords in estimated_zn_coords_grid]\n",
        "df_alanine['Zn_Z_Grid'] = [coords[2] if not isinstance(coords, str) else None for coords in estimated_zn_coords_grid]\n",
        "df_alanine['Zn_Score'] = zn_scores\n",
        "df_alanine['Angle_1'], df_alanine['Angle_2'], df_alanine['Angle_3'] = zip(*angles_list)\n",
        "\n",
        "# Remove rows where Zn_Score is 0\n",
        "df_alanine = df_alanine[df_alanine['Zn_Score'] != 0]\n",
        "\n",
        "# @markdown ### Save the Filtered DataFrame to an Excel File\n",
        "output_file_path = '/content/3ttis_coordinates_1_result.xlsx'  # @param {type:\"string\"}\n",
        "df_alanine.to_excel(output_file_path, index=False)\n",
        "# @markdown **Filtered Zn coordinates, scores, and angles saved.**\n",
        "print(f\"Filtered Zn coordinates, scores, and angles saved to '{output_file_path}'\")\n",
        "\n",
        "# @markdown ### Save the Proximity Information to an Excel File\n",
        "df_proximity = pd.DataFrame(proximity_data)\n",
        "output_proximity_file = '/content/test_proximity3.xlsx' # @param {type:\"string\"}\n",
        "df_proximity.to_excel(output_proximity_file, index=False)\n",
        "# @markdown **Proximity amino acid details saved.**\n",
        "print(f\"Proximity amino acid details saved to '{output_proximity_file}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8VwAlZ7nSEw",
        "outputId": "7ae11ae3-8b37-4e92-c8ac-4bcd91144629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyMOL script saved to /content/3tis_final.pml\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from Bio.PDB import PDBParser\n",
        "import requests\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 5: Analysis the result (Apply to the PDB file)\n",
        "\n",
        "# Load input file\n",
        "input_file_path = \"/content/3ttis_coordinates_1_result.xlsx\" # @param {type:\"string\"}\n",
        "df_new = pd.read_excel(input_file_path)\n",
        "\n",
        "# Generate PyMOL script file\n",
        "pymol_script_commands = []\n",
        "df_new['Combination_Number'] = range(1, len(df_new) + 1)\n",
        "\n",
        "# Generate the PyMOL script for both valid and invalid Zn binding forms\n",
        "for index, row in df_new.iterrows():\n",
        "    # Retrieve chain and residue information\n",
        "    chain1, res1 = row['Coord_chain_id_number1'], row['Coord_residue_number1']\n",
        "    chain2, res2 = row['Coord_chain_id_number2'], row['Coord_residue_number2']\n",
        "    chain3, res3 = row['Coord_chain_id_number3'], row['Coord_residue_number3']\n",
        "\n",
        "    # Retrieve Zn coordinates\n",
        "    zn_x, zn_y, zn_z = row['Zn_X_Grid'], row['Zn_Y_Grid'], row['Zn_Z_Grid']\n",
        "\n",
        "    selection_name = f\"obj{row['Combination_Number']:02d}\"\n",
        "\n",
        "    # Select the residues\n",
        "    pymol_script_commands.append(f\"select {selection_name}, (chain {chain1} and resi {res1}) or (chain {chain2} and resi {res2}) or (chain {chain3} and resi {res3})\")\n",
        "\n",
        "    # Create the objects for the residues\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue1, /{row['PDB_ID']}//{chain1}/{res1}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue2, /{row['PDB_ID']}//{chain2}/{res2}\")\n",
        "    pymol_script_commands.append(f\"create {selection_name}_residue3, /{row['PDB_ID']}//{chain3}/{res3}\")\n",
        "\n",
        "    # Check if Zn coordinates are available\n",
        "    if not pd.isna(zn_x) and not pd.isna(zn_y) and not pd.isna(zn_z):\n",
        "        # Zn coordinates are present, add the Zn pseudoatom\n",
        "        zn_name = f\"{selection_name}_Zn\"\n",
        "        pymol_script_commands.append(f\"pseudoatom {zn_name}, pos=[{zn_x}, {zn_y}, {zn_z}], elem=Zn, name={zn_name}\")\n",
        "        pymol_script_commands.append(f\"show sphere, {zn_name}\")\n",
        "    else:\n",
        "        # Zn coordinates are missing, mark this combination as non-binding\n",
        "        pymol_script_commands.append(f\"# {selection_name} does not bind Zn\")\n",
        "\n",
        "# Save the commands into a PyMOL script\n",
        "pymol_script_file = \"/content/3tis_final.pml\" # @param {type:\"string\"}\n",
        "with open(pymol_script_file, 'w') as f:\n",
        "    f.write(\"# PyMOL script for visualizing both Zn-binding and non-binding residue combinations\\n\\n\")\n",
        "    for command in pymol_script_commands:\n",
        "        f.write(command + '\\n')\n",
        "\n",
        "print(f\"PyMOL script saved to {pymol_script_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kU_wIAFoS_Yk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e36139c4-9315-4f5c-dcf5-8afe332c330a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved at: /content/3ttis_coordinates_1_result_residue_count.xlsx\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Markdown documentation for file pathways\n",
        "\n",
        "# @markdown # Step 5: Analysis the result (Sort the result based on the metal-ligating ligands)\n",
        "\n",
        "\n",
        "# Load the provided Excel file\n",
        "file_path = '/content/3ttis_coordinates_1_result.xlsx' # @param {type:\"string\"}\n",
        "excel_data = pd.ExcelFile(file_path)\n",
        "\n",
        "# Load the data from the first sheet\n",
        "df = excel_data.parse('Sheet1')\n",
        "\n",
        "# Define function to count specific residues in the 'Combination' column\n",
        "def count_residues(row):\n",
        "    # Count occurrences of specific residue names in the 'Combination' column\n",
        "    residue_names = ['HIS', 'CYS', 'GLU', 'ASP']\n",
        "    count = sum(row['Combination'].count(residue) for residue in residue_names)\n",
        "    return count\n",
        "\n",
        "# Apply the function to each row and store the result in a new column 'Residue_Count'\n",
        "df['Residue_Count'] = df.apply(count_residues, axis=1)\n",
        "\n",
        "# Split the data based on the count of residues and save to separate sheets in a new Excel file\n",
        "output_file_path = '/content/3ttis_coordinates_1_result_residue_count.xlsx'  # @param {type:\"string\"}\n",
        "with pd.ExcelWriter(output_file_path) as writer:\n",
        "    for count in df['Residue_Count'].unique():\n",
        "        df_filtered = df[df['Residue_Count'] == count]\n",
        "        df_filtered.to_excel(writer, sheet_name=f'Residue_Count_{count}', index=False)\n",
        "\n",
        "print(\"File saved at:\", output_file_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}