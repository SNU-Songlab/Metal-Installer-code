{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADJrFmW1wzDW"
      },
      "outputs": [],
      "source": [
        "#split (final): Filter out mononuclear copper protein\n",
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "from Bio.PDB import PDBParser\n",
        "from Bio.PDB.PDBExceptions import PDBConstructionWarning\n",
        "from Bio import SeqIO, pairwise2\n",
        "import numpy as np\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "# Function to download PDB files\n",
        "def download_pdb(pdb_code, save_directory):\n",
        "    download_url = f\"https://files.rcsb.org/download/{pdb_code}.pdb\"\n",
        "    response = requests.get(download_url)\n",
        "    if response.status_code == 200:\n",
        "        save_path = os.path.join(save_directory, f\"{pdb_code}.pdb\")\n",
        "        with open(save_path, \"wb\") as file:\n",
        "            file.write(response.content)\n",
        "        print(f\"Downloaded {pdb_code}.pdb\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"Failed to download {pdb_code}.pdb\")\n",
        "        return False\n",
        "\n",
        "# Function to categorize metal atoms in a PDB file\n",
        "def categorize_metal_atoms(filename):\n",
        "    pdb_id = os.path.basename(filename).split('.')[0]\n",
        "    cu_atoms, other_metals = [], []\n",
        "\n",
        "    with open(filename, 'r') as f:\n",
        "        for line in f:\n",
        "            if line.startswith('HETATM'):\n",
        "                element_symbol = line[76:78].strip()\n",
        "                if element_symbol == 'CU':\n",
        "                    cu_atoms.append((pdb_id, 'CU'))\n",
        "                elif element_symbol in ['ZN', 'MG', 'CO', 'CA', 'FE', 'PT', 'NA', 'K', 'LI', 'CD', 'YB', 'NI', 'PR', 'HG', 'MN']:\n",
        "                    other_metals.append((pdb_id, element_symbol))\n",
        "\n",
        "    return cu_atoms, other_metals\n",
        "\n",
        "# Function to save metal atoms information to Excel and copy PDB files\n",
        "def save_metal_atoms_to_excel(directory, destination):\n",
        "    pdb_files = [f for f in os.listdir(directory) if f.endswith('.pdb')]\n",
        "    all_cu_atoms, all_other_metals = [], []\n",
        "\n",
        "    for pdb_file in pdb_files:\n",
        "        cu_atoms, other_metals = categorize_metal_atoms(os.path.join(directory, pdb_file))\n",
        "        all_cu_atoms.extend(cu_atoms)\n",
        "        all_other_metals.extend(other_metals)\n",
        "\n",
        "    pd.DataFrame(all_cu_atoms, columns=['PDB ID', 'Name of metal atoms']).to_excel(os.path.join(destination, 'cu_atoms.xlsx'), index=False)\n",
        "    pd.DataFrame(all_other_metals, columns=['PDB ID', 'Name of metal atoms']).to_excel(os.path.join(destination, 'other_metals.xlsx'), index=False)\n",
        "\n",
        "    for pdb_id in pd.read_excel(os.path.join(destination, 'cu_atoms.xlsx'))['PDB ID'].tolist():\n",
        "        shutil.copy(os.path.join(directory, f\"{pdb_id}.pdb\"), destination)\n",
        "\n",
        "    print(\"Metal atoms categorized and saved to Excel.\")\n",
        "\n",
        "# Function to count and categorize copper atoms in PDB files\n",
        "def count_and_categorize_cu_atoms(excel_file, pdb_directory, output_excel):\n",
        "    df = pd.read_excel(excel_file)\n",
        "    cu_counts = df[df['Name of metal atoms'] == 'CU'].groupby('PDB ID').size().to_dict()\n",
        "\n",
        "    result_df = pd.DataFrame(list(cu_counts.items()), columns=['PDB ID', 'Metal Count'])\n",
        "    result_df.to_excel(output_excel, index=False)\n",
        "    print(f\"Metal atom counts have been saved to '{output_excel}'.\")\n",
        "\n",
        "    for pdb_id, count in cu_counts.items():\n",
        "        src_file = os.path.join(pdb_directory, f\"{pdb_id}.pdb\")\n",
        "        if os.path.isfile(src_file):\n",
        "            dest_dir = os.path.join(pdb_directory, 'metal_count_1' if count == 1 else 'metal_count_greater_than_1')\n",
        "            os.makedirs(dest_dir, exist_ok=True)\n",
        "            shutil.copy(src_file, dest_dir)\n",
        "\n",
        "    print(\"PDB files categorized and copied based on metal count.\")\n",
        "\n",
        "# Function to calculate the distance between two atoms\n",
        "def calculate_distance(atom1, atom2):\n",
        "    return np.linalg.norm(atom1.get_coord() - atom2.get_coord())\n",
        "\n",
        "# Function to categorize PDB files based on copper and other metals within a distance threshold\n",
        "def categorize_pdb_files(directory, distance_threshold=5.0):\n",
        "    copper_ion, other_metals = 'CU', ['ZN', 'MG', 'CO', 'CA', 'FE', 'PT', 'NA', 'K', 'LI', 'CD', 'YB', 'NI', 'PR', 'HG', 'MN']\n",
        "    mono_hetero_results, mono_results = [], []\n",
        "\n",
        "    for pdb_file in (f for f in os.listdir(directory) if f.endswith('.pdb')):\n",
        "        pdb_id = pdb_file.split('.')[0]\n",
        "        structure = PDBParser().get_structure(pdb_id, os.path.join(directory, pdb_file))\n",
        "        copper_atoms = [res for model in structure for chain in model for res in chain if res.get_resname() == copper_ion]\n",
        "\n",
        "        if len(copper_atoms) == 1:\n",
        "            copper_atom = copper_atoms[0]['CU']\n",
        "            other_metals_near_copper = any(\n",
        "                any(calculate_distance(copper_atom, atom) <= distance_threshold for atom in res if atom.element in other_metals)\n",
        "                for model in structure for chain in model for res in chain\n",
        "            )\n",
        "            (mono_hetero_results if other_metals_near_copper else mono_results).append(pdb_id)\n",
        "\n",
        "    save_results(mono_hetero_results, mono_results, directory)\n",
        "\n",
        "# Function to categorize PDB files based on the presence of multiple copper atoms and other metals within a distance threshold\n",
        "def categorize_pdb_files_multinuclear(directory, distance_threshold=5.0):\n",
        "    copper_ion, other_metals = 'CU', ['ZN', 'MG', 'CO', 'CA', 'FE', 'PT', 'NA', 'K', 'LI', 'CD', 'YB', 'NI', 'PR', 'HG', 'MN']\n",
        "    multi_hetero_results, multi_mono_results, homo_multinuclear_results = [], [], []\n",
        "\n",
        "    for pdb_file in (f for f in os.listdir(directory) if f.endswith('.pdb')):\n",
        "        pdb_id = pdb_file.split('.')[0]\n",
        "        structure = PDBParser().get_structure(pdb_id, os.path.join(directory, pdb_file))\n",
        "        copper_atoms = [res['CU'] for model in structure for chain in model for res in chain if res.get_resname() == copper_ion]\n",
        "\n",
        "        if len(copper_atoms) > 1:\n",
        "            if any(calculate_distance(atom1, atom2) <= distance_threshold for atom1 in copper_atoms for atom2 in copper_atoms if atom1 != atom2):\n",
        "                homo_multinuclear_results.append(pdb_id)\n",
        "            else:\n",
        "                other_metals_near_copper = any(\n",
        "                    any(calculate_distance(copper_atom, atom) <= distance_threshold for atom in res if atom.element in other_metals)\n",
        "                    for copper_atom in copper_atoms for model in structure for chain in model for res in chain\n",
        "                )\n",
        "                (multi_hetero_results if other_metals_near_copper else multi_mono_results).append(pdb_id)\n",
        "\n",
        "    save_results_multinuclear(multi_hetero_results, multi_mono_results, homo_multinuclear_results, directory)\n",
        "\n",
        "# Function to save results of categorized PDB files\n",
        "def save_results(mono_hetero_results, mono_results, directory):\n",
        "    for results, subdir in [(mono_hetero_results, 'mono_hetero2'), (mono_results, 'mono2')]:\n",
        "        output_dir = os.path.join(directory, subdir)\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        pd.DataFrame(results, columns=['PDB ID']).to_excel(os.path.join(output_dir, f'{subdir}.xlsx'), index=False)\n",
        "        for pdb_id in results:\n",
        "            shutil.copy(os.path.join(directory, f\"{pdb_id}.pdb\"), output_dir)\n",
        "        print(f\"Results saved to '{output_dir}/{subdir}.xlsx' and corresponding PDB files copied.\")\n",
        "\n",
        "# Function to save results of categorized multinuclear PDB files\n",
        "def save_results_multinuclear(multi_hetero_results, multi_mono_results, homo_multinuclear_results, directory):\n",
        "    for results, subdir in [(multi_hetero_results, 'multi_hetero'), (multi_mono_results, 'multi_mono'), (homo_multinuclear_results, 'homo_multinuclear')]:\n",
        "        output_dir = os.path.join(directory, subdir)\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        pd.DataFrame(results, columns=['PDB ID']).to_excel(os.path.join(output_dir, f'{subdir}.xlsx'), index=False)\n",
        "        for pdb_id in results:\n",
        "            shutil.copy(os.path.join(directory, f\"{pdb_id}.pdb\"), output_dir)\n",
        "        print(f\"Results saved to '{output_dir}/{subdir}.xlsx' and corresponding PDB files copied.\")\n",
        "\n",
        "# Function to copy directories and files\n",
        "def copy_directories_and_files(src_dirs, dst_dir):\n",
        "    os.makedirs(dst_dir, exist_ok=True)\n",
        "    for src_dir in src_dirs:\n",
        "        if os.path.exists(src_dir):\n",
        "            dst_subdir = os.path.join(dst_dir, os.path.basename(src_dir))\n",
        "            shutil.copytree(src_dir, dst_subdir)\n",
        "            for root, _, files in os.walk(src_dir):\n",
        "                for file in files:\n",
        "                    if file.endswith('.pdb'):\n",
        "                        shutil.copy(os.path.join(root, file), dst_dir)\n",
        "            print(f\"Directory '{src_dir}' and PDB files copied to '{dst_subdir}'.\")\n",
        "\n",
        "# Main script\n",
        "# 1. Download PDB files\n",
        "excel_file = \"D://240707_copper/cu_count_results0.xlsx\"\n",
        "df = pd.read_excel(excel_file)\n",
        "pdb_codes = df[\"PDB ID\"].tolist()\n",
        "pdb_directory = \"D://240707_copper/\"\n",
        "os.makedirs(pdb_directory, exist_ok=True)\n",
        "\n",
        "failed_pdb_ids = [pdb_code for pdb_code in pdb_codes if not download_pdb(pdb_code, pdb_directory)]\n",
        "pd.DataFrame({\"PDB ID\": failed_pdb_ids}).to_excel(\"D://240707_copper/Cu_failed.xlsx\", index=False)\n",
        "print(f\"Failed PDB IDs saved to D://240707_copper/Cu_failed.xlsx\")\n",
        "\n",
        "# 2. Save categorized metal atoms to Excel and copy corresponding PDB files\n",
        "save_metal_atoms_to_excel(pdb_directory, 'D://240707_copper/CU_combined')\n",
        "\n",
        "# 3. Count 'CU' atoms based on the PDB IDs in cu_atoms.xlsx and categorize PDB files\n",
        "count_and_categorize_cu_atoms(os.path.join('D://240707_copper/CU_combined', 'cu_atoms.xlsx'), 'D://240707_copper/CU_combined', os.path.join('D://240707_copper/CU_combined', 'cu_count_results.xlsx'))\n",
        "\n",
        "# 4. Categorize and copy PDB files based on the presence of copper and other metals\n",
        "categorize_pdb_files('D://240707_copper/CU_combined/metal_count_1/')\n",
        "\n",
        "# 5. Categorize and copy PDB files based on the presence of multiple copper and other metals\n",
        "categorize_pdb_files_multinuclear('D://240707_copper/CU_combined/metal_count_greater_than_1/')\n",
        "\n",
        "# 6. Copy 'mono_2' and 'multi_mono' directories and individual PDB files to the new directory\n",
        "copy_directories_and_files(['D:/240707_copper/CU_combined/metal_count_1/mono2', 'D:/240707_copper/CU_combined/metal_count_greater_than_1/multi_mono'], 'D:/240707_copper/CU_combined/mono')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split 2(final): Remove sequence redundancy\n",
        "# Function to calculate coordination information for copper atoms\n",
        "def calculate_coordination_info(structure, cu_distance_thresholds, allowed_residues, pdb_id):\n",
        "    coordination_info = {}\n",
        "\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            for res in chain:\n",
        "                if res.get_resname() == 'CU':\n",
        "                    cu_atom = res['CU']\n",
        "                    coord_info = set()\n",
        "                    for model2 in structure:\n",
        "                        for chain2 in model2:\n",
        "                            for res2 in chain2:\n",
        "                                if res2.get_resname() in allowed_residues:\n",
        "                                    for atom in res2:\n",
        "                                        dist = calculate_distance(cu_atom, atom)\n",
        "                                        key = f\"{res2.get_resname()}_{atom.id}\"\n",
        "                                        if key in cu_distance_thresholds and cu_distance_thresholds[key][0] <= dist <= cu_distance_thresholds[key][1]:\n",
        "                                            coord_info.add((pdb_id, structure.header['idcode'], chain.id, res.id[1], res.resname, chain2.id, res2.id[1], res2.resname, atom.id))\n",
        "\n",
        "                    coord_count = len(coord_info)\n",
        "                    if coord_count in coordination_info:\n",
        "                        coordination_info[coord_count].extend(coord_info)\n",
        "                    else:\n",
        "                        coordination_info[coord_count] = list(coord_info)\n",
        "\n",
        "    return coordination_info\n",
        "\n",
        "# Function to parse PDB files in a directory\n",
        "def parse_pdb_files(directory_path):\n",
        "    pdb_parser = PDBParser(QUIET=True)\n",
        "    return [(f[:4], pdb_parser.get_structure(f[:4], os.path.join(directory_path, f))) for f in os.listdir(directory_path) if f.endswith(\".pdb\")]\n",
        "\n",
        "# Function to create a DataFrame from coordination information\n",
        "def create_dataframe(info_list):\n",
        "    base_cols = ['PDB ID', 'Entry ID', 'Metal Chain ID', 'Metal Residue number', 'Metal', 'Chain ID', 'Residue number', 'Residue name']\n",
        "    dynamic_cols = [f'Binding atom {i+1}' for i in range(max(len(item) - len(base_cols) for item in info_list))]\n",
        "    return pd.DataFrame(info_list, columns=base_cols + dynamic_cols).fillna(np.nan)\n",
        "\n",
        "# Function to save DataFrame to an Excel file\n",
        "def save_to_excel(df, output_path):\n",
        "    df.to_excel(output_path, index=False)\n",
        "\n",
        "# Function to extract sequences from PDB files\n",
        "def extract_sequences(input_file, pdb_directory, output_file):\n",
        "    input_df = pd.read_excel(input_file)\n",
        "    sequences_data = []\n",
        "\n",
        "    for index, row in input_df.iterrows():\n",
        "        pdb_path = os.path.join(pdb_directory, f\"{row['PDB ID']}.pdb\")\n",
        "        try:\n",
        "            sequences = [str(record.seq) for record in SeqIO.parse(pdb_path, \"pdb-atom\") if record.annotations.get(\"chain\") == row['Chain ID']]\n",
        "            sequences_data.extend([{\"PDB ID\": row['PDB ID'], \"Chain ID\": row['Chain ID'], \"Sequence\": seq} for seq in sequences] or [{\"PDB ID\": row['PDB ID'], \"Chain ID\": row['Chain ID'], \"Sequence\": \"No sequence found\"}])\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {pdb_path}: {e}\")\n",
        "\n",
        "    pd.DataFrame(sequences_data).to_excel(output_file, index=False)\n",
        "    print(\"Sequences saved to\", output_file)\n",
        "\n",
        "# Function to align sequences and identify unique ones\n",
        "def align_sequences(input_file, threshold, output_file_unique, output_file_excluded):\n",
        "    df = pd.read_excel(input_file)\n",
        "    unique_sequences, excluded_sequences = [], []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        sequence, pdb_id = row[\"Sequence\"], row[\"PDB ID\"]\n",
        "        is_unique = True\n",
        "\n",
        "        for unique_pdb_id, unique_sequence in unique_sequences:\n",
        "            alignment = pairwise2.align.globalxx(sequence, unique_sequence, one_alignment_only=True)\n",
        "            if sum(a == b for a, b in zip(alignment[0][0], alignment[0][1])) / len(alignment[0][0]) * 100 >= threshold:\n",
        "                excluded_sequences.append((pdb_id, sequence))\n",
        "                print(f\"PDB ID {pdb_id} excluded due to high identity with {unique_pdb_id}.\")\n",
        "                is_unique = False\n",
        "                break\n",
        "\n",
        "        if is_unique:\n",
        "            unique_sequences.append((pdb_id, sequence))\n",
        "            print(f\"PDB ID {pdb_id} is unique.\")\n",
        "\n",
        "        print(f\"Progress: {i+1}/{len(df)} | Elapsed Time: {time.time() - start_time:.2f}s\")\n",
        "\n",
        "    pd.DataFrame(unique_sequences, columns=[\"PDB ID\", \"Sequence\"]).to_excel(output_file_unique, index=False)\n",
        "    pd.DataFrame(excluded_sequences, columns=[\"PDB ID\", \"Sequence\"]).to_excel(output_file_excluded, index=False)\n",
        "    print(\"Sequence identity analysis completed.\")\n",
        "\n",
        "# Function to copy PDB files for unique sequences\n",
        "def copy_pdb_files(df, source_dir, destination_dir):\n",
        "    os.makedirs(destination_dir, exist_ok=True)\n",
        "    for pdb_id in df['PDB ID'].tolist():\n",
        "        src_file = os.path.join(source_dir, f\"{pdb_id}.pdb\")\n",
        "        if os.path.exists(src_file):\n",
        "            shutil.copy(src_file, destination_dir)\n",
        "            print(f\"Copied: {pdb_id}.pdb to {destination_dir}\")\n",
        "        else:\n",
        "            print(f\"File not found: {pdb_id}.pdb\")\n",
        "\n",
        "# Main script continuation\n",
        "# Define allowed residues for coordination calculation\n",
        "allowed_residues = {'ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'LYS', 'MET', 'PHE', 'SER', 'THR', 'TYR', 'VAL'}\n",
        "\n",
        "# Define distance thresholds for copper coordination with various residues\n",
        "cu_distance_thresholds = {\n",
        "    'HIS_ND1': (0, 2.7), 'HIS_NE2': (0, 2.7), 'HIS_N': (0, 2.7), 'HIS_O': (0, 2.95), 'GLU_OE': (0, 2.95), 'ASP_OD': (0, 2.95),\n",
        "    'ASP_N': (0, 2.7), 'ASP_O': (0, 2.95), 'GLU_N': (0, 2.7), 'GLU_O': (0, 2.95), 'ALA_N': (0, 2.7), 'ALA_O': (0, 2.95),\n",
        "    'CYS': (0, 2.75), 'MET': (0, 2.75), 'ARG_NH1': (0, 2.7), 'ARG_NH2': (0, 2.7), 'ARG_N': (0, 2.7), 'ARG_O': (0, 2.95),\n",
        "    'ARG_NE': (0, 2.7), 'ASN_OD1': (0, 2.95), 'ASN_ND2': (0, 2.7), 'ASN_N': (0, 2.7), 'ASN_O': (0, 2.95), 'GLN_OE1': (0, 2.95),\n",
        "    'GLN_NE2': (0, 2.7), 'GLN_O': (0, 2.95), 'GLN_N': (0, 2.7), 'GLY_N': (0, 2.7), 'GLY_O': (0, 2.95), 'LYS_NZ': (0, 2.7),\n",
        "    'LYS_N': (0, 2.7), 'LYS_O': (0, 2.95), 'SER_OG': (0, 2.95), 'SER_N': (0, 2.7), 'SER_O': (0, 2.95), 'THR_OG1': (0, 2.95),\n",
        "    'THR_N': (0, 2.7), 'THR_O': (0, 2.95), 'TYR_OH': (0, 2.95), 'TYR_N': (0, 2.7), 'TYR_O': (0, 2.95)\n",
        "}\n",
        "\n",
        "# Parse PDB files\n",
        "structures = parse_pdb_files('D:/240707_copper/CU_combined/mono')\n",
        "\n",
        "# Calculate coordination info\n",
        "info_list = [info for pdb_id, structure in structures for info in sum(calculate_coordination_info(structure, cu_distance_thresholds, allowed_residues, pdb_id).values(), [])]\n",
        "\n",
        "# Create DataFrame and save to Excel\n",
        "df_coordination = create_dataframe(info_list)\n",
        "save_to_excel(df_coordination, 'D:/240707_copper/CU_combined/mono/mono_coordination.xlsx')\n",
        "\n",
        "print(f\"Excel file saved to: D:/240707_copper/CU_combined/mono/mono_coordination.xlsx\")\n",
        "\n",
        "# Extract sequences from PDB files and save to Excel\n",
        "extract_sequences('D:/240707_copper/CU_combined/mono/mono_coordination.xlsx', 'D:/240707_copper/CU_combined/mono/', 'D:/240707_copper/CU_combined/mono/mono_coordination_sequence.xlsx')\n",
        "\n",
        "# Align sequences and identify unique ones\n",
        "align_sequences('D:/240707_copper/CU_combined/mono/mono_coordination_sequence.xlsx', 50.0, 'D:/240707_copper/CU_combined/mono/mono_coordination_sequence_unique.xlsx', 'D:/240707_copper/CU_combined/mono/mono_coordination_sequence_exclude.xlsx')\n",
        "\n",
        "# Copy PDB files for unique sequences\n",
        "df_unique = pd.read_excel('D:/240707_copper/CU_combined/mono/mono_coordination_sequence_unique.xlsx')\n",
        "copy_pdb_files(df_unique, 'D:/240707_copper/CU_combined/mono/', 'D:/240707_copper/CU_combined/mono/final')\n",
        "\n",
        "print(\"File copying completed.\")"
      ],
      "metadata": {
        "id": "tmm5S2LHw2zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split 3(final): Filter out coordination # 3 with distance parameter from metalPDB\n",
        "import os\n",
        "import pandas as pd\n",
        "from Bio import PDB\n",
        "import numpy as np\n",
        "\n",
        "# Define the set of allowed residues\n",
        "allowed_residues = {'ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'LYS', 'MET', 'PHE', 'SER', 'THR', 'TYR', 'VAL'}\n",
        "\n",
        "def calculate_coordination_info(structure, cu_distance_thresholds, allowed_residues, pdb_id):\n",
        "    coordination_info = {}\n",
        "    distances_info = []\n",
        "\n",
        "    def calculate_distance(atom1, atom2):\n",
        "        # Calculate the Euclidean distance between two atoms\n",
        "        x1, y1, z1 = atom1.get_coord()\n",
        "        x2, y2, z2 = atom2.get_coord()\n",
        "        distance = ((x1 - x2)**2 + (y1 - y2)**2 + (z1 - z2)**2)**0.5\n",
        "        return distance\n",
        "\n",
        "    for cu_model_id, cu_model in enumerate(structure):\n",
        "        for cu_chain_id, cu_chain in enumerate(cu_model):\n",
        "            for cu_residue in cu_chain:\n",
        "                if cu_residue.get_resname() == 'CU':\n",
        "                    cu_atom = cu_residue['CU']\n",
        "                    coordination_info_for_cu = set()\n",
        "                    processed_residues = set()\n",
        "\n",
        "                    for model_id, model in enumerate(structure):\n",
        "                        for chain_id, chain in enumerate(model):\n",
        "                            for residue in chain:\n",
        "                                if residue.get_resname() not in allowed_residues:\n",
        "                                    continue\n",
        "\n",
        "                                coord_atoms = set()  # Use a set to store unique coordinated atoms for the current residue\n",
        "\n",
        "                                for atom in residue:\n",
        "                                    atom_name = atom.id\n",
        "\n",
        "                                    if residue.get_resname() == 'HIS' and atom_name == 'ND1':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['HIS_ND1']\n",
        "                                    elif residue.get_resname() == 'HIS' and atom_name == 'NE2':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['HIS_NE2']\n",
        "                                    elif residue.get_resname() == 'HIS' and atom_name == 'N':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['HIS_N']\n",
        "                                    elif residue.get_resname() == 'HIS' and atom_name == 'O':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['HIS_O']\n",
        "                                    elif residue.get_resname() == 'GLU' and atom_name == 'N':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['GLU_N']\n",
        "                                    elif residue.get_resname() == 'GLU' and atom_name == 'O':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['GLU_O']\n",
        "                                    elif residue.get_resname() == 'ASP' and atom_name == 'N':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['ASP_N']\n",
        "                                    elif residue.get_resname() == 'ASP' and atom_name == 'O':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['ASP_O']\n",
        "                                    elif residue.get_resname() == 'GLU' and atom_name == 'OE1':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['GLU_OE']\n",
        "                                    elif residue.get_resname() == 'GLU' and atom_name == 'OE2':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['GLU_OE']\n",
        "                                    elif residue.get_resname() == 'ASP' and atom_name == 'OD1':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['ASP_OD']\n",
        "                                    elif residue.get_resname() == 'ASP' and atom_name == 'OD2':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['ASP_OD']\n",
        "                                    elif residue.get_resname() == 'ALA' and atom_name == 'N':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['ALA_N']\n",
        "                                    elif residue.get_resname() == 'ALA' and atom_name == 'O':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['ALA_O']\n",
        "                                    elif residue.get_resname() == 'ARG' and atom_name == 'N':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['ARG_N']\n",
        "                                    elif residue.get_resname() == 'ARG' and atom_name == 'O':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['ARG_O']\n",
        "                                    elif residue.get_resname() == 'ASN' and atom_name == 'N':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['ASN_N']\n",
        "                                    elif residue.get_resname() == 'ASN' and atom_name == 'O':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['ASN_O']\n",
        "                                    elif residue.get_resname() == 'GLN' and atom_name == 'N':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['GLN_N']\n",
        "                                    elif residue.get_resname() == 'GLN' and atom_name == 'O':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['GLN_O']\n",
        "                                    elif residue.get_resname() == 'LYS' and atom_name == 'N':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['LYS_N']\n",
        "                                    elif residue.get_resname() == 'LYS' and atom_name == 'O':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['LYS_O']\n",
        "                                    elif residue.get_resname() == 'SER' and atom_name == 'N':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['SER_N']\n",
        "                                    elif residue.get_resname() == 'SER' and atom_name == 'O':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['SER_O']\n",
        "                                    elif residue.get_resname() == 'THR' and atom_name == 'N':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['THR_N']\n",
        "                                    elif residue.get_resname() == 'THR' and atom_name == 'O':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['THR_O']\n",
        "                                    elif residue.get_resname() == 'TYR' and atom_name == 'N':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['TYR_N']\n",
        "                                    elif residue.get_resname() == 'TYR' and atom_name == 'O':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['TYR_O']\n",
        "                                    elif residue.get_resname() == 'CYS' and atom_name == 'SG':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['CYS']\n",
        "                                    elif residue.get_resname() == 'MET' and atom_name == 'SD':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['MET']\n",
        "                                    elif residue.get_resname() == 'ARG' and atom_name == 'NH1':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['ARG_NH1']\n",
        "                                    elif residue.get_resname() == 'ARG' and atom_name == 'NH2':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['ARG_NH2']\n",
        "                                    elif residue.get_resname() == 'ARG' and atom_name == 'NE':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['ARG_NE']\n",
        "                                    elif residue.get_resname() == 'ASN' and atom_name == 'OD1':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['ASN_OD1']\n",
        "                                    elif residue.get_resname() == 'ASN' and atom_name == 'ND2':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['ASN_ND2']\n",
        "                                    elif residue.get_resname() == 'GLN' and atom_name == 'OE1':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['GLN_OE1']\n",
        "                                    elif residue.get_resname() == 'GLN' and atom_name == 'NE2':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['GLN_NE2']\n",
        "                                    elif residue.get_resname() == 'GLY' and atom_name == 'N':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['GLY_N']\n",
        "                                    elif residue.get_resname() == 'GLY' and atom_name == 'O':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['GLY_O']\n",
        "                                    elif residue.get_resname() == 'LYS' and atom_name == 'NZ':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['LYS_NZ']\n",
        "                                    elif residue.get_resname() == 'SER' and atom_name == 'OG':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['SER_OG']\n",
        "                                    elif residue.get_resname() == 'THR' and atom_name == 'OG1':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['THR_OG1']\n",
        "                                    elif residue.get_resname() == 'TYR' and atom_name == 'OH':\n",
        "                                        min_distance, max_distance = cu_distance_thresholds['TYR_OH']\n",
        "                                    else:\n",
        "                                        min_distance, max_distance = 0, 0\n",
        "\n",
        "                                    # Calculate the distance between cu_atom and atom\n",
        "                                    distance = calculate_distance(cu_atom, atom)\n",
        "\n",
        "                                    if min_distance <= distance <= max_distance:\n",
        "                                        coord_atoms.add((atom_name, residue.get_id()[1], distance))\n",
        "                                        distances_info.append((pdb_id, cu_chain.get_id(), cu_residue.get_id()[1], cu_residue.get_resname(),\n",
        "                                                              chain.get_id(), residue.get_id()[1], residue.get_resname(), atom_name, distance))\n",
        "\n",
        "                                if coord_atoms:\n",
        "                                    sorted_coord_atoms = sorted(coord_atoms, key=lambda x: x[1])[:3]\n",
        "                                    coord_residue_info = (\n",
        "                                        pdb_id,\n",
        "                                        structure.header['idcode'],\n",
        "                                        cu_chain.get_id(),\n",
        "                                        cu_residue.get_id()[1],\n",
        "                                        cu_residue.get_resname(),\n",
        "                                        chain.get_id(),\n",
        "                                        residue.get_id()[1],\n",
        "                                        residue.get_resname()\n",
        "                                    )\n",
        "\n",
        "                                    for coord_atom_info in sorted_coord_atoms:\n",
        "                                        coord_residue_info += (coord_atom_info[0],)\n",
        "\n",
        "                                    coordination_info_for_cu.add(coord_residue_info)\n",
        "                                processed_residues.add(residue.get_id())\n",
        "\n",
        "                    coordinated_residues_count = len(coordination_info_for_cu)\n",
        "\n",
        "                    if coordinated_residues_count in coordination_info:\n",
        "                        coordination_info[coordinated_residues_count].extend(coordination_info_for_cu)\n",
        "                    else:\n",
        "                        coordination_info[coordinated_residues_count] = list(coordination_info_for_cu)\n",
        "\n",
        "    return coordination_info, distances_info\n",
        "\n",
        "\n",
        "# Directory containing PDB files\n",
        "pdb_directory = 'D:/240701_All_copper_final/CU_combined/metal_count_greater_than_1/homo_multinuclear'\n",
        "\n",
        "# Dictionary defining distance thresholds for copper coordination with various residues\n",
        "# Define distance thresholds for each coordination\n",
        "cu_distance_thresholds = {\n",
        "    'HIS_ND1': (0, 2.7),\n",
        "    'HIS_NE2': (0, 2.7),\n",
        "    'HIS_N': (0, 2.7),\n",
        "    'HIS_O': (0, 2.95),\n",
        "    'GLU_OE': (0, 2.95),\n",
        "    'ASP_OD': (0, 2.95),\n",
        "    'ASP_N': (0, 2.7),\n",
        "    'ASP_O': (0, 2.95),\n",
        "    'GLU_N': (0, 2.7),\n",
        "    'GLU_O': (0, 2.95),\n",
        "    'ALA_N': (0, 2.7),\n",
        "    'ALA_O': (0, 2.95),\n",
        "    'CYS': (0, 2.75),\n",
        "    'MET': (0, 2.75),\n",
        "    'ARG_NH1': (0, 2.7),\n",
        "    'ARG_NH2': (0, 2.7),\n",
        "    'ARG_N': (0, 2.7),\n",
        "    'ARG_O': (0, 2.95),\n",
        "    'ARG_NE': (0, 2.7),\n",
        "    'ASN_OD1': (0, 2.95),\n",
        "    'ASN_ND2': (0, 2.7),\n",
        "    'ASN_N': (0, 2.7),\n",
        "    'ASN_O': (0, 2.95),\n",
        "    'GLN_OE1': (0, 2.95),\n",
        "    'GLN_NE2': (0, 2.7),\n",
        "    'GLN_O': (0, 2.95),\n",
        "    'GLN_N': (0, 2.7),\n",
        "    'GLY_N': (0, 2.7),\n",
        "    'GLY_O': (0, 2.95),\n",
        "    'LYS_NZ': (0, 2.7),\n",
        "    'LYS_N': (0, 2.7),\n",
        "    'LYS_O': (0, 2.95),\n",
        "    'SER_OG': (0, 2.95),\n",
        "    'SER_N': (0, 2.7),\n",
        "    'SER_O': (0, 2.95),\n",
        "    'THR_OG1': (0, 2.95),\n",
        "    'THR_N': (0, 2.7),\n",
        "    'THR_O': (0, 2.95),\n",
        "    'TYR_OH': (0, 2.95),\n",
        "    'TYR_N': (0, 2.7),\n",
        "    'TYR_O': (0, 2.95),\n",
        "}\n",
        "\n",
        "# Initialize a dictionary to store coordination information for different coordination numbers\n",
        "coordination_info_dict = {}\n",
        "distances_info_list = []\n",
        "\n",
        "# Loop through each PDB file in the specified directory\n",
        "for filename in os.listdir(pdb_directory):\n",
        "    if filename.endswith('.pdb'):\n",
        "        pdb_file_path = os.path.join(pdb_directory, filename)\n",
        "        pdb_id = filename.split('.')[0]  # Extract the PDB ID from the filename\n",
        "\n",
        "        # Parse the PDB file\n",
        "        parser = PDB.PDBParser(QUIET=True)\n",
        "        structure = parser.get_structure('protein', pdb_file_path)\n",
        "\n",
        "        # Calculate coordination information for the current PDB file\n",
        "        coordination_info, distances_info = calculate_coordination_info(structure, cu_distance_thresholds, allowed_residues, pdb_id)\n",
        "\n",
        "        # Get the number of columns from the first row of data (if available)\n",
        "        num_columns = len(next(iter(coordination_info.values()), [])) if coordination_info else 0\n",
        "\n",
        "        # Generate column names dynamically\n",
        "        columns = [f'Column{i}' for i in range(num_columns)]\n",
        "\n",
        "        # Add the coordination information to the coordination_info_dict\n",
        "        for coordination_number, info_list in coordination_info.items():\n",
        "            if coordination_number in coordination_info_dict:\n",
        "                coordination_info_dict[coordination_number].extend(info_list)\n",
        "            else:\n",
        "                coordination_info_dict[coordination_number] = info_list\n",
        "\n",
        "        # Add the distances information to the distances_info_list\n",
        "        distances_info_list.extend(distances_info)\n",
        "\n",
        "# Create and save Excel files for all coordination numbers\n",
        "for coordination_number, info_list in coordination_info_dict.items():\n",
        "    # Generate columns dynamically based on the maximum number of columns in the data\n",
        "    max_columns = max(len(row) for row in info_list) if info_list else 0\n",
        "    columns = ['Entry ID', 'PDB ID', 'Metal Chain ID', 'Metal Residue number', 'Metal', 'Chain ID', 'Residue number', 'Residue name']\n",
        "\n",
        "    # Add binding atom columns based on max number of binding atoms found\n",
        "    for i in range(1, max_columns - 8 + 1):\n",
        "        columns.append(f'Binding atom{i}')\n",
        "\n",
        "    # Create a DataFrame with a fixed number of columns and fill missing values with NaN\n",
        "    df_coordination = pd.DataFrame(info_list, columns=columns).fillna(np.nan)\n",
        "\n",
        "    output_excel_path = f'D:/240701_All_copper_final/CU_combined/metal_count_greater_than_1/homo_multinuclear/new_{coordination_number}.xlsx'\n",
        "    df_coordination.to_excel(output_excel_path, index=False)\n",
        "\n",
        "print('Data saved to properly formatted Excel files for all coordination numbers.')"
      ],
      "metadata": {
        "id": "cjDMbzUtw5RF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ebf842-df8e-4991-a670-f637d39f8f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to properly formatted Excel files for all coordination numbers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split (final): 4: change the format of excel file\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "coordination_df = pd.read_excel('D:/240701_All_copper_final/CU_combined/metal_count_greater_than_1/homo_multinuclear/new_3.xlsx')\n",
        "\n",
        "# Remove extra single quotes from column names\n",
        "coordination_df.columns = coordination_df.columns.str.replace(\"'\", \"\")\n",
        "\n",
        "# Prepare the data for horizontal arrangement based on PDB_ID, Metal Chain ID, and Metal Residue number\n",
        "grouped = coordination_df.groupby(['Entry ID', 'Metal Chain ID', 'Metal Residue number'])\n",
        "\n",
        "# Create a new DataFrame to hold the horizontally arranged data\n",
        "horizontal_data = []\n",
        "\n",
        "for name, group in grouped:\n",
        "    row = list(name)\n",
        "    for _, data in group.iterrows():\n",
        "        row.extend([\n",
        "            data['Chain ID'], data['Residue number'], data['Residue name'], data['Binding atom1']\n",
        "        ])\n",
        "    horizontal_data.append(row)\n",
        "\n",
        "# Determine the column names for the new DataFrame\n",
        "max_columns = max(len(row) for row in horizontal_data)\n",
        "columns = ['Entry ID', 'Metal Chain ID', 'Metal Residue number'] + \\\n",
        "    [item for i in range((max_columns - 3) // 4) for item in [f'Chain ID{i+1}', f'Residue_number{i+1}', f'Residue_name{i+1}', f'Binding atom{i+1}']]\n",
        "\n",
        "# Create the horizontally arranged DataFrame\n",
        "horizontal_df = pd.DataFrame(horizontal_data, columns=columns)\n",
        "\n",
        "# Save the resulting DataFrame to a new Excel file\n",
        "horizontal_df.to_excel('D:/240701_All_copper_final/CU_combined/metal_count_greater_than_1/homo_multinuclear/new_3_format.xlsx', index=False)"
      ],
      "metadata": {
        "id": "KMsiYSi2w7sZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split (final): 4: calculate the theta aangle\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "coordination_df = pd.read_excel('D:/240701_All_copper_final/CU_combined/metal_count_greater_than_1/homo_multinuclear/new_3_format.xlsx')\n",
        "\n",
        "# Remove extra single quotes from column names\n",
        "coordination_df.columns = coordination_df.columns.str.replace(\"'\", \"\")\n",
        "\n",
        "# Prepare the data for horizontal arrangement based on PDB_ID, Metal Chain ID, and Metal Residue number\n",
        "grouped = coordination_df.groupby(['Entry ID', 'Metal Chain ID', 'Metal Residue number'])\n",
        "\n",
        "# Create a new DataFrame to hold the horizontally arranged data\n",
        "horizontal_data = []\n",
        "\n",
        "for name, group in grouped:\n",
        "    row = list(name)\n",
        "    for _, data in group.iterrows():\n",
        "        row.extend([\n",
        "            data['Chain ID'], data['Residue number'], data['Residue name'], data['Binding atom1']\n",
        "        ])\n",
        "    horizontal_data.append(row)\n",
        "\n",
        "# Determine the column names for the new DataFrame\n",
        "max_columns = max(len(row) for row in horizontal_data)\n",
        "columns = ['Entry ID', 'Metal Chain ID', 'Metal Residue number'] + \\\n",
        "    [item for i in range((max_columns - 3) // 4) for item in [f'Chain ID{i+1}', f'Residue_number{i+1}', f'Residue_name{i+1}', f'Binding atom{i+1}']]\n",
        "\n",
        "# Create the horizontally arranged DataFrame\n",
        "horizontal_df = pd.DataFrame(horizontal_data, columns=columns)\n",
        "\n",
        "# Save the resulting DataFrame to a new Excel file\n",
        "horizontal_df.to_excel('D:/240701_All_copper_final/CU_combined/metal_count_greater_than_1/homo_multinuclear/new_3_theta.xlsx', index=False)"
      ],
      "metadata": {
        "id": "AmdICIq6w9ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split (final): 5: calculate the pie angle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import acos, degrees\n",
        "\n",
        "# Function to calculate the angle between two vectors\n",
        "def calculate_angle(vector1, vector2):\n",
        "    \"\"\"\n",
        "    Calculate the angle between two vectors.\n",
        "    \"\"\"\n",
        "    unit_vector1 = vector1 / np.linalg.norm(vector1)\n",
        "    unit_vector2 = vector2 / np.linalg.norm(vector2)\n",
        "    dot_product = np.dot(unit_vector1, unit_vector2)\n",
        "    angle = degrees(acos(dot_product))\n",
        "    return angle\n",
        "\n",
        "# Read data from the Excel file\n",
        "input_file_path = 'D:/240701_All_copper_final/CU_combined/metal_count_greater_than_1/homo_multinuclear/new_3_theta.xlsx'\n",
        "data = pd.read_excel(input_file_path)\n",
        "\n",
        "# Process each row to calculate angles\n",
        "def calculate_angles_for_row(row):\n",
        "    try:\n",
        "        # Vectors for residue pair 1 (1-2)\n",
        "        vector_CA1_CA2 = np.array([row['Calpha_X_2'] - row['Calpha_X_1'],\n",
        "                                   row['Calpha_Y_2'] - row['Calpha_Y_1'],\n",
        "                                   row['Calpha_Z_2'] - row['Calpha_Z_1']])\n",
        "        vector_CB1_CB2 = np.array([row['Cbeta_X_2'] - row['Cbeta_X_1'],\n",
        "                                   row['Cbeta_Y_2'] - row['Cbeta_Y_1'],\n",
        "                                   row['Cbeta_Z_2'] - row['Cbeta_Z_1']])\n",
        "        angle1 = calculate_angle(vector_CA1_CA2, vector_CB1_CB2)\n",
        "\n",
        "        # Vectors for residue pair 2 (1-3)\n",
        "        vector_CA1_CA3 = np.array([row['Calpha_X_3'] - row['Calpha_X_1'],\n",
        "                                   row['Calpha_Y_3'] - row['Calpha_Y_1'],\n",
        "                                   row['Calpha_Z_3'] - row['Calpha_Z_1']])\n",
        "        vector_CB1_CB3 = np.array([row['Cbeta_X_3'] - row['Cbeta_X_1'],\n",
        "                                   row['Cbeta_Y_3'] - row['Cbeta_Y_1'],\n",
        "                                   row['Cbeta_Z_3'] - row['Cbeta_Z_1']])\n",
        "        angle2 = calculate_angle(vector_CA1_CA3, vector_CB1_CB3)\n",
        "\n",
        "        # Vectors for residue pair 3 (2-3)\n",
        "        vector_CA2_CA3 = np.array([row['Calpha_X_3'] - row['Calpha_X_2'],\n",
        "                                   row['Calpha_Y_3'] - row['Calpha_Y_2'],\n",
        "                                   row['Calpha_Z_3'] - row['Calpha_Z_2']])\n",
        "        vector_CB2_CB3 = np.array([row['Cbeta_X_3'] - row['Cbeta_X_2'],\n",
        "                                   row['Cbeta_Y_3'] - row['Cbeta_Y_2'],\n",
        "                                   row['Cbeta_Z_3'] - row['Cbeta_Z_2']])\n",
        "        angle3 = calculate_angle(vector_CA2_CA3, vector_CB2_CB3)\n",
        "\n",
        "        return pd.Series([angle1, angle2, angle3])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing row: {e}\")\n",
        "        return pd.Series([None, None, None])\n",
        "\n",
        "# Apply the function to each row and store the results in new columns\n",
        "pi_angle_columns = ['Pi_Angle_1', 'Pi_Angle_2', 'Pi_Angle_3']\n",
        "data[pi_angle_columns] = data.apply(calculate_angles_for_row, axis=1)\n",
        "\n",
        "# Save the results back to an Excel file\n",
        "output_path = 'D:/240701_All_copper_final/CU_combined/metal_count_greater_than_1/homo_multinuclear/new_3_theta_pie.xlsx'\n",
        "data.to_excel(output_path, index=False)\n",
        "\n",
        "print(\"Angles calculated and saved to:\", output_path)"
      ],
      "metadata": {
        "id": "DSPJw-cInsXZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}